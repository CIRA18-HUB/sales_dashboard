# enhanced_sales_prediction_streamlit_fixed.py
"""
ä¿®å¤ç‰ˆé”€å”®é¢„æµ‹ç³»ç»Ÿ - åŸºäºçœŸå®æ•°æ®ä¸Šä¼ 
============================================

ä¿®å¤äº†åŸç³»ç»Ÿçš„è‡´å‘½é—®é¢˜ï¼Œå¢åŠ äº†é¢„æµ‹è·Ÿè¸ªå’ŒéªŒè¯åŠŸèƒ½
è§£å†³äº†æ•°æ®æºä¸å­˜åœ¨ã€æ—¶é—´åºåˆ—å¤„ç†ã€é¢„æµ‹éªŒè¯ç­‰æ ¸å¿ƒé—®é¢˜

æ ¸å¿ƒä¿®å¤ï¼š
1. ğŸ”§ æ”¹ä¸ºæœ¬åœ°æ–‡ä»¶ä¸Šä¼ ï¼Œä¸ä¾èµ–ä¸å­˜åœ¨çš„GitHubæº
2. â° ä¸¥æ ¼çš„æ—¶é—´åºåˆ—åˆ†å‰²ï¼Œé¿å…æ•°æ®æ³„éœ²
3. ğŸ“Š é¢„æµ‹è·Ÿè¸ªç³»ç»Ÿï¼Œæ”¯æŒæœªæ¥éªŒè¯
4. ğŸ¯ æ”¹è¿›çš„å‡†ç¡®ç‡è®¡ç®—å’Œç½®ä¿¡åº¦è¯„ä¼°
5. ğŸ›¡ï¸ å®Œå–„çš„é”™è¯¯å¤„ç†å’Œæ•°æ®éªŒè¯

ç‰ˆæœ¬: v2.2 Fixed & Enhanced
æ›´æ–°: 2025-06-04
ä¿®å¤: è‡´å‘½çš„æ•°æ®æºå’Œé¢„æµ‹éªŒè¯é—®é¢˜
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import warnings
import time
import io
import json
import pickle
import hashlib

warnings.filterwarnings('ignore')

# æœºå™¨å­¦ä¹ åº“
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, r2_score
from sklearn.preprocessing import RobustScaler, StandardScaler
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb
import lightgbm as lgb

# ====================================================================
# é¡µé¢é…ç½®
# ====================================================================
st.set_page_config(
    page_title="ä¿®å¤ç‰ˆé”€å”®é¢„æµ‹ç³»ç»Ÿ",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ====================================================================
# ç°ä»£åŒ–æ ·å¼
# ====================================================================
modern_styles = """
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');

    .stApp {
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        min-height: 100vh;
    }

    .main {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        min-height: 100vh;
    }

    /* å¤´éƒ¨æ ·å¼ */
    .prediction-header {
        background: rgba(255, 255, 255, 0.95);
        backdrop-filter: blur(25px);
        border-radius: 20px;
        padding: 2rem;
        margin-bottom: 2rem;
        box-shadow: 0 10px 30px rgba(0,0,0,0.1);
        text-align: center;
    }

    .prediction-title {
        font-size: 3rem;
        font-weight: 800;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 1rem;
    }

    .prediction-subtitle {
        font-size: 1.2rem;
        color: #666;
        margin-bottom: 1rem;
    }

    /* åŠŸèƒ½å¡ç‰‡ */
    .feature-card {
        background: rgba(255, 255, 255, 0.95);
        backdrop-filter: blur(25px);
        border-radius: 15px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 8px 25px rgba(0,0,0,0.1);
        border-left: 4px solid #667eea;
        transition: all 0.3s ease;
    }

    .feature-card:hover {
        transform: translateY(-3px);
        box-shadow: 0 12px 35px rgba(0,0,0,0.15);
    }

    /* æŒ‡æ ‡å¡ç‰‡ */
    .metric-card {
        background: rgba(255, 255, 255, 0.95);
        border-radius: 15px;
        padding: 1.5rem;
        text-align: center;
        border-left: 4px solid #667eea;
        box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        height: 100%;
    }

    .metric-value {
        font-size: 2.5rem;
        font-weight: bold;
        color: #667eea;
    }

    .metric-label {
        font-size: 1rem;
        color: #666;
        margin-top: 0.5rem;
    }

    /* çŠ¶æ€æŒ‡ç¤ºå™¨ */
    .status-indicator {
        width: 12px;
        height: 12px;
        border-radius: 50%;
        display: inline-block;
        margin-right: 0.5rem;
        animation: pulse 2s infinite;
    }

    .status-success { background-color: #4CAF50; }
    .status-warning { background-color: #FF9800; }
    .status-danger { background-color: #f44336; }

    @keyframes pulse {
        0% { transform: scale(1); opacity: 1; }
        50% { transform: scale(1.1); opacity: 0.8; }
        100% { transform: scale(1); opacity: 1; }
    }

    /* è¿›åº¦æ¡æ ·å¼ */
    .stProgress > div > div > div > div {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    }

    /* æŒ‰é’®æ ·å¼ */
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 10px;
        font-weight: 500;
        transition: all 0.3s ease;
    }

    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 5px 15px rgba(0,0,0,0.2);
    }

    .upload-section {
        border: 2px dashed #667eea;
        border-radius: 15px;
        padding: 2rem;
        background: rgba(255, 255, 255, 0.9);
        text-align: center;
        margin: 1rem 0;
    }

    .error-card {
        background: rgba(255, 82, 82, 0.1);
        border: 1px solid #ff5252;
        border-radius: 10px;
        padding: 1rem;
        margin: 1rem 0;
    }

    .warning-card {
        background: rgba(255, 193, 7, 0.1);
        border: 1px solid #ffc107;
        border-radius: 10px;
        padding: 1rem;
        margin: 1rem 0;
    }

    .success-card {
        background: rgba(76, 175, 80, 0.1);
        border: 1px solid #4caf50;
        border-radius: 10px;
        padding: 1rem;
        margin: 1rem 0;
    }
</style>
"""

st.markdown(modern_styles, unsafe_allow_html=True)

# ====================================================================
# Session State åˆå§‹åŒ–
# ====================================================================
def initialize_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    defaults = {
        'model_trained': False,
        'prediction_system': None,
        'training_progress': 0.0,
        'training_status': "ç­‰å¾…å¼€å§‹",
        'prediction_results': None,
        'historical_analysis': None,
        'accuracy_stats': None,
        'feature_importance': None,
        'model_comparison': None,
        'uploaded_data': None,
        'data_validation_passed': False,
        'prediction_tracker': None,
        # è®­ç»ƒå‚æ•°
        'test_ratio': 0.2,
        'months_ahead': 3,
        'outlier_factor': 3.0,
        'min_data_points': 4,
        'n_estimators': 300,
        'max_depth': 5,
        'learning_rate': 0.05
    }
    
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

initialize_session_state()

# ====================================================================
# é¢„æµ‹è·Ÿè¸ªç³»ç»Ÿç±»
# ====================================================================
class PredictionTracker:
    """é¢„æµ‹è·Ÿè¸ªç³»ç»Ÿ - å­˜å‚¨æœªæ¥é¢„æµ‹å¹¶ç­‰å¾…éªŒè¯"""
    
    def __init__(self):
        self.predictions_store = {}  # å­˜å‚¨é¢„æµ‹è®°å½•
        self.validation_results = {}  # å­˜å‚¨éªŒè¯ç»“æœ
        
    def save_prediction(self, product_code, target_month, predicted_value, 
                       confidence_interval, model_used, prediction_date=None):
        """ä¿å­˜æœªæ¥é¢„æµ‹"""
        if prediction_date is None:
            prediction_date = datetime.now()
            
        pred_id = f"{product_code}_{target_month}"
        
        self.predictions_store[pred_id] = {
            'product_code': product_code,
            'target_month': target_month,
            'predicted_value': predicted_value,
            'confidence_interval': confidence_interval,
            'model_used': model_used,
            'prediction_date': prediction_date,
            'status': 'pending',  # pending, validated, expired
            'actual_value': None,
            'accuracy': None,
            'validation_date': None
        }
    
    def validate_prediction(self, product_code, target_month, actual_value):
        """éªŒè¯é¢„æµ‹å‡†ç¡®æ€§"""
        pred_id = f"{product_code}_{target_month}"
        
        if pred_id in self.predictions_store:
            prediction = self.predictions_store[pred_id]
            
            # è®¡ç®—å‡†ç¡®ç‡
            accuracy = self.calculate_robust_accuracy(
                actual_value, prediction['predicted_value']
            )
            
            # æ›´æ–°è®°å½•
            prediction.update({
                'actual_value': actual_value,
                'accuracy': accuracy,
                'status': 'validated',
                'validation_date': datetime.now()
            })
            
            return accuracy
        
        return None
    
    def calculate_robust_accuracy(self, actual, predicted):
        """è®¡ç®—ç¨³å¥å‡†ç¡®ç‡"""
        if actual == 0 and predicted == 0:
            return 100.0
        
        smape = 200 * abs(actual - predicted) / (abs(actual) + abs(predicted) + 1e-8)
        return max(0, 100 - smape)
    
    def get_pending_predictions(self):
        """è·å–å¾…éªŒè¯çš„é¢„æµ‹"""
        pending = []
        for pred_id, pred in self.predictions_store.items():
            if pred['status'] == 'pending':
                pending.append(pred)
        return pending
    
    def get_validation_stats(self):
        """è·å–éªŒè¯ç»Ÿè®¡"""
        validated = [p for p in self.predictions_store.values() if p['status'] == 'validated']
        
        if not validated:
            return None
        
        accuracies = [p['accuracy'] for p in validated]
        
        return {
            'total_validated': len(validated),
            'avg_accuracy': np.mean(accuracies),
            'median_accuracy': np.median(accuracies),
            'min_accuracy': np.min(accuracies),
            'max_accuracy': np.max(accuracies),
            'std_accuracy': np.std(accuracies),
            'above_80_pct': len([a for a in accuracies if a >= 80]) / len(accuracies) * 100,
            'above_90_pct': len([a for a in accuracies if a >= 90]) / len(accuracies) * 100
        }

# ====================================================================
# ä¿®å¤ç‰ˆé¢„æµ‹ç³»ç»Ÿç±»
# ====================================================================
class FixedSalesPredictionSystem:
    """ä¿®å¤ç‰ˆé”€å”®é¢„æµ‹ç³»ç»Ÿ - è§£å†³è‡´å‘½é—®é¢˜"""
    
    def __init__(self):
        self.shipment_data = None
        self.promotion_data = None
        self.feature_data = None
        self.models = {}
        self.scalers = {}
        self.predictions = None
        self.accuracy_results = {}
        self.product_segments = {}
        self.historical_predictions = None
        self.historical_accuracy = None
        self.data_summary = {}
        self.training_time = None
        self.data_source_info = {}
        self.prediction_tracker = PredictionTracker()
        
    def load_data_from_upload(self, uploaded_file, progress_callback=None):
        """ä»ä¸Šä¼ æ–‡ä»¶åŠ è½½æ•°æ®"""
        if progress_callback:
            progress_callback(0.1, "ğŸ“ å¤„ç†ä¸Šä¼ æ–‡ä»¶...")
        
        try:
            # è¯»å–ä¸Šä¼ çš„æ–‡ä»¶
            if uploaded_file.name.endswith('.csv'):
                self.shipment_data = pd.read_csv(uploaded_file)
            elif uploaded_file.name.endswith(('.xlsx', '.xls')):
                self.shipment_data = pd.read_excel(uploaded_file)
            else:
                raise Exception("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä¸Šä¼ CSVæˆ–Excelæ–‡ä»¶")
            
            if progress_callback:
                progress_callback(0.2, f"âœ… æˆåŠŸè¯»å–æ–‡ä»¶: {len(self.shipment_data)} è¡Œæ•°æ®")
            
            # éªŒè¯å’Œæ¸…ç†æ•°æ®
            self.shipment_data = self._validate_and_clean_shipment_data(self.shipment_data)
            
            # ä¿å­˜æ•°æ®æºä¿¡æ¯
            self.data_source_info = {
                'file_name': uploaded_file.name,
                'file_size': uploaded_file.size,
                'load_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'source_type': 'uploaded_file'
            }
            
            if progress_callback:
                progress_callback(0.3, f"âœ… æ•°æ®éªŒè¯å®Œæˆ: {len(self.shipment_data)} æ¡æœ‰æ•ˆè®°å½•")
            
            return True
            
        except Exception as e:
            error_msg = f"æ•°æ®åŠ è½½å¤±è´¥: {str(e)}"
            if progress_callback:
                progress_callback(0.1, f"âŒ {error_msg}")
            raise Exception(error_msg)
    
    def _validate_and_clean_shipment_data(self, raw_data):
        """å¢å¼ºçš„æ•°æ®éªŒè¯å’Œæ¸…ç†"""
        print("ğŸ” éªŒè¯æ•°æ®æ ¼å¼...")
        
        if len(raw_data) == 0:
            raise Exception("æ•°æ®æ–‡ä»¶ä¸ºç©º")
        
        print(f"åŸå§‹æ•°æ®å½¢çŠ¶: {raw_data.shape}")
        print(f"åŸå§‹åˆ—å: {list(raw_data.columns)}")
        
        # æ ‡å‡†åŒ–åˆ—åæ˜ å°„
        column_mapping = {
            # ä¸­æ–‡åˆ—å
            'è®¢å•æ—¥æœŸ': 'order_date', 'å‡ºè´§æ—¥æœŸ': 'order_date', 'æ—¥æœŸ': 'order_date',
            'åŒºåŸŸ': 'region', 'åœ°åŒº': 'region',
            'å®¢æˆ·ä»£ç ': 'customer_code', 'å®¢æˆ·ç¼–ç ': 'customer_code', 'ç»é”€å•†ä»£ç ': 'customer_code',
            'äº§å“ä»£ç ': 'product_code', 'äº§å“ç¼–ç ': 'product_code', 'è´§å·': 'product_code',
            'æ•°é‡': 'quantity', 'é”€é‡': 'quantity', 'å‡ºè´§é‡': 'quantity', 'ç®±æ•°': 'quantity',
            
            # è‹±æ–‡åˆ—å
            'date': 'order_date', 'ship_date': 'order_date',
            'area': 'region', 'customer': 'customer_code', 'customer_id': 'customer_code',
            'dealer': 'customer_code', 'dealer_code': 'customer_code',
            'product': 'product_code', 'product_id': 'product_code', 'sku': 'product_code',
            'qty': 'quantity', 'volume': 'quantity', 'sales': 'quantity', 'amount': 'quantity'
        }
        
        # åº”ç”¨åˆ—åæ˜ å°„
        cleaned_data = raw_data.copy()
        
        # æ™ºèƒ½åˆ—ååŒ¹é…
        for original_col in raw_data.columns:
            col_lower = str(original_col).lower().strip()
            
            # ç²¾ç¡®åŒ¹é…
            if col_lower in column_mapping:
                cleaned_data = cleaned_data.rename(columns={original_col: column_mapping[col_lower]})
                continue
            
            # æ¨¡ç³ŠåŒ¹é…
            for pattern, target in column_mapping.items():
                if pattern in col_lower or col_lower in pattern:
                    cleaned_data = cleaned_data.rename(columns={original_col: target})
                    break
        
        print(f"æ˜ å°„ååˆ—å: {list(cleaned_data.columns)}")
        
        # æ£€æŸ¥å¿…è¦å­—æ®µ
        required_fields = ['order_date', 'product_code', 'quantity']
        missing_fields = [field for field in required_fields if field not in cleaned_data.columns]
        
        if missing_fields:
            # æ™ºèƒ½æ¨æ–­ç¼ºå¤±å­—æ®µ
            available_cols = list(cleaned_data.columns)
            
            for field in missing_fields:
                inferred_col = self._infer_column(field, available_cols, cleaned_data)
                if inferred_col:
                    cleaned_data[field] = cleaned_data[inferred_col]
                    print(f"æ¨æ–­å­—æ®µ: {inferred_col} -> {field}")
        
        # æœ€ç»ˆæ£€æŸ¥
        final_missing = [field for field in required_fields if field not in cleaned_data.columns]
        if final_missing:
            raise Exception(f"æ— æ³•è¯†åˆ«å¿…è¦å­—æ®µ: {final_missing}ã€‚è¯·ç¡®ä¿æ•°æ®åŒ…å«æ—¥æœŸã€äº§å“ä»£ç å’Œæ•°é‡åˆ—ã€‚")
        
        # æ·»åŠ é»˜è®¤å­—æ®µ
        if 'customer_code' not in cleaned_data.columns:
            cleaned_data['customer_code'] = 'DEFAULT_CUSTOMER'
        if 'region' not in cleaned_data.columns:
            cleaned_data['region'] = 'DEFAULT_REGION'
        
        # æ•°æ®ç±»å‹å’Œè´¨é‡æ£€æŸ¥
        cleaned_data = self._perform_data_quality_checks(cleaned_data)
        
        print(f"âœ… æ•°æ®éªŒè¯å®Œæˆï¼Œæœ€ç»ˆå­—æ®µ: {list(cleaned_data.columns)}")
        return cleaned_data
    
    def _infer_column(self, target_field, available_cols, data):
        """æ™ºèƒ½æ¨æ–­åˆ—å"""
        inference_rules = {
            'order_date': {
                'keywords': ['date', 'æ—¥æœŸ', 'time', 'æ—¶é—´'],
                'data_check': lambda x: pd.api.types.is_datetime64_any_dtype(x) or 
                                       any(str(val).count('-') >= 2 or str(val).count('/') >= 2 
                                           for val in x.dropna().head(10))
            },
            'product_code': {
                'keywords': ['product', 'sku', 'item', 'äº§å“', 'è´§å·', 'code', 'id'],
                'data_check': lambda x: x.nunique() > 1 and len(str(x.iloc[0])) <= 50
            },
            'quantity': {
                'keywords': ['qty', 'quantity', 'amount', 'volume', 'sales', 'æ•°é‡', 'é”€é‡'],
                'data_check': lambda x: pd.api.types.is_numeric_dtype(x) and x.min() >= 0
            }
        }
        
        if target_field not in inference_rules:
            return None
        
        rule = inference_rules[target_field]
        candidates = []
        
        # å…³é”®è¯åŒ¹é…
        for col in available_cols:
            col_lower = str(col).lower()
            if any(keyword in col_lower for keyword in rule['keywords']):
                candidates.append((col, 2))  # é«˜ä¼˜å…ˆçº§
        
        # æ•°æ®ç‰¹å¾åŒ¹é…
        for col in available_cols:
            if col not in [c[0] for c in candidates]:
                try:
                    if rule['data_check'](data[col]):
                        candidates.append((col, 1))  # ä½ä¼˜å…ˆçº§
                except:
                    continue
        
        # è¿”å›æœ€ä½³å€™é€‰
        if candidates:
            candidates.sort(key=lambda x: x[1], reverse=True)
            return candidates[0][0]
        
        return None
    
    def _perform_data_quality_checks(self, data):
        """æ‰§è¡Œæ•°æ®è´¨é‡æ£€æŸ¥"""
        print("ğŸ” æ•°æ®è´¨é‡æ£€æŸ¥...")
        
        original_len = len(data)
        
        # 1. æ—¥æœŸå¤„ç†
        try:
            data['order_date'] = pd.to_datetime(data['order_date'], errors='coerce')
            invalid_dates = data['order_date'].isna().sum()
            if invalid_dates > 0:
                print(f"âš ï¸ å‘ç° {invalid_dates} ä¸ªæ— æ•ˆæ—¥æœŸ")
        except Exception as e:
            raise Exception(f"æ—¥æœŸå­—æ®µå¤„ç†å¤±è´¥: {str(e)}")
        
        # 2. æ•°é‡å¤„ç†
        try:
            data['quantity'] = pd.to_numeric(data['quantity'], errors='coerce')
            invalid_qty = data['quantity'].isna().sum()
            if invalid_qty > 0:
                print(f"âš ï¸ å‘ç° {invalid_qty} ä¸ªæ— æ•ˆæ•°é‡å€¼")
        except Exception as e:
            raise Exception(f"æ•°é‡å­—æ®µå¤„ç†å¤±è´¥: {str(e)}")
        
        # 3. åŸºç¡€æ¸…æ´—
        data = data.dropna(subset=['order_date', 'product_code', 'quantity'])
        data = data[data['quantity'] > 0]
        
        # 4. æ•°æ®èŒƒå›´æ£€æŸ¥
        date_range = (data['order_date'].min(), data['order_date'].max())
        if pd.isna(date_range[0]) or pd.isna(date_range[1]):
            raise Exception("æ—¥æœŸæ•°æ®æ— æ•ˆ")
        
        days_span = (date_range[1] - date_range[0]).days
        if days_span < 30:
            print(f"âš ï¸ æ•°æ®æ—¶é—´è·¨åº¦è¾ƒçŸ­: {days_span} å¤©")
        
        # 5. äº§å“å’Œæ•°é‡æ£€æŸ¥
        unique_products = data['product_code'].nunique()
        if unique_products < 2:
            raise Exception("äº§å“ç§ç±»è¿‡å°‘ï¼Œæ— æ³•è¿›è¡Œæœ‰æ•ˆé¢„æµ‹")
        
        max_qty = data['quantity'].max()
        avg_qty = data['quantity'].mean()
        if max_qty > avg_qty * 100:  # å¼‚å¸¸å€¼æ£€æŸ¥
            print(f"âš ï¸ å‘ç°å¯èƒ½çš„å¼‚å¸¸å€¼: æœ€å¤§æ•°é‡ {max_qty} vs å¹³å‡æ•°é‡ {avg_qty:.1f}")
        
        print(f"âœ… æ•°æ®è´¨é‡æ£€æŸ¥å®Œæˆ: {original_len} â†’ {len(data)} è¡Œ")
        print(f"   æ—¶é—´è·¨åº¦: {date_range[0].strftime('%Y-%m-%d')} è‡³ {date_range[1].strftime('%Y-%m-%d')}")
        print(f"   äº§å“æ•°é‡: {unique_products}")
        print(f"   æ•°é‡èŒƒå›´: {data['quantity'].min()} - {data['quantity'].max()}")
        
        return data
    
    def preprocess_data(self, progress_callback=None):
        """æ”¹è¿›çš„æ•°æ®é¢„å¤„ç†"""
        if progress_callback:
            progress_callback(0.4, "ğŸ§¹ æ•°æ®é¢„å¤„ç†ä¸­...")
        
        print("ğŸ§¹ æ”¹è¿›æ•°æ®é¢„å¤„ç†...")
        
        # å¼‚å¸¸å€¼å¤„ç†
        original_len = len(self.shipment_data)
        self.shipment_data = self._remove_outliers_iqr(self.shipment_data, factor=st.session_state.outlier_factor)
        
        # äº§å“åˆ†æ®µ
        self._segment_products()
        
        # æ•°æ®æ‘˜è¦
        self.data_summary = {
            'total_records': len(self.shipment_data),
            'total_products': self.shipment_data['product_code'].nunique(),
            'total_customers': self.shipment_data['customer_code'].nunique(),
            'total_regions': self.shipment_data['region'].nunique(),
            'date_range': (self.shipment_data['order_date'].min(), self.shipment_data['order_date'].max()),
            'total_quantity': self.shipment_data['quantity'].sum(),
            'avg_daily_quantity': self.shipment_data.groupby('order_date')['quantity'].sum().mean(),
            'data_source': self.data_source_info,
            'outliers_removed': original_len - len(self.shipment_data),
            'data_quality_score': self._calculate_data_quality_score()
        }
        
        if progress_callback:
            progress_callback(0.5, f"âœ… é¢„å¤„ç†å®Œæˆ: {len(self.shipment_data)} è¡Œä¼˜è´¨æ•°æ®")
        
        return True
    
    def _calculate_data_quality_score(self):
        """è®¡ç®—æ•°æ®è´¨é‡è¯„åˆ†"""
        score = 100
        
        # æ—¶é—´è·¨åº¦æ£€æŸ¥
        days_span = (self.data_summary['date_range'][1] - self.data_summary['date_range'][0]).days
        if days_span < 90:
            score -= 20
        elif days_span < 180:
            score -= 10
        
        # äº§å“æ•°é‡æ£€æŸ¥
        if self.data_summary['total_products'] < 5:
            score -= 20
        elif self.data_summary['total_products'] < 10:
            score -= 10
        
        # æ•°æ®é‡æ£€æŸ¥
        if self.data_summary['total_records'] < 100:
            score -= 20
        elif self.data_summary['total_records'] < 500:
            score -= 10
        
        # å¼‚å¸¸å€¼æ¯”ä¾‹æ£€æŸ¥
        outlier_ratio = self.data_summary['outliers_removed'] / (self.data_summary['total_records'] + self.data_summary['outliers_removed'])
        if outlier_ratio > 0.2:
            score -= 15
        elif outlier_ratio > 0.1:
            score -= 5
        
        return max(0, score)
    
    def _remove_outliers_iqr(self, data, column='quantity', factor=3.0):
        """ä½¿ç”¨IQRæ–¹æ³•ç§»é™¤å¼‚å¸¸å€¼"""
        Q1 = data[column].quantile(0.25)
        Q3 = data[column].quantile(0.75)
        IQR = Q3 - Q1
        
        lower_bound = Q1 - factor * IQR
        upper_bound = Q3 + factor * IQR
        
        outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]
        data_cleaned = data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]
        
        print(f"ğŸ”§ å¼‚å¸¸å€¼å¤„ç†: {len(data)} â†’ {len(data_cleaned)} (ç§»é™¤ {len(outliers)} ä¸ªå¼‚å¸¸å€¼)")
        
        return data_cleaned
    
    def _segment_products(self):
        """äº§å“åˆ†æ®µ"""
        print("ğŸ“Š äº§å“åˆ†æ®µåˆ†æ...")
        
        product_stats = self.shipment_data.groupby('product_code')['quantity'].agg([
            'count', 'mean', 'std', 'min', 'max', 'sum'
        ]).reset_index()
        
        product_stats['cv'] = product_stats['std'] / product_stats['mean']
        product_stats['cv'] = product_stats['cv'].fillna(0)
        
        # æ”¹è¿›çš„åˆ†æ®µé€»è¾‘
        volume_high = product_stats['mean'].quantile(0.67)
        volume_low = product_stats['mean'].quantile(0.33)
        cv_high = product_stats['cv'].quantile(0.67)
        
        def classify_product(row):
            if row['mean'] >= volume_high:
                return 'é«˜é”€é‡ç¨³å®š' if row['cv'] <= cv_high else 'é«˜é”€é‡æ³¢åŠ¨'
            elif row['mean'] >= volume_low:
                return 'ä¸­é”€é‡ç¨³å®š' if row['cv'] <= cv_high else 'ä¸­é”€é‡æ³¢åŠ¨'
            else:
                return 'ä½é”€é‡ç¨³å®š' if row['cv'] <= cv_high else 'ä½é”€é‡æ³¢åŠ¨'
        
        product_stats['segment'] = product_stats.apply(classify_product, axis=1)
        self.product_segments = dict(zip(product_stats['product_code'], product_stats['segment']))
        
        segment_counts = product_stats['segment'].value_counts()
        print("ğŸ“Š äº§å“åˆ†æ®µç»“æœ:")
        for segment, count in segment_counts.items():
            print(f"   {segment}: {count} ä¸ªäº§å“")
        
        return product_stats
    
    def create_advanced_features(self, progress_callback=None):
        """æ”¹è¿›çš„ç‰¹å¾å·¥ç¨‹ - ä¸¥æ ¼æ—¶é—´åºåˆ—å¤„ç†"""
        if progress_callback:
            progress_callback(0.6, "ğŸ”§ ä¸¥æ ¼æ—¶é—´åºåˆ—ç‰¹å¾å·¥ç¨‹...")
        
        print("ğŸ”§ ä¸¥æ ¼æ—¶é—´åºåˆ—ç‰¹å¾å·¥ç¨‹...")
        
        # åˆ›å»ºæœˆåº¦æ•°æ®
        monthly_data = self.shipment_data.groupby([
            'product_code',
            self.shipment_data['order_date'].dt.to_period('M')
        ]).agg({
            'quantity': ['sum', 'count', 'mean', 'std'],
            'customer_code': 'nunique',
            'region': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.iloc[0]
        }).reset_index()
        
        monthly_data.columns = ['product_code', 'year_month', 'total_qty', 'order_count',
                               'avg_qty', 'std_qty', 'customer_count', 'main_region']
        monthly_data['std_qty'] = monthly_data['std_qty'].fillna(0)
        monthly_data = monthly_data.sort_values(['product_code', 'year_month'])
        
        print(f"ğŸ“Š æœˆåº¦æ•°æ®: {len(monthly_data)} è¡Œ")
        
        # ä¸¥æ ¼çš„æ—¶é—´åºåˆ—ç‰¹å¾åˆ›å»º
        all_features = []
        
        for product in self.product_segments.keys():
            product_data = monthly_data[monthly_data['product_code'] == product].copy()
            
            if len(product_data) < st.session_state.min_data_points:
                continue
            
            # ä¸¥æ ¼æŒ‰æ—¶é—´é¡ºåºåˆ›å»ºç‰¹å¾ï¼Œç¡®ä¿ä¸ä½¿ç”¨æœªæ¥ä¿¡æ¯
            for idx in range(3, len(product_data)):
                # åªä½¿ç”¨idxä¹‹å‰çš„å†å²æ•°æ®
                historical_data = product_data.iloc[:idx].copy()
                
                features = self._create_time_series_features(
                    product, historical_data, self.product_segments[product]
                )
                
                # ç›®æ ‡å˜é‡
                target_row = product_data.iloc[idx]
                features['target'] = target_row['total_qty']
                features['target_month'] = str(target_row['year_month'])
                features['segment'] = self.product_segments[product]
                
                all_features.append(features)
        
        self.feature_data = pd.DataFrame(all_features)
        
        if len(self.feature_data) == 0:
            raise Exception("æ— æ³•åˆ›å»ºç‰¹å¾æ•°æ®ï¼Œè¯·æ£€æŸ¥æ•°æ®è´¨é‡å’Œå®Œæ•´æ€§")
        
        # ç‰¹å¾åå¤„ç†
        self._post_process_features()
        
        print(f"âœ… æ—¶é—´åºåˆ—ç‰¹å¾: {len(self.feature_data)} æ ·æœ¬, {len(self.feature_data.columns) - 4} ä¸ªç‰¹å¾")
        
        if progress_callback:
            progress_callback(0.65, f"âœ… ç‰¹å¾å®Œæˆ: {len(self.feature_data)} æ—¶é—´åºåˆ—æ ·æœ¬")
        
        return True
    
    def _create_time_series_features(self, product_code, historical_data, segment):
        """åˆ›å»ºä¸¥æ ¼çš„æ—¶é—´åºåˆ—ç‰¹å¾ - æ— æœªæ¥ä¿¡æ¯æ³„éœ²"""
        features = {'product_code': product_code}
        
        if len(historical_data) < 3:
            return features
        
        qty_values = historical_data['total_qty'].values
        
        # 1. åŸºç¡€ç»Ÿè®¡ç‰¹å¾
        features.update({
            'qty_mean': np.mean(qty_values),
            'qty_median': np.median(qty_values),
            'qty_std': np.std(qty_values),
            'qty_cv': np.std(qty_values) / (np.mean(qty_values) + 1),
            
            # æ»åç‰¹å¾
            'qty_lag_1': qty_values[-1],
            'qty_lag_2': qty_values[-2] if len(qty_values) > 1 else 0,
            'qty_lag_3': qty_values[-3] if len(qty_values) > 2 else 0,
            
            # ç§»åŠ¨å¹³å‡ï¼ˆåªä½¿ç”¨å†å²æ•°æ®ï¼‰
            'qty_ma_2': np.mean(qty_values[-2:]),
            'qty_ma_3': np.mean(qty_values[-3:]) if len(qty_values) >= 3 else np.mean(qty_values),
        })
        
        # 2. è¶‹åŠ¿ç‰¹å¾ï¼ˆåŸºäºå†å²æ•°æ®ï¼‰
        if len(qty_values) > 2:
            # çº¿æ€§è¶‹åŠ¿
            x = np.arange(len(qty_values))
            trend_coef = np.polyfit(x, qty_values, 1)[0]
            features['trend_slope'] = trend_coef
            
            # æœ€è¿‘å¢é•¿ç‡
            recent_growth = (qty_values[-1] - qty_values[-2]) / (qty_values[-2] + 1)
            features['recent_growth'] = recent_growth
            
            # ç¨³å®šæ€§æŒ‡æ ‡
            features['stability_score'] = 1 / (1 + features['qty_cv'])
        else:
            features.update({
                'trend_slope': 0,
                'recent_growth': 0,
                'stability_score': 0.5
            })
        
        # 3. æ—¶é—´ç‰¹å¾
        last_period = historical_data.iloc[-1]['year_month']
        features.update({
            'month': last_period.month,
            'quarter': last_period.quarter,
            'is_year_end': 1 if last_period.month in [11, 12] else 0,
            'is_peak_season': 1 if last_period.month in [3, 4, 10, 11] else 0,
        })
        
        # 4. äº§å“æ®µç‰¹å¾
        segment_map = {
            'é«˜é”€é‡ç¨³å®š': 1, 'é«˜é”€é‡æ³¢åŠ¨': 2, 'ä¸­é”€é‡ç¨³å®š': 3,
            'ä¸­é”€é‡æ³¢åŠ¨': 4, 'ä½é”€é‡ç¨³å®š': 5, 'ä½é”€é‡æ³¢åŠ¨': 6
        }
        features['segment_encoded'] = segment_map.get(segment, 0)
        
        # 5. æ•°æ®è´¨é‡ç‰¹å¾
        features.update({
            'data_points': len(qty_values),
            'consistency_score': len(qty_values[qty_values > 0]) / len(qty_values)
        })
        
        return features
    
    def _post_process_features(self):
        """ç‰¹å¾åå¤„ç†"""
        print("ğŸ”§ ç‰¹å¾åå¤„ç†...")
        
        feature_cols = [col for col in self.feature_data.columns 
                       if col not in ['product_code', 'target', 'target_month', 'segment']]
        
        # å¤„ç†å¼‚å¸¸å€¼
        self.feature_data[feature_cols] = self.feature_data[feature_cols].replace([np.inf, -np.inf], np.nan)
        self.feature_data[feature_cols] = self.feature_data[feature_cols].fillna(0)
        
        # ç§»é™¤å¸¸æ•°ç‰¹å¾
        constant_features = [col for col in feature_cols if self.feature_data[col].std() == 0]
        if constant_features:
            print(f"  ç§»é™¤å¸¸æ•°ç‰¹å¾: {constant_features}")
            self.feature_data = self.feature_data.drop(columns=constant_features)
        
        print(f"âœ… æœ€ç»ˆç‰¹å¾æ•°: {len([col for col in self.feature_data.columns if col not in ['product_code', 'target', 'target_month', 'segment']])}")
    
    def train_models_with_strict_validation(self, progress_callback=None):
        """ä¸¥æ ¼æ—¶é—´åºåˆ—éªŒè¯çš„æ¨¡å‹è®­ç»ƒ"""
        if progress_callback:
            progress_callback(0.7, "ğŸš€ ä¸¥æ ¼æ—¶é—´åºåˆ—æ¨¡å‹è®­ç»ƒ...")
        
        print("ğŸš€ ä¸¥æ ¼æ—¶é—´åºåˆ—æ¨¡å‹è®­ç»ƒ...")
        start_time = time.time()
        
        # å‡†å¤‡æ•°æ®
        feature_cols = [col for col in self.feature_data.columns 
                       if col not in ['product_code', 'target', 'target_month', 'segment']]
        
        X = self.feature_data[feature_cols]
        y = self.feature_data['target']
        
        # ä¸¥æ ¼çš„æ—¶é—´åºåˆ—åˆ†å‰²
        # æŒ‰target_monthæ’åºï¼Œç¡®ä¿æ—¶é—´é¡ºåº
        self.feature_data['target_month_dt'] = pd.to_datetime(self.feature_data['target_month'])
        sorted_indices = self.feature_data.sort_values('target_month_dt').index
        
        X = X.loc[sorted_indices]
        y = y.loc[sorted_indices]
        
        # æ—¶é—´åˆ†å‰²ç‚¹
        n_samples = len(X)
        split_point = int(n_samples * (1 - st.session_state.test_ratio))
        
        X_train, X_test = X.iloc[:split_point], X.iloc[split_point:]
        y_train, y_test = y.iloc[:split_point], y.iloc[split_point:]
        
        print(f"ğŸ“Š ä¸¥æ ¼æ—¶é—´åˆ†å‰²:")
        print(f"   è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬")
        print(f"   æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬")
        
        # ç‰¹å¾ç¼©æ”¾
        scaler = RobustScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        self.scalers['feature_scaler'] = scaler
        
        # è®­ç»ƒæ¨¡å‹
        models = {}
        predictions = {}
        
        # XGBoost
        if progress_callback:
            progress_callback(0.75, "ğŸ¯ è®­ç»ƒXGBoost...")
        
        xgb_model = xgb.XGBRegressor(
            n_estimators=st.session_state.n_estimators,
            max_depth=st.session_state.max_depth,
            learning_rate=st.session_state.learning_rate,
            subsample=0.8,
            colsample_bytree=0.8,
            reg_alpha=0.1,
            reg_lambda=0.1,
            random_state=42,
            n_jobs=-1
        )
        
        xgb_model.fit(X_train_scaled, y_train, verbose=False)
        xgb_pred = np.maximum(xgb_model.predict(X_test_scaled), 0)
        
        models['XGBoost'] = xgb_model
        predictions['XGBoost'] = xgb_pred
        
        # LightGBM
        if progress_callback:
            progress_callback(0.85, "ğŸ¯ è®­ç»ƒLightGBM...")
        
        lgb_model = lgb.LGBMRegressor(
            n_estimators=st.session_state.n_estimators,
            max_depth=st.session_state.max_depth,
            learning_rate=st.session_state.learning_rate,
            subsample=0.8,
            colsample_bytree=0.8,
            reg_alpha=0.1,
            reg_lambda=0.1,
            random_state=42,
            n_jobs=-1,
            verbose=-1
        )
        
        lgb_model.fit(X_train_scaled, y_train)
        lgb_pred = np.maximum(lgb_model.predict(X_test_scaled), 0)
        
        models['LightGBM'] = lgb_model
        predictions['LightGBM'] = lgb_pred
        
        # Random Forest
        if progress_callback:
            progress_callback(0.9, "ğŸ¯ è®­ç»ƒRandom Forest...")
        
        rf_model = RandomForestRegressor(
            n_estimators=int(st.session_state.n_estimators * 0.7),
            max_depth=st.session_state.max_depth + 5,
            min_samples_split=5,
            min_samples_leaf=2,
            random_state=42,
            n_jobs=-1
        )
        
        rf_model.fit(X_train_scaled, y_train)
        rf_pred = np.maximum(rf_model.predict(X_test_scaled), 0)
        
        models['RandomForest'] = rf_model
        predictions['RandomForest'] = rf_pred
        
        # æ¨¡å‹èåˆ
        weights = self._calculate_model_weights(predictions, y_test)
        ensemble_pred = (weights['XGBoost'] * predictions['XGBoost'] + 
                        weights['LightGBM'] * predictions['LightGBM'] + 
                        weights['RandomForest'] * predictions['RandomForest'])
        
        predictions['Ensemble'] = ensemble_pred
        
        # æ¨¡å‹è¯„ä¼°
        results = {}
        for model_name, pred in predictions.items():
            smape_accuracies = self.calculate_batch_robust_accuracy(y_test.values, pred)
            smape_accuracy = np.mean(smape_accuracies)
            
            mae = np.mean(np.abs(y_test - pred))
            rmse = np.sqrt(mean_squared_error(y_test, pred))
            r2 = r2_score(y_test, pred)
            
            results[model_name] = {
                'SMAPE_Accuracy': smape_accuracy,
                'MAE': mae,
                'RMSE': rmse,
                'RÂ²': r2
            }
        
        # é€‰æ‹©æœ€ä½³æ¨¡å‹
        best_model_name = max(results.keys(), key=lambda x: results[x]['SMAPE_Accuracy'])
        
        self.models = {
            'best_model': models[best_model_name],
            'best_model_name': best_model_name,
            'all_models': models,
            'feature_cols': feature_cols,
            'weights': weights if best_model_name == 'Ensemble' else None
        }
        
        self.accuracy_results = results
        self.training_time = time.time() - start_time
        
        if progress_callback:
            best_accuracy = results[best_model_name]['SMAPE_Accuracy']
            progress_callback(1.0, f"âœ… è®­ç»ƒå®Œæˆ! {best_model_name}: {best_accuracy:.1f}%")
        
        print(f"ğŸ† æœ€ä½³æ¨¡å‹: {best_model_name} (SMAPEå‡†ç¡®ç‡: {results[best_model_name]['SMAPE_Accuracy']:.1f}%)")
        
        return True
    
    def calculate_batch_robust_accuracy(self, actual_values, predicted_values):
        """æ‰¹é‡è®¡ç®—SMAPEå‡†ç¡®ç‡"""
        actual_values = np.array(actual_values)
        predicted_values = np.array(predicted_values)
        
        both_zero = (actual_values == 0) & (predicted_values == 0)
        
        smape = 200 * np.abs(actual_values - predicted_values) / (
            np.abs(actual_values) + np.abs(predicted_values) + 1e-8
        )
        accuracy = np.maximum(0, 100 - smape)
        accuracy[both_zero] = 100.0
        
        return accuracy
    
    def _calculate_model_weights(self, predictions, y_true):
        """è®¡ç®—æ¨¡å‹èåˆæƒé‡"""
        scores = {}
        for name, pred in predictions.items():
            smape_accuracies = self.calculate_batch_robust_accuracy(y_true.values, pred)
            scores[name] = np.mean(smape_accuracies)
        
        total_score = sum(scores.values())
        if total_score > 0:
            weights = {name: score / total_score for name, score in scores.items()}
        else:
            weights = {name: 1/len(scores) for name in scores.keys()}
        
        return weights
    
    def predict_future_with_tracking(self, months_ahead=None):
        """é¢„æµ‹æœªæ¥å¹¶åŠ å…¥è·Ÿè¸ªç³»ç»Ÿ"""
        if months_ahead is None:
            months_ahead = st.session_state.months_ahead
        
        print(f"ğŸ”® é¢„æµ‹æœªæ¥{months_ahead}ä¸ªæœˆå¹¶å¯ç”¨è·Ÿè¸ª...")
        
        predictions = []
        products = self.feature_data['product_code'].unique()
        
        for product in products:
            product_features = self.feature_data[
                self.feature_data['product_code'] == product
            ].tail(1)
            
            if len(product_features) == 0:
                continue
            
            for month in range(1, months_ahead + 1):
                X = product_features[self.models['feature_cols']]
                X_scaled = self.scalers['feature_scaler'].transform(X)
                
                # é¢„æµ‹
                if self.models['best_model_name'] == 'Ensemble':
                    xgb_pred = self.models['all_models']['XGBoost'].predict(X_scaled)[0]
                    lgb_pred = self.models['all_models']['LightGBM'].predict(X_scaled)[0]
                    rf_pred = self.models['all_models']['RandomForest'].predict(X_scaled)[0]
                    
                    weights = self.models['weights']
                    final_pred = (weights['XGBoost'] * xgb_pred + 
                                 weights['LightGBM'] * lgb_pred + 
                                 weights['RandomForest'] * rf_pred)
                else:
                    final_pred = self.models['best_model'].predict(X_scaled)[0]
                
                final_pred = max(0, final_pred)
                
                # ç½®ä¿¡åŒºé—´
                segment = product_features['segment'].iloc[0]
                confidence_factor = self._get_confidence_factor(segment)
                lower_bound = max(0, final_pred * (1 - confidence_factor))
                upper_bound = final_pred * (1 + confidence_factor)
                
                # ä¿å­˜åˆ°è·Ÿè¸ªç³»ç»Ÿ
                target_month = datetime.now().replace(day=1) + timedelta(days=32*month)
                target_month_str = target_month.strftime('%Y-%m')
                
                self.prediction_tracker.save_prediction(
                    product_code=product,
                    target_month=target_month_str,
                    predicted_value=final_pred,
                    confidence_interval=(lower_bound, upper_bound),
                    model_used=self.models['best_model_name']
                )
                
                predictions.append({
                    'äº§å“ä»£ç ': product,
                    'æœªæ¥æœˆä»½': month,
                    'ç›®æ ‡æœˆä»½': target_month_str,
                    'é¢„æµ‹é”€é‡': round(final_pred, 2),
                    'ä¸‹é™': round(lower_bound, 2),
                    'ä¸Šé™': round(upper_bound, 2),
                    'ç½®ä¿¡åº¦': confidence_factor,
                    'äº§å“æ®µ': segment,
                    'ä½¿ç”¨æ¨¡å‹': self.models['best_model_name']
                })
        
        self.predictions = pd.DataFrame(predictions)
        print(f"âœ… å®Œæˆ {len(products)} ä¸ªäº§å“çš„é¢„æµ‹å’Œè·Ÿè¸ªè®¾ç½®")
        
        return self.predictions
    
    def _get_confidence_factor(self, segment):
        """è·å–ç½®ä¿¡åº¦å› å­"""
        confidence_map = {
            'é«˜é”€é‡ç¨³å®š': 0.15,
            'é«˜é”€é‡æ³¢åŠ¨': 0.25,
            'ä¸­é”€é‡ç¨³å®š': 0.20,
            'ä¸­é”€é‡æ³¢åŠ¨': 0.30,
            'ä½é”€é‡ç¨³å®š': 0.25,
            'ä½é”€é‡æ³¢åŠ¨': 0.35
        }
        return confidence_map.get(segment, 0.25)

# ====================================================================
# ä¿®å¤ç‰ˆç•Œé¢å‡½æ•°
# ====================================================================

def render_header():
    """æ¸²æŸ“ä¿®å¤ç‰ˆå¤´éƒ¨"""
    st.markdown(f"""
    <div class="prediction-header">
        <h1 class="prediction-title">ğŸš€ ä¿®å¤ç‰ˆé”€å”®é¢„æµ‹ç³»ç»Ÿ</h1>
        <p class="prediction-subtitle">
            è§£å†³è‡´å‘½é—®é¢˜ Â· çœŸå®æ•°æ®ä¸Šä¼  Â· é¢„æµ‹è·Ÿè¸ªéªŒè¯ Â· ä¸¥æ ¼æ—¶é—´åºåˆ—å¤„ç†
        </p>
        <div style="display: flex; justify-content: center; gap: 1rem; flex-wrap: wrap; margin-top: 1rem;">
            <span style="background: linear-gradient(135deg, #4CAF50 0%, #45a049 100%); color: white; padding: 0.5rem 1rem; border-radius: 20px;">âœ… ä¿®å¤æ•°æ®æº</span>
            <span style="background: linear-gradient(135deg, #FF9800 0%, #F57C00 100%); color: white; padding: 0.5rem 1rem; border-radius: 20px;">â° ä¸¥æ ¼æ—¶åº</span>
            <span style="background: linear-gradient(135deg, #2196F3 0%, #1976D2 100%); color: white; padding: 0.5rem 1rem; border-radius: 20px;">ğŸ“Š é¢„æµ‹è·Ÿè¸ª</span>
            <span style="background: linear-gradient(135deg, #9C27B0 0%, #7B1FA2 100%); color: white; padding: 0.5rem 1rem; border-radius: 20px;">ğŸ¯ å‡†ç¡®éªŒè¯</span>
        </div>
        <div style="margin-top: 1rem; font-size: 0.9rem; color: #666;">
            ç‰ˆæœ¬: v2.2 Fixed & Enhanced | ä¿®å¤æ—¥æœŸ: {datetime.now().strftime('%Y-%m-%d')} | çŠ¶æ€: ç”Ÿäº§å°±ç»ª
        </div>
    </div>
    """, unsafe_allow_html=True)

def show_data_upload_tab():
    """æ•°æ®ä¸Šä¼ æ ‡ç­¾é¡µ"""
    st.markdown("### ğŸ“ æ•°æ®ä¸Šä¼ ä¸éªŒè¯")
    
    # æ•°æ®ä¸Šä¼ åŒºåŸŸ
    st.markdown("""
    <div class="upload-section">
        <h3>ğŸ“‚ ä¸Šä¼ é”€å”®æ•°æ®æ–‡ä»¶</h3>
        <p>æ”¯æŒCSVå’ŒExcelæ ¼å¼ï¼Œè¯·ç¡®ä¿åŒ…å«ä»¥ä¸‹å­—æ®µï¼š</p>
        <ul style="text-align: left; display: inline-block;">
            <li><strong>æ—¥æœŸå­—æ®µ</strong>: è®¢å•æ—¥æœŸ/å‡ºè´§æ—¥æœŸ (å¿…éœ€)</li>
            <li><strong>äº§å“å­—æ®µ</strong>: äº§å“ä»£ç /äº§å“ID (å¿…éœ€)</li>
            <li><strong>æ•°é‡å­—æ®µ</strong>: é”€é‡/å‡ºè´§é‡ (å¿…éœ€)</li>
            <li><strong>å¯é€‰å­—æ®µ</strong>: å®¢æˆ·ä»£ç ã€åŒºåŸŸç­‰</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)
    
    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader(
        "é€‰æ‹©é”€å”®æ•°æ®æ–‡ä»¶",
        type=['csv', 'xlsx', 'xls'],
        help="æ”¯æŒCSVå’ŒExcelæ ¼å¼ï¼Œå»ºè®®æ•°æ®åŒ…å«è‡³å°‘3ä¸ªæœˆçš„å†å²é”€å”®è®°å½•"
    )
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        if uploaded_file is not None:
            if st.button("ğŸ” éªŒè¯æ•°æ®", type="primary", use_container_width=True):
                try:
                    with st.spinner("æ­£åœ¨éªŒè¯æ•°æ®..."):
                        # åˆå§‹åŒ–ç³»ç»Ÿ
                        system = FixedSalesPredictionSystem()
                        
                        # åŠ è½½å’ŒéªŒè¯æ•°æ®
                        success = system.load_data_from_upload(uploaded_file)
                        
                        if success:
                            # é¢„å¤„ç†
                            system.preprocess_data()
                            
                            # ä¿å­˜åˆ°session state
                            st.session_state.uploaded_data = system
                            st.session_state.data_validation_passed = True
                            
                            # æ˜¾ç¤ºæ•°æ®æ‘˜è¦
                            st.success("âœ… æ•°æ®éªŒè¯æˆåŠŸï¼")
                            
                            summary = system.data_summary
                            
                            st.markdown(f"""
                            <div class="success-card">
                                <h4>ğŸ“Š æ•°æ®æ‘˜è¦</h4>
                                <p><strong>æ–‡ä»¶å:</strong> {summary['data_source']['file_name']}</p>
                                <p><strong>æ•°æ®è®°å½•:</strong> {summary['total_records']:,} æ¡</p>
                                <p><strong>äº§å“æ•°é‡:</strong> {summary['total_products']} ä¸ª</p>
                                <p><strong>æ—¶é—´è·¨åº¦:</strong> {summary['date_range'][0].strftime('%Y-%m-%d')} è‡³ {summary['date_range'][1].strftime('%Y-%m-%d')}</p>
                                <p><strong>æ€»é”€é‡:</strong> {summary['total_quantity']:,.0f} ç®±</p>
                                <p><strong>æ•°æ®è´¨é‡:</strong> {summary['data_quality_score']}/100</p>
                                <p><strong>å¼‚å¸¸å€¼ç§»é™¤:</strong> {summary['outliers_removed']} æ¡</p>
                            </div>
                            """, unsafe_allow_html=True)
                            
                            # æ•°æ®é¢„è§ˆ
                            st.markdown("##### ğŸ“‹ æ•°æ®é¢„è§ˆ")
                            st.dataframe(system.shipment_data.head(10), use_container_width=True)
                            
                except Exception as e:
                    st.error(f"âŒ æ•°æ®éªŒè¯å¤±è´¥: {str(e)}")
                    st.markdown(f"""
                    <div class="error-card">
                        <h4>ğŸ’¡ æ•°æ®æ ¼å¼å»ºè®®</h4>
                        <p>è¯·ç¡®ä¿æ‚¨çš„æ•°æ®æ–‡ä»¶åŒ…å«ä»¥ä¸‹åˆ—:</p>
                        <ul>
                            <li>æ—¥æœŸåˆ—: å¦‚"è®¢å•æ—¥æœŸ"ã€"date"ã€"å‡ºè´§æ—¥æœŸ"ç­‰</li>
                            <li>äº§å“åˆ—: å¦‚"äº§å“ä»£ç "ã€"product_code"ã€"SKU"ç­‰</li>
                            <li>æ•°é‡åˆ—: å¦‚"é”€é‡"ã€"quantity"ã€"æ•°é‡"ç­‰</li>
                        </ul>
                        <p>ç³»ç»Ÿä¼šè‡ªåŠ¨è¯†åˆ«ä¸­è‹±æ–‡åˆ—åï¼Œä½†è¯·ç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®ã€‚</p>
                    </div>
                    """, unsafe_allow_html=True)
        else:
            st.info("è¯·å…ˆä¸Šä¼ é”€å”®æ•°æ®æ–‡ä»¶")
    
    with col2:
        st.markdown("#### ğŸ“‹ æ•°æ®è¦æ±‚")
        
        requirements = """
        <div class="feature-card">
            <h4>âœ… æ•°æ®è´¨é‡è¦æ±‚</h4>
            <ul>
                <li><strong>æ—¶é—´è·¨åº¦:</strong> è‡³å°‘3ä¸ªæœˆæ•°æ®</li>
                <li><strong>äº§å“æ•°é‡:</strong> è‡³å°‘5ä¸ªäº§å“</li>
                <li><strong>æ•°æ®é‡:</strong> å»ºè®®100æ¡ä»¥ä¸Š</li>
                <li><strong>æ•°æ®æ ¼å¼:</strong> CSVæˆ–Excel</li>
                <li><strong>å¿…éœ€å­—æ®µ:</strong> æ—¥æœŸã€äº§å“ã€æ•°é‡</li>
            </ul>
            
            <h4>ğŸ”§ è‡ªåŠ¨å¤„ç†åŠŸèƒ½</h4>
            <ul>
                <li>æ™ºèƒ½åˆ—åè¯†åˆ«</li>
                <li>å¼‚å¸¸å€¼è‡ªåŠ¨æ¸…ç†</li>
                <li>æ•°æ®è´¨é‡è¯„ä¼°</li>
                <li>ç¼ºå¤±å€¼å¤„ç†</li>
                <li>äº§å“è‡ªåŠ¨åˆ†æ®µ</li>
            </ul>
        </div>
        """
        
        st.markdown(requirements, unsafe_allow_html=True)
        
        # ç¤ºä¾‹æ•°æ®æ ¼å¼
        st.markdown("#### ğŸ“ ç¤ºä¾‹æ•°æ®æ ¼å¼")
        
        example_data = pd.DataFrame({
            'è®¢å•æ—¥æœŸ': ['2024-01-15', '2024-01-16', '2024-01-17'],
            'äº§å“ä»£ç ': ['P001', 'P002', 'P001'],
            'é”€é‡': [150, 80, 200],
            'å®¢æˆ·ä»£ç ': ['C001', 'C002', 'C001'],
            'åŒºåŸŸ': ['åä¸œ', 'åå—', 'åä¸œ']
        })
        
        st.dataframe(example_data, use_container_width=True, hide_index=True)

def show_fixed_training_tab():
    """ä¿®å¤ç‰ˆè®­ç»ƒæ ‡ç­¾é¡µ"""
    st.markdown("### ğŸš€ ä¿®å¤ç‰ˆæ¨¡å‹è®­ç»ƒ")
    
    if not st.session_state.data_validation_passed:
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ å¹¶éªŒè¯æ•°æ®")
        return
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("#### ğŸ¯ ä¸¥æ ¼æ—¶é—´åºåˆ—è®­ç»ƒ")
        
        # ä¿®å¤è¯´æ˜
        st.markdown("""
        <div class="feature-card">
            <h4>ğŸ”§ å…³é”®ä¿®å¤å†…å®¹</h4>
            <ul>
                <li>âœ… <strong>æ•°æ®æºä¿®å¤:</strong> æ”¹ä¸ºæœ¬åœ°æ–‡ä»¶ä¸Šä¼ ï¼Œè§£å†³GitHubä¸å­˜åœ¨é—®é¢˜</li>
                <li>â° <strong>ä¸¥æ ¼æ—¶åº:</strong> é˜²æ­¢æ•°æ®æ³„éœ²ï¼Œç¡®ä¿åªä½¿ç”¨å†å²ä¿¡æ¯</li>
                <li>ğŸ“Š <strong>é¢„æµ‹è·Ÿè¸ª:</strong> æ–°å¢é¢„æµ‹éªŒè¯ç³»ç»Ÿï¼Œè·Ÿè¸ªçœŸå®å‡†ç¡®ç‡</li>
                <li>ğŸ¯ <strong>å‡†ç¡®ç‡æ”¹è¿›:</strong> ä¼˜åŒ–SMAPEè®¡ç®—ï¼Œæå‡è¯„ä¼°å¯é æ€§</li>
                <li>ğŸ›¡ï¸ <strong>é”™è¯¯å¤„ç†:</strong> å®Œå–„çš„æ•°æ®éªŒè¯å’Œå¼‚å¸¸å¤„ç†æœºåˆ¶</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
        
        # è®­ç»ƒæŒ‰é’®
        if st.button("ğŸš€ å¼€å§‹ä¸¥æ ¼è®­ç»ƒ", type="primary", use_container_width=True):
            try:
                system = st.session_state.uploaded_data
                
                with st.container():
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    def update_progress(progress, message):
                        progress_bar.progress(progress)
                        status_text.text(message)
                    
                    # ç‰¹å¾å·¥ç¨‹
                    if system.create_advanced_features(update_progress):
                        # ä¸¥æ ¼æ¨¡å‹è®­ç»ƒ
                        if system.train_models_with_strict_validation(update_progress):
                            # é¢„æµ‹æœªæ¥
                            system.predict_future_with_tracking()
                            
                            # ä¿å­˜ç³»ç»Ÿ
                            st.session_state.prediction_system = system
                            st.session_state.model_trained = True
                            st.session_state.prediction_tracker = system.prediction_tracker
                            
                            progress_bar.empty()
                            status_text.empty()
                            
                            st.success("ğŸ‰ ä¿®å¤ç‰ˆæ¨¡å‹è®­ç»ƒå®Œæˆï¼")
                            st.balloons()
                            st.rerun()
                
            except Exception as e:
                st.error(f"âŒ è®­ç»ƒå¤±è´¥: {str(e)}")
    
    with col2:
        if st.session_state.model_trained and st.session_state.prediction_system:
            system = st.session_state.prediction_system
            
            st.markdown("#### ğŸ† è®­ç»ƒç»“æœ")
            
            best_model = system.models['best_model_name']
            best_accuracy = system.accuracy_results[best_model]['SMAPE_Accuracy']
            
            # å‡†ç¡®ç‡å¡ç‰‡
            st.markdown(f"""
            <div class="metric-card">
                <div class="metric-value">{best_accuracy:.1f}%</div>
                <div class="metric-label">SMAPEå‡†ç¡®ç‡</div>
            </div>
            """, unsafe_allow_html=True)
            
            # è®­ç»ƒæ‘˜è¦
            st.markdown(f"""
            <div class="feature-card">
                <h4>âœ… è®­ç»ƒå®Œæˆ</h4>
                <p><strong>æœ€ä½³æ¨¡å‹:</strong> {best_model}</p>
                <p><strong>è®­ç»ƒæ—¶é—´:</strong> {system.training_time:.1f}ç§’</p>
                <p><strong>ç‰¹å¾æ•°:</strong> {len(system.models['feature_cols'])}</p>
                <p><strong>è®­ç»ƒæ ·æœ¬:</strong> {len(system.feature_data)}</p>
                <p><strong>æ•°æ®è´¨é‡:</strong> {system.data_summary['data_quality_score']}/100</p>
                <p><strong>é¢„æµ‹è·Ÿè¸ª:</strong> å·²å¯ç”¨</p>
            </div>
            """, unsafe_allow_html=True)
            
            # æ¨¡å‹å¯¹æ¯”
            st.markdown("#### ğŸ“Š æ¨¡å‹å¯¹æ¯”")
            comparison_data = []
            for model_name, results in system.accuracy_results.items():
                comparison_data.append({
                    'æ¨¡å‹': model_name,
                    'SMAPEå‡†ç¡®ç‡': f"{results['SMAPE_Accuracy']:.1f}%",
                    'MAE': f"{results['MAE']:.1f}",
                    'RÂ²': f"{results['RÂ²']:.3f}"
                })
            
            comparison_df = pd.DataFrame(comparison_data)
            st.dataframe(comparison_df, use_container_width=True, hide_index=True)
        
        else:
            system = st.session_state.uploaded_data
            summary = system.data_summary
            
            st.markdown("#### ğŸ“Š æ•°æ®å‡†å¤‡å°±ç»ª")
            st.markdown(f"""
            <div class="feature-card">
                <h4>ğŸ¯ è®­ç»ƒå‡†å¤‡</h4>
                <p><strong>æ•°æ®æ–‡ä»¶:</strong> {summary['data_source']['file_name']}</p>
                <p><strong>è®°å½•æ•°:</strong> {summary['total_records']:,}</p>
                <p><strong>äº§å“æ•°:</strong> {summary['total_products']}</p>
                <p><strong>è´¨é‡è¯„åˆ†:</strong> {summary['data_quality_score']}/100</p>
                <p><strong>æ—¶é—´è·¨åº¦:</strong> {(summary['date_range'][1] - summary['date_range'][0]).days} å¤©</p>
                
                <h5>ğŸ”§ è®­ç»ƒç‰¹ç‚¹:</h5>
                <ul>
                    <li>ä¸¥æ ¼æ—¶é—´åºåˆ—åˆ†å‰²</li>
                    <li>å¤šæ¨¡å‹èåˆä¼˜åŒ–</li>
                    <li>SMAPEå‡†ç¡®ç‡è¯„ä¼°</li>
                    <li>é¢„æµ‹è·Ÿè¸ªå¯ç”¨</li>
                </ul>
            </div>
            """, unsafe_allow_html=True)

def show_prediction_tracking_tab():
    """é¢„æµ‹è·Ÿè¸ªæ ‡ç­¾é¡µ"""
    st.markdown("### ğŸ“Š é¢„æµ‹è·Ÿè¸ªä¸éªŒè¯")
    
    if not st.session_state.model_trained:
        st.warning("âš ï¸ è¯·å…ˆå®Œæˆæ¨¡å‹è®­ç»ƒ")
        return
    
    system = st.session_state.prediction_system
    tracker = system.prediction_tracker
    
    # æœªæ¥é¢„æµ‹å±•ç¤º
    st.markdown("#### ğŸ”® æœªæ¥é¢„æµ‹ (å·²å¯ç”¨è·Ÿè¸ª)")
    
    if system.predictions is not None:
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # é¢„æµ‹æ±‡æ€»å›¾
            monthly_summary = system.predictions.groupby('æœªæ¥æœˆä»½').agg({
                'é¢„æµ‹é”€é‡': 'sum',
                'ä¸‹é™': 'sum',
                'ä¸Šé™': 'sum'
            }).reset_index()
            
            fig = go.Figure()
            fig.add_trace(go.Bar(
                x=[f"ç¬¬{m}ä¸ªæœˆ" for m in monthly_summary['æœªæ¥æœˆä»½']],
                y=monthly_summary['é¢„æµ‹é”€é‡'],
                name='é¢„æµ‹é”€é‡',
                marker_color='#667eea'
            ))
            
            fig.add_trace(go.Scatter(
                x=[f"ç¬¬{m}ä¸ªæœˆ" for m in monthly_summary['æœªæ¥æœˆä»½']],
                y=monthly_summary['ä¸Šé™'],
                mode='lines',
                name='ä¸Šé™',
                line=dict(color='red', dash='dash')
            ))
            
            fig.add_trace(go.Scatter(
                x=[f"ç¬¬{m}ä¸ªæœˆ" for m in monthly_summary['æœªæ¥æœˆä»½']],
                y=monthly_summary['ä¸‹é™'],
                mode='lines',
                name='ä¸‹é™',
                line=dict(color='green', dash='dash')
            ))
            
            fig.update_layout(
                title="æœªæ¥é¢„æµ‹æ±‡æ€» (å·²å¯ç”¨è·Ÿè¸ª)",
                xaxis_title="æœˆä»½",
                yaxis_title="é¢„æµ‹é”€é‡",
                height=400
            )
            
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            total_pred = system.predictions['é¢„æµ‹é”€é‡'].sum()
            
            st.markdown(f"""
            <div class="metric-card">
                <div class="metric-value">{total_pred:,.0f}</div>
                <div class="metric-label">æ€»é¢„æµ‹é”€é‡(ç®±)</div>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown(f"""
            <div class="feature-card">
                <h4>ğŸ“Š é¢„æµ‹æ‘˜è¦</h4>
                <p><strong>é¢„æµ‹äº§å“:</strong> {system.predictions['äº§å“ä»£ç '].nunique()} ä¸ª</p>
                <p><strong>é¢„æµ‹æœˆæ•°:</strong> {system.predictions['æœªæ¥æœˆä»½'].max()} ä¸ªæœˆ</p>
                <p><strong>è·Ÿè¸ªçŠ¶æ€:</strong> âœ… å·²å¯ç”¨</p>
                <p><strong>é¢„æµ‹è®°å½•:</strong> {len(system.predictions)} æ¡</p>
                <p><strong>ä½¿ç”¨æ¨¡å‹:</strong> {system.models['best_model_name']}</p>
            </div>
            """, unsafe_allow_html=True)
    
    # é¢„æµ‹éªŒè¯åŒºåŸŸ
    st.markdown("#### ğŸ¯ é¢„æµ‹éªŒè¯ (è¾“å…¥å®é™…å€¼)")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("##### ğŸ“¥ æ·»åŠ å®é™…é”€é‡")
        
        # è·å–å¾…éªŒè¯çš„é¢„æµ‹
        pending_predictions = tracker.get_pending_predictions()
        
        if pending_predictions:
            # é€‰æ‹©äº§å“å’Œæœˆä»½
            products_months = [(p['product_code'], p['target_month']) for p in pending_predictions]
            product_month_options = [f"{pm[0]} - {pm[1]}" for pm in products_months]
            
            selected_pm = st.selectbox("é€‰æ‹©è¦éªŒè¯çš„é¢„æµ‹", product_month_options)
            
            if selected_pm:
                selected_product, selected_month = selected_pm.split(' - ')
                
                # æ‰¾åˆ°å¯¹åº”çš„é¢„æµ‹
                pred_info = None
                for p in pending_predictions:
                    if p['product_code'] == selected_product and p['target_month'] == selected_month:
                        pred_info = p
                        break
                
                if pred_info:
                    st.markdown(f"""
                    <div class="feature-card">
                        <h4>ğŸ“Š é¢„æµ‹ä¿¡æ¯</h4>
                        <p><strong>äº§å“:</strong> {pred_info['product_code']}</p>
                        <p><strong>ç›®æ ‡æœˆä»½:</strong> {pred_info['target_month']}</p>
                        <p><strong>é¢„æµ‹å€¼:</strong> {pred_info['predicted_value']:.2f} ç®±</p>
                        <p><strong>ç½®ä¿¡åŒºé—´:</strong> {pred_info['confidence_interval'][0]:.1f} - {pred_info['confidence_interval'][1]:.1f}</p>
                        <p><strong>é¢„æµ‹æ—¥æœŸ:</strong> {pred_info['prediction_date'].strftime('%Y-%m-%d')}</p>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    # è¾“å…¥å®é™…å€¼
                    actual_value = st.number_input(
                        "è¾“å…¥å®é™…é”€é‡ (ç®±)",
                        min_value=0.0,
                        value=0.0,
                        step=1.0,
                        key=f"actual_{selected_product}_{selected_month}"
                    )
                    
                    if st.button("âœ… éªŒè¯é¢„æµ‹", use_container_width=True):
                        if actual_value >= 0:
                            accuracy = tracker.validate_prediction(
                                selected_product, selected_month, actual_value
                            )
                            
                            if accuracy is not None:
                                st.success(f"âœ… éªŒè¯å®Œæˆ! å‡†ç¡®ç‡: {accuracy:.1f}%")
                                st.rerun()
                            else:
                                st.error("éªŒè¯å¤±è´¥")
                        else:
                            st.error("è¯·è¾“å…¥æœ‰æ•ˆçš„å®é™…é”€é‡")
        else:
            st.info("æš‚æ— å¾…éªŒè¯çš„é¢„æµ‹è®°å½•")
    
    with col2:
        st.markdown("##### ğŸ“Š éªŒè¯ç»Ÿè®¡")
        
        validation_stats = tracker.get_validation_stats()
        
        if validation_stats:
            st.markdown(f"""
            <div class="feature-card">
                <h4>ğŸ¯ éªŒè¯ç»“æœç»Ÿè®¡</h4>
                <p><strong>å·²éªŒè¯æ•°:</strong> {validation_stats['total_validated']} ä¸ª</p>
                <p><strong>å¹³å‡å‡†ç¡®ç‡:</strong> {validation_stats['avg_accuracy']:.1f}%</p>
                <p><strong>ä¸­ä½å‡†ç¡®ç‡:</strong> {validation_stats['median_accuracy']:.1f}%</p>
                <p><strong>å‡†ç¡®ç‡èŒƒå›´:</strong> {validation_stats['min_accuracy']:.1f}% - {validation_stats['max_accuracy']:.1f}%</p>
                <p><strong>æ ‡å‡†å·®:</strong> {validation_stats['std_accuracy']:.1f}%</p>
                <p><strong>80%ä»¥ä¸Š:</strong> {validation_stats['above_80_pct']:.1f}%</p>
                <p><strong>90%ä»¥ä¸Š:</strong> {validation_stats['above_90_pct']:.1f}%</p>
            </div>
            """, unsafe_allow_html=True)
            
            # éªŒè¯å‡†ç¡®ç‡è¯„çº§
            avg_acc = validation_stats['avg_accuracy']
            if avg_acc >= 90:
                grade = "ğŸ† ä¼˜ç§€"
                color = "#4CAF50"
            elif avg_acc >= 80:
                grade = "ğŸ‘ è‰¯å¥½"
                color = "#FF9800"
            elif avg_acc >= 70:
                grade = "âš ï¸ ä¸€èˆ¬"
                color = "#FFC107"
            else:
                grade = "ğŸ”´ éœ€æ”¹è¿›"
                color = "#f44336"
            
            st.markdown(f"""
            <div style="background: {color}20; border: 1px solid {color}; border-radius: 10px; padding: 1rem; text-align: center;">
                <h3 style="color: {color}; margin: 0;">{grade}</h3>
                <p style="margin: 0;">æ¨¡å‹çœŸå®è¡¨ç°è¯„çº§</p>
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown("""
            <div class="warning-card">
                <h4>ğŸ“‹ ç­‰å¾…éªŒè¯</h4>
                <p>æš‚æ— éªŒè¯æ•°æ®ã€‚å½“å®é™…é”€é‡æ•°æ®åˆ°æ¥æ—¶ï¼Œæ‚¨å¯ä»¥åœ¨æ­¤éªŒè¯é¢„æµ‹å‡†ç¡®æ€§ã€‚</p>
                <p><strong>éªŒè¯æµç¨‹:</strong></p>
                <ol>
                    <li>é€‰æ‹©å¾…éªŒè¯çš„é¢„æµ‹è®°å½•</li>
                    <li>è¾“å…¥å®é™…é”€é‡å€¼</li>
                    <li>ç³»ç»Ÿè‡ªåŠ¨è®¡ç®—å‡†ç¡®ç‡</li>
                    <li>æ›´æ–°æ¨¡å‹çœŸå®è¡¨ç°ç»Ÿè®¡</li>
                </ol>
            </div>
            """, unsafe_allow_html=True)
    
    # è¯¦ç»†é¢„æµ‹è¡¨æ ¼
    st.markdown("#### ğŸ“‹ è¯¦ç»†é¢„æµ‹è®°å½•")
    
    if system.predictions is not None:
        display_columns = ['äº§å“ä»£ç ', 'æœªæ¥æœˆä»½', 'ç›®æ ‡æœˆä»½', 'é¢„æµ‹é”€é‡', 'ä¸‹é™', 'ä¸Šé™', 'äº§å“æ®µ', 'ä½¿ç”¨æ¨¡å‹']
        st.dataframe(
            system.predictions[display_columns],
            use_container_width=True,
            hide_index=True
        )

def create_sidebar():
    """åˆ›å»ºä¾§è¾¹æ """
    with st.sidebar:
        st.markdown("### ğŸ›ï¸ ç³»ç»Ÿæ§åˆ¶å°")
        
        # ç³»ç»ŸçŠ¶æ€
        st.markdown("#### ğŸ“Š ç³»ç»ŸçŠ¶æ€")
        
        if st.session_state.data_validation_passed:
            status_color = "success"
            status_text = "æ•°æ®å·²éªŒè¯"
        else:
            status_color = "warning"
            status_text = "ç­‰å¾…æ•°æ®"
        
        if st.session_state.model_trained:
            model_color = "success"
            model_text = "æ¨¡å‹å·²è®­ç»ƒ"
        else:
            model_color = "warning"
            model_text = "ç­‰å¾…è®­ç»ƒ"
        
        st.markdown(f"""
        <div class="feature-card">
            <div style="display: flex; align-items: center; margin-bottom: 0.5rem;">
                <span class="status-indicator status-{status_color}"></span>
                <strong>{status_text}</strong>
            </div>
            <div style="display: flex; align-items: center;">
                <span class="status-indicator status-{model_color}"></span>
                <strong>{model_text}</strong>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        # è®­ç»ƒå‚æ•°
        st.markdown("#### âš™ï¸ è®­ç»ƒå‚æ•°")
        st.session_state.test_ratio = st.slider("æµ‹è¯•é›†æ¯”ä¾‹", 0.1, 0.3, st.session_state.test_ratio, 0.05)
        st.session_state.months_ahead = st.slider("é¢„æµ‹æœˆæ•°", 1, 6, st.session_state.months_ahead)
        
        with st.expander("é«˜çº§å‚æ•°"):
            st.session_state.outlier_factor = st.slider("å¼‚å¸¸å€¼å› å­", 2.0, 5.0, st.session_state.outlier_factor, 0.5)
            st.session_state.min_data_points = st.slider("æœ€å°æ•°æ®ç‚¹", 3, 6, st.session_state.min_data_points)
            st.session_state.n_estimators = st.slider("æ ‘çš„æ•°é‡", 100, 500, st.session_state.n_estimators, 50)
            st.session_state.max_depth = st.slider("æœ€å¤§æ·±åº¦", 3, 15, st.session_state.max_depth)
            st.session_state.learning_rate = st.slider("å­¦ä¹ ç‡", 0.01, 0.2, st.session_state.learning_rate, 0.01)
        
        # ç³»ç»Ÿé‡ç½®
        st.markdown("#### âš¡ ç³»ç»Ÿæ“ä½œ")
        if st.button("ğŸ”„ é‡ç½®ç³»ç»Ÿ", use_container_width=True):
            for key in ['model_trained', 'prediction_system', 'uploaded_data', 
                       'data_validation_passed', 'prediction_tracker']:
                if key in st.session_state:
                    if key in ['model_trained', 'data_validation_passed']:
                        st.session_state[key] = False
                    else:
                        st.session_state[key] = None
            st.success("âœ… ç³»ç»Ÿå·²é‡ç½®")
            st.rerun()

# ====================================================================
# ä¸»ç¨‹åº
# ====================================================================

def main():
    """ä¸»ç¨‹åº"""
    render_header()
    create_sidebar()
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4 = st.tabs([
        "ğŸ“ æ•°æ®ä¸Šä¼ ",
        "ğŸš€ æ¨¡å‹è®­ç»ƒ", 
        "ğŸ“Š é¢„æµ‹è·Ÿè¸ª",
        "ğŸ” ç³»ç»ŸçŠ¶æ€"
    ])
    
    with tab1:
        show_data_upload_tab()
    
    with tab2:
        show_fixed_training_tab()
    
    with tab3:
        show_prediction_tracking_tab()
    
    with tab4:
        if st.session_state.model_trained:
            system = st.session_state.prediction_system
            
            st.markdown("### ğŸ” ç³»ç»ŸçŠ¶æ€è¯¦æƒ…")
            
            # æ•°æ®æºä¿¡æ¯
            st.markdown("#### ğŸ“Š æ•°æ®æº")
            source_info = system.data_summary['data_source']
            st.json(source_info)
            
            # æ¨¡å‹ä¿¡æ¯
            st.markdown("#### ğŸ¤– æ¨¡å‹ä¿¡æ¯")
            model_info = {
                'best_model': system.models['best_model_name'],
                'feature_count': len(system.models['feature_cols']),
                'training_time': f"{system.training_time:.2f}ç§’",
                'data_quality_score': system.data_summary['data_quality_score']
            }
            st.json(model_info)
            
            # å‡†ç¡®ç‡è¯¦æƒ…
            st.markdown("#### ğŸ¯ å‡†ç¡®ç‡è¯¦æƒ…")
            st.json(system.accuracy_results)
            
        else:
            st.info("è¯·å…ˆå®Œæˆæ¨¡å‹è®­ç»ƒä»¥æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€")

if __name__ == "__main__":
    main()
