# enhanced_sales_prediction_streamlit.py
"""
å¢å¼ºç‰ˆé”€å”®é¢„æµ‹ç³»ç»Ÿ - åŸºäºçœŸå®GitHubæ•°æ®
==========================================

åŸºäºCIRA18-HUB/sales_dashboardçœŸå®æ•°æ®çš„é«˜ç²¾åº¦æœºå™¨å­¦ä¹ é¢„æµ‹ç³»ç»Ÿ
ä½¿ç”¨å¤šæ¨¡å‹èåˆæŠ€æœ¯å’ŒSMAPEå‡†ç¡®ç‡è¯„ä¼°

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. ğŸ¯ é«˜ç²¾åº¦æœºå™¨å­¦ä¹ é¢„æµ‹å¼•æ“ (XGBoost, LightGBM, RandomForest)
2. ğŸ“Š å®Œæ•´çš„å†å²é¢„æµ‹å¯¹æ¯”åˆ†æ  
3. ğŸ”§ 30+é«˜çº§ç‰¹å¾å·¥ç¨‹å’Œæ•°æ®éªŒè¯
4. ğŸ¤– æ™ºèƒ½æ¨¡å‹èåˆå’Œæ€§èƒ½è¯„ä¼°
5. ğŸ“ˆ å®æ—¶å‡†ç¡®ç‡ç›‘æ§å’Œå¯è§†åŒ–
6. ğŸ’¾ é¢„æµ‹ç»“æœå¯¼å‡ºå’Œè·Ÿè¸ª

ç‰ˆæœ¬: v2.1 Production Ready - ä»…çœŸå®æ•°æ®
æ›´æ–°: 2025-06-04
ä½œè€…: åŸºäºCIRA18-HUBçœŸå®æ•°æ®çš„é”€å”®é¢„æµ‹ä¸“å®¶ç³»ç»Ÿ
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import warnings
import time
import io
import json
import requests
from urllib.parse import quote

warnings.filterwarnings('ignore')

# æœºå™¨å­¦ä¹ åº“
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, r2_score
from sklearn.preprocessing import RobustScaler, StandardScaler
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb
import lightgbm as lgb

# ====================================================================
# é¡µé¢é…ç½®
# ====================================================================
st.set_page_config(
    page_title="å¢å¼ºç‰ˆé”€å”®é¢„æµ‹ç³»ç»Ÿ - çœŸå®æ•°æ®ç‰ˆ",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ====================================================================
# ç°ä»£åŒ–æ ·å¼
# ====================================================================
modern_styles = """
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');

    .stApp {
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        min-height: 100vh;
    }

    .main {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        min-height: 100vh;
    }

    /* å¤´éƒ¨æ ·å¼ */
    .prediction-header {
        background: rgba(255, 255, 255, 0.95);
        backdrop-filter: blur(25px);
        border-radius: 20px;
        padding: 2rem;
        margin-bottom: 2rem;
        box-shadow: 0 10px 30px rgba(0,0,0,0.1);
        text-align: center;
    }

    .prediction-title {
        font-size: 3rem;
        font-weight: 800;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 1rem;
    }

    .prediction-subtitle {
        font-size: 1.2rem;
        color: #666;
        margin-bottom: 1rem;
    }

    /* åŠŸèƒ½å¡ç‰‡ */
    .feature-card {
        background: rgba(255, 255, 255, 0.95);
        backdrop-filter: blur(25px);
        border-radius: 15px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 8px 25px rgba(0,0,0,0.1);
        border-left: 4px solid #667eea;
        transition: all 0.3s ease;
    }

    .feature-card:hover {
        transform: translateY(-3px);
        box-shadow: 0 12px 35px rgba(0,0,0,0.15);
    }

    /* æŒ‡æ ‡å¡ç‰‡ */
    .metric-card {
        background: rgba(255, 255, 255, 0.95);
        border-radius: 15px;
        padding: 1.5rem;
        text-align: center;
        border-left: 4px solid #667eea;
        box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        height: 100%;
    }

    .metric-value {
        font-size: 2.5rem;
        font-weight: bold;
        color: #667eea;
    }

    .metric-label {
        font-size: 1rem;
        color: #666;
        margin-top: 0.5rem;
    }

    /* çŠ¶æ€æŒ‡ç¤ºå™¨ */
    .status-indicator {
        width: 12px;
        height: 12px;
        border-radius: 50%;
        display: inline-block;
        margin-right: 0.5rem;
        animation: pulse 2s infinite;
    }

    .status-success { background-color: #4CAF50; }
    .status-warning { background-color: #FF9800; }
    .status-danger { background-color: #f44336; }

    @keyframes pulse {
        0% { transform: scale(1); opacity: 1; }
        50% { transform: scale(1.1); opacity: 0.8; }
        100% { transform: scale(1); opacity: 1; }
    }

    /* è¿›åº¦æ¡æ ·å¼ */
    .stProgress > div > div > div > div {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    }

    /* æŒ‰é’®æ ·å¼ */
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 10px;
        font-weight: 500;
        transition: all 0.3s ease;
    }

    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 5px 15px rgba(0,0,0,0.2);
    }

    /* ä¾§è¾¹æ  */
    .css-1d391kg {
        background: rgba(255, 255, 255, 0.95);
        backdrop-filter: blur(10px);
    }

    /* æ•°æ®è¡¨æ ¼ */
    .stDataFrame {
        border-radius: 10px;
        overflow: hidden;
        box-shadow: 0 5px 15px rgba(0,0,0,0.1);
    }
</style>
"""

st.markdown(modern_styles, unsafe_allow_html=True)

# ====================================================================
# Session State åˆå§‹åŒ–
# ====================================================================
def initialize_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    defaults = {
        'model_trained': False,
        'prediction_system': None,
        'training_progress': 0.0,
        'training_status': "ç­‰å¾…å¼€å§‹",
        'prediction_results': None,
        'historical_analysis': None,
        'accuracy_stats': None,
        'feature_importance': None,
        'model_comparison': None
    }
    
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

initialize_session_state()

# ====================================================================
# æ ¸å¿ƒé¢„æµ‹ç³»ç»Ÿç±»
# ====================================================================
class EnhancedSalesPredictionSystem:
    """å¢å¼ºç‰ˆé”€å”®é¢„æµ‹ç³»ç»Ÿ - åŸºäºCIRA18-HUBçœŸå®æ•°æ®"""
    
    def __init__(self):
        self.shipment_data = None
        self.promotion_data = None
        self.feature_data = None
        self.models = {}
        self.scalers = {}
        self.predictions = None
        self.accuracy_results = {}
        self.product_segments = {}
        self.historical_predictions = None
        self.historical_accuracy = None
        self.data_summary = {}
        self.training_time = None
        self.data_source_info = {}
        
    def load_data_from_github(self, progress_callback=None):
        """ä»CIRA18-HUB/sales_dashboard GitHubä»“åº“åŠ è½½çœŸå®é”€å”®æ•°æ®"""
        if progress_callback:
            progress_callback(0.1, "ğŸ“¡ è¿æ¥CIRA18-HUB/sales_dashboardçœŸå®æ•°æ®æº...")
        
        try:
            # æ­£ç¡®çš„GitHubæ•°æ®æº - CIRA18-HUB/sales_dashboard
            github_base_url = "https://raw.githubusercontent.com/CIRA18-HUB/sales_dashboard/main"
            
            # åŸºäºç”¨æˆ·æä¾›çš„æ–‡ä»¶åï¼Œå°è¯•å¤šç§å¯èƒ½çš„è·¯å¾„
            possible_shipment_files = [
                "é¢„æµ‹æ¨¡å‹å‡ºè´§æ•°æ®æ¯æ—¥xlsx.xlsx",
                "data/é¢„æµ‹æ¨¡å‹å‡ºè´§æ•°æ®æ¯æ—¥xlsx.xlsx",
                "datasets/é¢„æµ‹æ¨¡å‹å‡ºè´§æ•°æ®æ¯æ—¥xlsx.xlsx",
                "files/é¢„æµ‹æ¨¡å‹å‡ºè´§æ•°æ®æ¯æ—¥xlsx.xlsx",
                "pages/é¢„æµ‹æ¨¡å‹å‡ºè´§æ•°æ®æ¯æ—¥xlsx.xlsx",
                "pages/data/é¢„æµ‹æ¨¡å‹å‡ºè´§æ•°æ®æ¯æ—¥xlsx.xlsx",
                "å‡ºè´§æ•°æ®.xlsx",
                "shipment_data.xlsx",
                "sales_data.xlsx",
                "data/å‡ºè´§æ•°æ®.xlsx",
                "data/shipment_data.xlsx",
                "data/sales_data.xlsx"
            ]
            
            possible_promotion_files = [
                "é”€å”®ä¸šåŠ¡å‘˜ä¿ƒé”€æ–‡ä»¶.xlsx",
                "data/é”€å”®ä¸šåŠ¡å‘˜ä¿ƒé”€æ–‡ä»¶.xlsx",
                "datasets/é”€å”®ä¸šåŠ¡å‘˜ä¿ƒé”€æ–‡ä»¶.xlsx", 
                "files/é”€å”®ä¸šåŠ¡å‘˜ä¿ƒé”€æ–‡ä»¶.xlsx",
                "pages/é”€å”®ä¸šåŠ¡å‘˜ä¿ƒé”€æ–‡ä»¶.xlsx",
                "pages/data/é”€å”®ä¸šåŠ¡å‘˜ä¿ƒé”€æ–‡ä»¶.xlsx",
                "ä¿ƒé”€æ•°æ®.xlsx",
                "promotion_data.xlsx",
                "data/ä¿ƒé”€æ•°æ®.xlsx",
                "data/promotion_data.xlsx"
            ]
            
            # åŒæ—¶å°è¯•CSVæ ¼å¼
            possible_shipment_csv = [
                "é¢„æµ‹æ¨¡å‹å‡ºè´§æ•°æ®æ¯æ—¥.csv",
                "data/é¢„æµ‹æ¨¡å‹å‡ºè´§æ•°æ®æ¯æ—¥.csv",
                "å‡ºè´§æ•°æ®.csv",
                "shipment_data.csv", 
                "sales_data.csv",
                "data/å‡ºè´§æ•°æ®.csv",
                "data/shipment_data.csv",
                "data/sales_data.csv"
            ]
            
            possible_promotion_csv = [
                "é”€å”®ä¸šåŠ¡å‘˜ä¿ƒé”€æ–‡ä»¶.csv",
                "data/é”€å”®ä¸šåŠ¡å‘˜ä¿ƒé”€æ–‡ä»¶.csv",
                "ä¿ƒé”€æ•°æ®.csv",
                "promotion_data.csv",
                "data/ä¿ƒé”€æ•°æ®.csv",
                "data/promotion_data.csv"
            ]
            
            if progress_callback:
                progress_callback(0.15, "ğŸ” æœç´¢å‡ºè´§æ•°æ®æ–‡ä»¶...")
            
            shipment_data = None
            promotion_data = None
            shipment_source = None
            promotion_source = None
            
            # 1. ä¼˜å…ˆå°è¯•åŠ è½½å‡ºè´§æ•°æ® Excel æ–‡ä»¶
            for file_path in possible_shipment_files:
                try:
                    file_url = f"{github_base_url}/{quote(file_path)}"
                    if progress_callback:
                        progress_callback(0.2, f"ğŸ“¥ å°è¯•åŠ è½½å‡ºè´§æ•°æ®: {file_path}")
                    
                    response = requests.get(file_url, timeout=30)
                    if response.status_code == 200:
                        shipment_data = pd.read_excel(io.BytesIO(response.content))
                        shipment_source = file_path
                        print(f"âœ… æˆåŠŸåŠ è½½å‡ºè´§æ•°æ®: {file_path}")
                        break
                except Exception as e:
                    print(f"å°è¯•åŠ è½½ {file_path} å¤±è´¥: {str(e)}")
                    continue
            
            # 2. å¦‚æœExcelå¤±è´¥ï¼Œå°è¯•CSVæ ¼å¼
            if shipment_data is None:
                for file_path in possible_shipment_csv:
                    try:
                        file_url = f"{github_base_url}/{quote(file_path)}"
                        if progress_callback:
                            progress_callback(0.25, f"ğŸ“¥ å°è¯•åŠ è½½å‡ºè´§CSV: {file_path}")
                        
                        response = requests.get(file_url, timeout=30)
                        if response.status_code == 200:
                            shipment_data = pd.read_csv(io.StringIO(response.content.decode('utf-8')))
                            shipment_source = file_path
                            print(f"âœ… æˆåŠŸåŠ è½½å‡ºè´§CSV: {file_path}")
                            break
                    except Exception as e:
                        print(f"å°è¯•åŠ è½½CSV {file_path} å¤±è´¥: {str(e)}")
                        continue
            
            # 3. å°è¯•åŠ è½½ä¿ƒé”€æ•°æ®
            if progress_callback:
                progress_callback(0.3, "ğŸ” æœç´¢ä¿ƒé”€æ•°æ®æ–‡ä»¶...")
            
            for file_path in possible_promotion_files:
                try:
                    file_url = f"{github_base_url}/{quote(file_path)}"
                    if progress_callback:
                        progress_callback(0.35, f"ğŸ“¥ å°è¯•åŠ è½½ä¿ƒé”€æ•°æ®: {file_path}")
                    
                    response = requests.get(file_url, timeout=30)
                    if response.status_code == 200:
                        promotion_data = pd.read_excel(io.BytesIO(response.content))
                        promotion_source = file_path
                        print(f"âœ… æˆåŠŸåŠ è½½ä¿ƒé”€æ•°æ®: {file_path}")
                        break
                except Exception as e:
                    print(f"å°è¯•åŠ è½½ä¿ƒé”€æ•°æ® {file_path} å¤±è´¥: {str(e)}")
                    continue
            
            # 4. å¦‚æœä¿ƒé”€Excelå¤±è´¥ï¼Œå°è¯•CSV
            if promotion_data is None:
                for file_path in possible_promotion_csv:
                    try:
                        file_url = f"{github_base_url}/{quote(file_path)}"
                        if progress_callback:
                            progress_callback(0.4, f"ğŸ“¥ å°è¯•åŠ è½½ä¿ƒé”€CSV: {file_path}")
                        
                        response = requests.get(file_url, timeout=30)
                        if response.status_code == 200:
                            promotion_data = pd.read_csv(io.StringIO(response.content.decode('utf-8')))
                            promotion_source = file_path
                            print(f"âœ… æˆåŠŸåŠ è½½ä¿ƒé”€CSV: {file_path}")
                            break
                    except Exception as e:
                        print(f"å°è¯•åŠ è½½ä¿ƒé”€CSV {file_path} å¤±è´¥: {str(e)}")
                        continue
            
            # æ£€æŸ¥æ•°æ®åŠ è½½ç»“æœ
            if shipment_data is None:
                raise Exception("æ— æ³•ä»CIRA18-HUB/sales_dashboardä»“åº“åŠ è½½å‡ºè´§æ•°æ®ï¼Œè¯·æ£€æŸ¥ä»“åº“æ˜¯å¦å­˜åœ¨ä»¥åŠæ–‡ä»¶è·¯å¾„")
            
            # éªŒè¯å‡ºè´§æ•°æ®æ ¼å¼
            self.shipment_data = self._validate_and_clean_shipment_data(shipment_data)
            self.promotion_data = promotion_data  # ä¿ƒé”€æ•°æ®æ˜¯å¯é€‰çš„
            
            # ä¿å­˜æ•°æ®æºä¿¡æ¯
            self.data_source_info = {
                'shipment_source': shipment_source,
                'promotion_source': promotion_source,
                'github_repo': 'CIRA18-HUB/sales_dashboard',
                'load_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
            if progress_callback:
                progress_callback(0.45, f"âœ… çœŸå®æ•°æ®åŠ è½½å®Œæˆ: {len(self.shipment_data):,} æ¡å‡ºè´§è®°å½•")
            
            print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ:")
            print(f"   å‡ºè´§æ•°æ®: {len(self.shipment_data):,} æ¡è®°å½• (æ¥æº: {shipment_source})")
            if promotion_data is not None:
                print(f"   ä¿ƒé”€æ•°æ®: {len(promotion_data):,} æ¡è®°å½• (æ¥æº: {promotion_source})")
            else:
                print(f"   ä¿ƒé”€æ•°æ®: æœªæ‰¾åˆ° (å¯é€‰)")
            print(f"   æ—¶é—´èŒƒå›´: {self.shipment_data['order_date'].min()} è‡³ {self.shipment_data['order_date'].max()}")
            
            return True
            
        except Exception as e:
            error_msg = f"æ•°æ®åŠ è½½å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            if progress_callback:
                progress_callback(0.1, f"âŒ {error_msg}")
            
            # ç”±äºç”¨æˆ·æ˜ç¡®è¦æ±‚ä¸ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼Œè¿™é‡Œç›´æ¥è¿”å›å¤±è´¥
            raise Exception(f"æ— æ³•ä»CIRA18-HUB/sales_dashboardåŠ è½½çœŸå®æ•°æ®: {str(e)}")
    
    def _validate_and_clean_shipment_data(self, raw_data):
        """éªŒè¯å’Œæ¸…ç†å‡ºè´§æ•°æ®æ ¼å¼"""
        print("ğŸ” éªŒè¯æ•°æ®æ ¼å¼...")
        
        # æ‰“å°åŸå§‹æ•°æ®ä¿¡æ¯
        print(f"åŸå§‹æ•°æ®å½¢çŠ¶: {raw_data.shape}")
        print(f"åŸå§‹åˆ—å: {list(raw_data.columns)}")
        
        # å°è¯•æ ‡å‡†åŒ–åˆ—åï¼ˆå¤„ç†ä¸­è‹±æ–‡åˆ—åï¼‰
        column_mapping = {
            # ä¸­æ–‡åˆ—åæ˜ å°„
            'è®¢å•æ—¥æœŸ': 'order_date',
            'å‡ºè´§æ—¥æœŸ': 'order_date', 
            'æ—¥æœŸ': 'order_date',
            'åŒºåŸŸ': 'region',
            'åœ°åŒº': 'region',
            'å®¢æˆ·ä»£ç ': 'customer_code',
            'å®¢æˆ·ç¼–ç ': 'customer_code',
            'ç»é”€å•†ä»£ç ': 'customer_code',
            'äº§å“ä»£ç ': 'product_code',
            'äº§å“ç¼–ç ': 'product_code',
            'è´§å·': 'product_code',
            'æ•°é‡': 'quantity',
            'é”€é‡': 'quantity',
            'å‡ºè´§é‡': 'quantity',
            'ç®±æ•°': 'quantity',
            
            # è‹±æ–‡åˆ—åæ˜ å°„
            'date': 'order_date',
            'order_date': 'order_date',
            'ship_date': 'order_date',
            'region': 'region',
            'area': 'region',
            'customer': 'customer_code',
            'customer_id': 'customer_code',
            'dealer': 'customer_code',
            'dealer_code': 'customer_code',
            'product': 'product_code',
            'product_id': 'product_code',
            'sku': 'product_code',
            'qty': 'quantity',
            'volume': 'quantity',
            'sales': 'quantity',
            'amount': 'quantity'
        }
        
        # åº”ç”¨åˆ—åæ˜ å°„
        cleaned_data = raw_data.copy()
        
        # å°è¯•æ‰¾åˆ°åŒ¹é…çš„åˆ—
        for original_col in raw_data.columns:
            col_lower = original_col.lower().strip()
            if col_lower in column_mapping:
                cleaned_data = cleaned_data.rename(columns={original_col: column_mapping[col_lower]})
            elif original_col.strip() in column_mapping:
                cleaned_data = cleaned_data.rename(columns={original_col: column_mapping[original_col.strip()]})
        
        print(f"æ˜ å°„ååˆ—å: {list(cleaned_data.columns)}")
        
        # æ£€æŸ¥å¿…è¦å­—æ®µ
        required_fields = ['order_date', 'product_code', 'quantity']
        missing_fields = [field for field in required_fields if field not in cleaned_data.columns]
        
        if missing_fields:
            # å°è¯•ä»ç°æœ‰åˆ—ä¸­æ¨æ–­
            available_cols = list(cleaned_data.columns)
            print(f"ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_fields}")
            print(f"å¯ç”¨å­—æ®µ: {available_cols}")
            
            # æ™ºèƒ½æ¨æ–­å­—æ®µ
            for field in missing_fields:
                if field == 'order_date':
                    # æŸ¥æ‰¾æ—¥æœŸç›¸å…³åˆ—
                    date_cols = [col for col in available_cols if any(keyword in col.lower() 
                                for keyword in ['date', 'æ—¥æœŸ', 'time', 'æ—¶é—´'])]
                    if date_cols:
                        cleaned_data['order_date'] = cleaned_data[date_cols[0]]
                        print(f"æ¨æ–­æ—¥æœŸå­—æ®µ: {date_cols[0]} -> order_date")
                
                elif field == 'product_code':
                    # æŸ¥æ‰¾äº§å“ç›¸å…³åˆ—
                    product_cols = [col for col in available_cols if any(keyword in col.lower() 
                                   for keyword in ['product', 'sku', 'item', 'äº§å“', 'è´§å·', 'code'])]
                    if product_cols:
                        cleaned_data['product_code'] = cleaned_data[product_cols[0]]
                        print(f"æ¨æ–­äº§å“å­—æ®µ: {product_cols[0]} -> product_code")
                
                elif field == 'quantity':
                    # æŸ¥æ‰¾æ•°é‡ç›¸å…³åˆ—
                    qty_cols = [col for col in available_cols if any(keyword in col.lower() 
                               for keyword in ['qty', 'quantity', 'amount', 'volume', 'sales', 'æ•°é‡', 'é”€é‡', 'ç®±'])]
                    if qty_cols:
                        cleaned_data['quantity'] = cleaned_data[qty_cols[0]]
                        print(f"æ¨æ–­æ•°é‡å­—æ®µ: {qty_cols[0]} -> quantity")
        
        # å†æ¬¡æ£€æŸ¥å¿…è¦å­—æ®µ
        final_missing = [field for field in required_fields if field not in cleaned_data.columns]
        if final_missing:
            raise Exception(f"æ•°æ®ç¼ºå°‘å¿…è¦å­—æ®µ: {final_missing}ã€‚è¯·ç¡®ä¿æ•°æ®åŒ…å«æ—¥æœŸã€äº§å“ä»£ç å’Œæ•°é‡ä¿¡æ¯ã€‚")
        
        # æ·»åŠ é»˜è®¤å­—æ®µ
        if 'customer_code' not in cleaned_data.columns:
            cleaned_data['customer_code'] = 'DEFAULT_CUSTOMER'
        if 'region' not in cleaned_data.columns:
            cleaned_data['region'] = 'DEFAULT_REGION'
        
        print(f"âœ… æ•°æ®éªŒè¯å®Œæˆï¼Œæœ€ç»ˆå­—æ®µ: {list(cleaned_data.columns)}")
        return cleaned_data
    
    def preprocess_data(self, progress_callback=None):
        """é«˜çº§æ•°æ®é¢„å¤„ç†"""
        if progress_callback:
            progress_callback(0.5, "ğŸ§¹ æ•°æ®é¢„å¤„ç†ä¸­...")
        
        print("ğŸ§¹ é«˜çº§æ•°æ®é¢„å¤„ç†...")
        
        # æ•°æ®ç±»å‹è½¬æ¢
        self.shipment_data['order_date'] = pd.to_datetime(self.shipment_data['order_date'], errors='coerce')
        self.shipment_data['quantity'] = pd.to_numeric(self.shipment_data['quantity'], errors='coerce')
        
        # ä¿ƒé”€æ•°æ®å¤„ç†
        if self.promotion_data is not None and len(self.promotion_data) > 0:
            try:
                # å°è¯•æ ‡å‡†åŒ–ä¿ƒé”€æ•°æ®åˆ—å
                promo_mapping = {
                    'ç”³è¯·æ—¥æœŸ': 'apply_date',
                    'ç»é”€å•†ä»£ç ': 'dealer_code', 
                    'äº§å“ä»£ç ': 'product_code',
                    'ä¿ƒé”€å¼€å§‹æ—¥æœŸ': 'promo_start_date',
                    'ä¿ƒé”€ç»“æŸæ—¥æœŸ': 'promo_end_date',
                    'é¢„è®¡é”€é‡': 'expected_sales',
                    'èµ å“æ•°é‡': 'gift_quantity'
                }
                
                for original_col in self.promotion_data.columns:
                    if original_col in promo_mapping:
                        self.promotion_data = self.promotion_data.rename(columns={original_col: promo_mapping[original_col]})
                
                # è½¬æ¢ä¿ƒé”€æ•°æ®çš„æ—¥æœŸå­—æ®µ
                date_cols = ['apply_date', 'promo_start_date', 'promo_end_date']
                for col in date_cols:
                    if col in self.promotion_data.columns:
                        self.promotion_data[col] = pd.to_datetime(self.promotion_data[col], errors='coerce')
                        
                print(f"âœ… ä¿ƒé”€æ•°æ®é¢„å¤„ç†å®Œæˆ: {len(self.promotion_data)} æ¡è®°å½•")
            except Exception as e:
                print(f"âš ï¸ ä¿ƒé”€æ•°æ®é¢„å¤„ç†å¤±è´¥: {str(e)}")
                self.promotion_data = None
        
        # æ•°æ®æ¸…æ´—
        original_len = len(self.shipment_data)
        self.shipment_data = self.shipment_data.dropna(subset=['order_date', 'product_code', 'quantity'])
        self.shipment_data = self.shipment_data[self.shipment_data['quantity'] > 0]
        
        print(f"âœ… åŸºç¡€æ•°æ®æ¸…æ´—: {original_len} â†’ {len(self.shipment_data)} è¡Œ")
        
        # å¼‚å¸¸å€¼å¤„ç†
        self.shipment_data = self._remove_outliers_iqr(self.shipment_data, factor=3.0)
        
        # äº§å“åˆ†æ®µ
        self._segment_products()
        
        # æ•°æ®æ‘˜è¦
        self.data_summary = {
            'total_records': len(self.shipment_data),
            'total_products': self.shipment_data['product_code'].nunique(),
            'total_customers': self.shipment_data['customer_code'].nunique(),
            'total_regions': self.shipment_data['region'].nunique(),
            'date_range': (self.shipment_data['order_date'].min(), self.shipment_data['order_date'].max()),
            'total_quantity': self.shipment_data['quantity'].sum(),
            'avg_daily_quantity': self.shipment_data.groupby('order_date')['quantity'].sum().mean(),
            'data_source': self.data_source_info
        }
        
        if progress_callback:
            progress_callback(0.55, f"âœ… é¢„å¤„ç†å®Œæˆ: {len(self.shipment_data)} è¡ŒçœŸå®æ•°æ®")
        
        return True
    
    def _remove_outliers_iqr(self, data, column='quantity', factor=3.0):
        """ä½¿ç”¨IQRæ–¹æ³•ç§»é™¤å¼‚å¸¸å€¼"""
        Q1 = data[column].quantile(0.25)
        Q3 = data[column].quantile(0.75)
        IQR = Q3 - Q1
        
        lower_bound = Q1 - factor * IQR
        upper_bound = Q3 + factor * IQR
        
        outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]
        data_cleaned = data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]
        
        print(f"ğŸ”§ å¼‚å¸¸å€¼å¤„ç†ç»“æœ: {len(data)} â†’ {len(data_cleaned)} (ç§»é™¤ {len(outliers)} ä¸ªå¼‚å¸¸å€¼)")
        
        return data_cleaned
    
    def _segment_products(self):
        """äº§å“åˆ†æ®µ - æŒ‰é”€é‡ç‰¹å¾åˆ†ç±»"""
        print("ğŸ“Š äº§å“åˆ†æ®µåˆ†æ...")
        
        # è®¡ç®—æ¯ä¸ªäº§å“çš„é”€é‡ç‰¹å¾
        product_stats = self.shipment_data.groupby('product_code')['quantity'].agg([
            'count', 'mean', 'std', 'min', 'max', 'sum'
        ]).reset_index()
        
        product_stats['cv'] = product_stats['std'] / product_stats['mean']  # å˜å¼‚ç³»æ•°
        product_stats['cv'] = product_stats['cv'].fillna(0)
        
        # åŸºäºé”€é‡å‡å€¼å’Œå˜å¼‚ç³»æ•°åˆ†æ®µ
        volume_high = product_stats['mean'].quantile(0.67)
        volume_low = product_stats['mean'].quantile(0.33)
        cv_high = product_stats['cv'].quantile(0.67)
        
        def classify_product(row):
            if row['mean'] >= volume_high:
                return 'é«˜é”€é‡ç¨³å®š' if row['cv'] <= cv_high else 'é«˜é”€é‡æ³¢åŠ¨'
            elif row['mean'] >= volume_low:
                return 'ä¸­é”€é‡ç¨³å®š' if row['cv'] <= cv_high else 'ä¸­é”€é‡æ³¢åŠ¨'
            else:
                return 'ä½é”€é‡ç¨³å®š' if row['cv'] <= cv_high else 'ä½é”€é‡æ³¢åŠ¨'
        
        product_stats['segment'] = product_stats.apply(classify_product, axis=1)
        
        # ä¿å­˜åˆ†æ®µç»“æœ
        self.product_segments = dict(zip(product_stats['product_code'], product_stats['segment']))
        
        # æ‰“å°åˆ†æ®µç»Ÿè®¡
        segment_counts = product_stats['segment'].value_counts()
        print("ğŸ“Š äº§å“åˆ†æ®µç»“æœ:")
        for segment, count in segment_counts.items():
            print(f"   {segment}: {count} ä¸ªäº§å“")
        
        return product_stats
    
    def create_advanced_features(self, progress_callback=None):
        """åˆ›å»ºé«˜çº§ç‰¹å¾å·¥ç¨‹"""
        if progress_callback:
            progress_callback(0.6, "ğŸ”§ é«˜çº§ç‰¹å¾å·¥ç¨‹...")
        
        print("ğŸ”§ é«˜çº§ç‰¹å¾å·¥ç¨‹...")
        
        # åˆ›å»ºæœˆåº¦æ•°æ®
        monthly_data = self.shipment_data.groupby([
            'product_code',
            self.shipment_data['order_date'].dt.to_period('M')
        ]).agg({
            'quantity': ['sum', 'count', 'mean', 'std'],
            'customer_code': 'nunique',
            'region': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.iloc[0]
        }).reset_index()
        
        # æ‰å¹³åŒ–åˆ—å
        monthly_data.columns = ['product_code', 'year_month', 'total_qty', 'order_count',
                               'avg_qty', 'std_qty', 'customer_count', 'main_region']
        monthly_data['std_qty'] = monthly_data['std_qty'].fillna(0)
        
        # æ’åº
        monthly_data = monthly_data.sort_values(['product_code', 'year_month'])
        
        print(f"ğŸ“Š æœˆåº¦èšåˆæ•°æ®: {len(monthly_data)} è¡Œ")
        
        # ä¸ºæ¯ä¸ªäº§å“æ®µåˆ†åˆ«åˆ›å»ºç‰¹å¾
        all_features = []
        
        for segment in self.product_segments.values():
            segment_products = [k for k, v in self.product_segments.items() if v == segment]
            segment_data = monthly_data[monthly_data['product_code'].isin(segment_products)]
            
            for product in segment_products:
                product_data = segment_data[segment_data['product_code'] == product].copy()
                
                if len(product_data) < 4:  # è‡³å°‘éœ€è¦4ä¸ªæœˆæ•°æ®
                    continue
                
                # ä¸ºæ¯ä¸ªæ—¶é—´ç‚¹åˆ›å»ºç‰¹å¾
                for idx in range(3, len(product_data)):
                    features = self._create_advanced_product_features(
                        product, product_data.iloc[:idx], segment
                    )
                    
                    # ç›®æ ‡å˜é‡
                    target_row = product_data.iloc[idx]
                    features['target'] = target_row['total_qty']
                    features['target_month'] = str(target_row['year_month'])
                    features['segment'] = segment
                    
                    all_features.append(features)
        
        self.feature_data = pd.DataFrame(all_features)
        
        if len(self.feature_data) == 0:
            raise Exception("æ— æ³•åˆ›å»ºç‰¹å¾æ•°æ®ï¼Œè¯·æ£€æŸ¥æ•°æ®è´¨é‡å’Œå®Œæ•´æ€§")
        
        print(f"âœ… é«˜çº§ç‰¹å¾æ•°æ®: {len(self.feature_data)} è¡Œ, {len(self.feature_data.columns) - 4} ä¸ªç‰¹å¾")
        
        # ç‰¹å¾å·¥ç¨‹åå¤„ç†
        self._post_process_features()
        
        if progress_callback:
            progress_callback(0.65, f"âœ… ç‰¹å¾å®Œæˆ: {len(self.feature_data)} æ ·æœ¬")
        
        return True
    
    def _create_advanced_product_features(self, product_code, historical_data, segment):
        """ä¸ºå•ä¸ªäº§å“åˆ›å»ºé«˜çº§ç‰¹å¾"""
        features = {'product_code': product_code}
        
        if len(historical_data) < 3:
            return features
        
        # åŸºç¡€æ•°æ®
        qty_values = historical_data['total_qty'].values
        order_counts = historical_data['order_count'].values
        customer_counts = historical_data['customer_count'].values
        
        # 1. é”€é‡ç‰¹å¾ - ä½¿ç”¨å¯¹æ•°å˜æ¢å¤„ç†åæ€åˆ†å¸ƒ
        log_qty = np.log1p(qty_values)  # log(1+x) é¿å…log(0)
        
        features.update({
            # åŸå§‹é”€é‡ç‰¹å¾
            'qty_mean': np.mean(qty_values),
            'qty_median': np.median(qty_values),
            'qty_std': np.std(qty_values),
            'qty_cv': np.std(qty_values) / (np.mean(qty_values) + 1),
            
            # å¯¹æ•°å˜æ¢ç‰¹å¾
            'log_qty_mean': np.mean(log_qty),
            'log_qty_std': np.std(log_qty),
            
            # æ»åç‰¹å¾
            'qty_lag_1': qty_values[-1],
            'qty_lag_2': qty_values[-2] if len(qty_values) > 1 else 0,
            'qty_lag_3': qty_values[-3] if len(qty_values) > 2 else 0,
            
            # ç§»åŠ¨å¹³å‡
            'qty_ma_2': np.mean(qty_values[-2:]),
            'qty_ma_3': np.mean(qty_values[-3:]),
            
            # åŠ æƒç§»åŠ¨å¹³å‡ï¼ˆæœ€è¿‘çš„æƒé‡æ›´å¤§ï¼‰
            'qty_wma_3': np.average(qty_values[-3:], weights=[1, 2, 3]) if len(qty_values) >= 3 else np.mean(qty_values),
        })
        
        # 2. è¶‹åŠ¿ç‰¹å¾
        if len(qty_values) > 1:
            # ç®€å•å¢é•¿ç‡
            features['growth_rate_1'] = (qty_values[-1] - qty_values[-2]) / (qty_values[-2] + 1)
            
            # çº¿æ€§è¶‹åŠ¿
            x = np.arange(len(qty_values))
            if len(qty_values) > 2:
                trend_coef = np.polyfit(x, qty_values, 1)[0]
                features['trend_slope'] = trend_coef
                
                # è¶‹åŠ¿å¼ºåº¦ï¼ˆRÂ²ï¼‰
                y_pred = np.polyval([trend_coef, np.mean(qty_values)], x)
                ss_res = np.sum((qty_values - y_pred) ** 2)
                ss_tot = np.sum((qty_values - np.mean(qty_values)) ** 2)
                features['trend_strength'] = 1 - (ss_res / (ss_tot + 1e-8))
            else:
                features['trend_slope'] = 0
                features['trend_strength'] = 0
        else:
            features['growth_rate_1'] = 0
            features['trend_slope'] = 0
            features['trend_strength'] = 0
        
        # 3. è®¢å•è¡Œä¸ºç‰¹å¾
        features.update({
            'order_count_mean': np.mean(order_counts),
            'order_count_trend': order_counts[-1] - order_counts[0] if len(order_counts) > 1 else 0,
            'avg_order_size': features['qty_mean'] / (np.mean(order_counts) + 1),
            'customer_count_mean': np.mean(customer_counts),
            'penetration_rate': np.mean(customer_counts) / (np.max(customer_counts) + 1)
        })
        
        # 4. æ—¶é—´ç‰¹å¾
        last_month = historical_data.iloc[-1]['year_month']
        features.update({
            'month': last_month.month,
            'quarter': last_month.quarter,
            'is_year_end': 1 if last_month.month in [11, 12] else 0,
            'is_peak_season': 1 if last_month.month in [3, 4, 10, 11] else 0,
        })
        
        # 5. ç¨³å®šæ€§ç‰¹å¾
        features.update({
            'data_points': len(qty_values),
            'stability_score': 1 / (1 + features['qty_cv']),  # å˜å¼‚ç³»æ•°è¶Šå°è¶Šç¨³å®š
            'consistency_score': len(qty_values[qty_values > 0]) / len(qty_values)
        })
        
        # 6. äº§å“æ®µç‰¹å¾
        segment_map = {
            'é«˜é”€é‡ç¨³å®š': 1,
            'é«˜é”€é‡æ³¢åŠ¨': 2,
            'ä¸­é”€é‡ç¨³å®š': 3,
            'ä¸­é”€é‡æ³¢åŠ¨': 4,
            'ä½é”€é‡ç¨³å®š': 5,
            'ä½é”€é‡æ³¢åŠ¨': 6
        }
        features['segment_encoded'] = segment_map.get(segment, 0)
        
        return features
    
    def _post_process_features(self):
        """ç‰¹å¾åå¤„ç†"""
        print("ğŸ”§ ç‰¹å¾åå¤„ç†...")
        
        # è·å–æ•°å€¼ç‰¹å¾åˆ—
        feature_cols = [col for col in self.feature_data.columns 
                       if col not in ['product_code', 'target', 'target_month', 'segment']]
        
        # å¤„ç†æ— ç©·å€¼å’ŒNaN
        self.feature_data[feature_cols] = self.feature_data[feature_cols].replace([np.inf, -np.inf], np.nan)
        
        # ç”¨0å¡«å……NaNï¼ˆå¯¹äºé”€å”®æ•°æ®ï¼Œ0æ˜¯åˆç†çš„é»˜è®¤å€¼ï¼‰
        self.feature_data[feature_cols] = self.feature_data[feature_cols].fillna(0)
        
        # ç§»é™¤å¸¸æ•°ç‰¹å¾
        constant_features = []
        for col in feature_cols:
            if self.feature_data[col].std() == 0:
                constant_features.append(col)
        
        if constant_features:
            print(f"  ç§»é™¤å¸¸æ•°ç‰¹å¾: {constant_features}")
            self.feature_data = self.feature_data.drop(columns=constant_features)
        
        print(f"âœ… æœ€ç»ˆç‰¹å¾æ•°: {len([col for col in self.feature_data.columns if col not in ['product_code', 'target', 'target_month', 'segment']])}")
    
    def train_advanced_models(self, test_ratio=0.2, progress_callback=None):
        """è®­ç»ƒé«˜çº§æœºå™¨å­¦ä¹ æ¨¡å‹"""
        if progress_callback:
            progress_callback(0.7, "ğŸš€ æ¨¡å‹è®­ç»ƒä¸­...")
        
        print("ğŸš€ è®­ç»ƒé«˜çº§æ¨¡å‹...")
        start_time = time.time()
        
        if self.feature_data is None or len(self.feature_data) == 0:
            raise Exception("æ²¡æœ‰ç‰¹å¾æ•°æ®ï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹")
        
        # å‡†å¤‡æ•°æ®
        feature_cols = [col for col in self.feature_data.columns 
                       if col not in ['product_code', 'target', 'target_month', 'segment']]
        
        X = self.feature_data[feature_cols]
        y = self.feature_data['target']
        
        # ç›®æ ‡å˜é‡å¯¹æ•°å˜æ¢ï¼ˆå¤„ç†åæ€åˆ†å¸ƒï¼‰
        y_log = np.log1p(y)
        
        print(f"ğŸ“Š æ•°æ®å‡†å¤‡:")
        print(f"   ç‰¹å¾æ•°: {len(feature_cols)}")
        print(f"   æ ·æœ¬æ•°: {len(X)}")
        print(f"   ç›®æ ‡å€¼èŒƒå›´: {y.min():.1f} - {y.max():.1f}")
        
        # æ—¶é—´åºåˆ—åˆ†å‰²
        n_samples = len(X)
        split_point = int(n_samples * (1 - test_ratio))
        
        X_train, X_test = X[:split_point], X[split_point:]
        y_train, y_test = y[:split_point], y[split_point:]
        y_log_train, y_log_test = y_log[:split_point], y_log[split_point:]
        
        # ç‰¹å¾æ ‡å‡†åŒ–
        scaler = RobustScaler()  # å¯¹å¼‚å¸¸å€¼æ›´ç¨³å¥
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        self.scalers['feature_scaler'] = scaler
        
        print(f"ğŸ“ˆ æ•°æ®åˆ†å‰²:")
        print(f"   è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬")
        print(f"   æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬")
        
        # è®­ç»ƒå¤šä¸ªæ¨¡å‹
        models = {}
        predictions = {}
        
        # 1. XGBoost
        if progress_callback:
            progress_callback(0.75, "ğŸ¯ è®­ç»ƒXGBoost...")
        
        print("ğŸ¯ è®­ç»ƒXGBoost...")
        xgb_model = xgb.XGBRegressor(
            n_estimators=300,
            max_depth=5,
            learning_rate=0.05,
            subsample=0.8,
            colsample_bytree=0.8,
            reg_alpha=0.1,
            reg_lambda=0.1,
            random_state=42,
            n_jobs=-1
        )
        
        xgb_model.fit(X_train_scaled, y_log_train, verbose=False)
        xgb_pred_log = xgb_model.predict(X_test_scaled)
        xgb_pred = np.expm1(xgb_pred_log)  # åå˜æ¢
        
        models['XGBoost'] = xgb_model
        predictions['XGBoost'] = xgb_pred
        
        # 2. LightGBM
        if progress_callback:
            progress_callback(0.85, "ğŸ¯ è®­ç»ƒLightGBM...")
        
        print("ğŸ¯ è®­ç»ƒLightGBM...")
        lgb_model = lgb.LGBMRegressor(
            n_estimators=300,
            max_depth=5,
            learning_rate=0.05,
            subsample=0.8,
            colsample_bytree=0.8,
            reg_alpha=0.1,
            reg_lambda=0.1,
            random_state=42,
            n_jobs=-1,
            verbose=-1
        )
        
        lgb_model.fit(X_train_scaled, y_log_train)
        lgb_pred_log = lgb_model.predict(X_test_scaled)
        lgb_pred = np.expm1(lgb_pred_log)
        
        models['LightGBM'] = lgb_model
        predictions['LightGBM'] = lgb_pred
        
        # 3. Random Forest
        if progress_callback:
            progress_callback(0.9, "ğŸ¯ è®­ç»ƒRandom Forest...")
        
        print("ğŸ¯ è®­ç»ƒRandom Forest...")
        rf_model = RandomForestRegressor(
            n_estimators=200,
            max_depth=10,
            min_samples_split=5,
            min_samples_leaf=2,
            random_state=42,
            n_jobs=-1
        )
        
        rf_model.fit(X_train_scaled, y_train)
        rf_pred = rf_model.predict(X_test_scaled)
        
        models['RandomForest'] = rf_model
        predictions['RandomForest'] = rf_pred
        
        # 4. èåˆæ¨¡å‹
        print("ğŸ¯ åˆ›å»ºèåˆæ¨¡å‹...")
        weights = self._calculate_model_weights(predictions, y_test)
        
        ensemble_pred = (weights['XGBoost'] * predictions['XGBoost'] + 
                        weights['LightGBM'] * predictions['LightGBM'] + 
                        weights['RandomForest'] * predictions['RandomForest'])
        
        predictions['Ensemble'] = ensemble_pred
        
        # è¯„ä¼°æ‰€æœ‰æ¨¡å‹
        print("ğŸ“Š æ¨¡å‹æ€§èƒ½è¯„ä¼°:")
        results = {}
        
        for model_name, pred in predictions.items():
            pred = np.maximum(pred, 0)  # ç¡®ä¿é¢„æµ‹å€¼éè´Ÿ
            
            # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
            mae = np.mean(np.abs(y_test - pred))
            rmse = np.sqrt(mean_squared_error(y_test, pred))
            
            # SMAPEå‡†ç¡®ç‡è®¡ç®—
            smape_accuracies = self.calculate_batch_robust_accuracy(
                y_test.values, pred, method='smape'
            )
            smape_accuracy = np.mean(smape_accuracies)
            
            # ä¼ ç»ŸMAPE
            mape_values = []
            for actual, predicted in zip(y_test.values, pred):
                if actual >= 1:
                    mape_val = abs((actual - predicted) / actual) * 100
                else:
                    mape_val = abs((actual - predicted) / max(actual, 5)) * 100
                mape_values.append(mape_val)
            
            mape = np.mean(mape_values)
            mape_accuracy = max(0, 100 - mape)
            
            # å¯¹ç§°MAPE
            smape = 100 * np.mean(2 * np.abs(y_test - pred) / (np.abs(y_test) + np.abs(pred) + 1))
            
            r2 = r2_score(y_test, pred)
            
            results[model_name] = {
                'Accuracy': mape_accuracy,
                'SMAPE_Accuracy': smape_accuracy,
                'MAPE': mape,
                'SMAPE': smape,
                'MAE': mae,
                'RMSE': rmse,
                'RÂ²': r2
            }
            
            print(f"  {model_name}:")
            print(f"    SMAPEå‡†ç¡®ç‡: {smape_accuracy:.1f}%")
            print(f"    MAE: {mae:.1f}")
            print(f"    RÂ²: {r2:.3f}")
        
        # é€‰æ‹©æœ€ä½³æ¨¡å‹
        best_model_name = max(results.keys(), key=lambda x: results[x]['SMAPE_Accuracy'])
        
        # ç”Ÿæˆå†å²é¢„æµ‹å¯¹æ¯”
        if progress_callback:
            progress_callback(0.95, "ğŸ“Š ç”Ÿæˆå†å²é¢„æµ‹å¯¹æ¯”...")
        
        self._generate_complete_historical_predictions(
            models[best_model_name], 
            best_model_name, 
            feature_cols, 
            scaler
        )
        
        self.models = {
            'best_model': models.get(best_model_name),
            'best_model_name': best_model_name,
            'all_models': models,
            'feature_cols': feature_cols,
            'weights': weights if best_model_name == 'Ensemble' else None,
            'log_transform': best_model_name in ['XGBoost', 'LightGBM']
        }
        
        self.accuracy_results = results
        self.training_time = time.time() - start_time
        
        if progress_callback:
            best_accuracy = results[best_model_name]['SMAPE_Accuracy']
            progress_callback(1.0, f"âœ… è®­ç»ƒå®Œæˆ! {best_model_name}: {best_accuracy:.1f}%")
        
        print(f"ğŸ† æœ€ä½³æ¨¡å‹: {best_model_name} (SMAPEå‡†ç¡®ç‡: {results[best_model_name]['SMAPE_Accuracy']:.1f}%)")
        
        return True
    
    def calculate_robust_accuracy(self, actual_value, predicted_value, method='smape'):
        """è®¡ç®—ç¨³å¥çš„å‡†ç¡®ç‡"""
        if method == 'smape':
            if actual_value == 0 and predicted_value == 0:
                return 100.0
            
            smape = 200 * abs(actual_value - predicted_value) / (abs(actual_value) + abs(predicted_value) + 1e-8)
            return max(0, 100 - smape)
        
        return 0.0
    
    def calculate_batch_robust_accuracy(self, actual_values, predicted_values, method='smape'):
        """æ‰¹é‡è®¡ç®—ç¨³å¥å‡†ç¡®ç‡"""
        actual_values = np.array(actual_values)
        predicted_values = np.array(predicted_values)
        
        if method == 'smape':
            both_zero = (actual_values == 0) & (predicted_values == 0)
            
            smape = 200 * np.abs(actual_values - predicted_values) / (
                np.abs(actual_values) + np.abs(predicted_values) + 1e-8
            )
            accuracy = np.maximum(0, 100 - smape)
            accuracy[both_zero] = 100.0
            
            return accuracy
        
        return np.zeros_like(actual_values)
    
    def _generate_complete_historical_predictions(self, model, model_name, feature_cols, scaler):
        """ç”Ÿæˆå®Œæ•´å†å²é¢„æµ‹è®°å½•"""
        all_historical_predictions = []
        
        print("ğŸ“Š ç”Ÿæˆå®Œæ•´å†å²é¢„æµ‹å¯¹æ¯”...")
        
        products = self.feature_data['product_code'].unique()
        
        for i, product in enumerate(products):
            if i % 50 == 0:
                print(f"  è¿›åº¦: {i}/{len(products)} ({i/len(products)*100:.1f}%)")
            
            # è·å–è¯¥äº§å“çš„æ‰€æœ‰æœˆåº¦æ•°æ®
            product_monthly = self.shipment_data[
                self.shipment_data['product_code'] == product
            ].copy()
            
            # æŒ‰æœˆèšåˆ
            product_monthly['year_month'] = product_monthly['order_date'].dt.to_period('M')
            monthly_agg = product_monthly.groupby('year_month').agg({
                'quantity': ['sum', 'count', 'mean', 'std'],
                'customer_code': 'nunique',
                'region': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.iloc[0]
            }).reset_index()
            
            # æ‰å¹³åŒ–åˆ—å
            monthly_agg.columns = ['year_month', 'total_qty', 'order_count',
                                  'avg_qty', 'std_qty', 'customer_count', 'main_region']
            monthly_agg['std_qty'] = monthly_agg['std_qty'].fillna(0)
            monthly_agg = monthly_agg.sort_values('year_month')
            
            if len(monthly_agg) < 4:
                continue
            
            # è·å–äº§å“æ®µ
            segment = self.product_segments.get(product, 'ä¸­é”€é‡ç¨³å®š')
            
            # æ»šåŠ¨é¢„æµ‹
            for j in range(3, len(monthly_agg)):
                historical_data = monthly_agg.iloc[:j]
                features = self._create_advanced_product_features(
                    product, historical_data, segment
                )
                
                # è½¬æ¢ä¸ºç‰¹å¾å‘é‡
                feature_vector = pd.DataFrame([features])[feature_cols]
                X_scaled = scaler.transform(feature_vector)
                
                # é¢„æµ‹
                if model_name in ['XGBoost', 'LightGBM']:
                    pred_log = model.predict(X_scaled)[0]
                    pred_value = np.expm1(pred_log)
                else:
                    pred_value = model.predict(X_scaled)[0]
                
                pred_value = max(0, pred_value)
                
                # å®é™…å€¼
                actual_value = monthly_agg.iloc[j]['total_qty']
                target_month = monthly_agg.iloc[j]['year_month']
                
                # è®¡ç®—å‡†ç¡®ç‡
                accuracy = self.calculate_robust_accuracy(
                    actual_value, pred_value, method='smape'
                )
                
                error = abs(actual_value - pred_value)
                
                all_historical_predictions.append({
                    'äº§å“ä»£ç ': product,
                    'å¹´æœˆ': str(target_month),
                    'é¢„æµ‹å€¼': round(pred_value, 2),
                    'å®é™…å€¼': round(actual_value, 2),
                    'ç»å¯¹è¯¯å·®': round(error, 2),
                    'å‡†ç¡®ç‡(%)': round(accuracy, 2),
                    'äº§å“æ®µ': segment
                })
        
        self.historical_predictions = pd.DataFrame(all_historical_predictions)
        self._calculate_product_accuracy_stats()
        
        print(f"âœ… ç”Ÿæˆäº† {len(all_historical_predictions)} æ¡å†å²é¢„æµ‹è®°å½•")
        
        if len(self.historical_predictions) > 0:
            overall_accuracy = self.historical_predictions['å‡†ç¡®ç‡(%)'].mean()
            print(f"ğŸ“Š æ•´ä½“å¹³å‡SMAPEå‡†ç¡®ç‡: {overall_accuracy:.2f}%")
    
    def _calculate_product_accuracy_stats(self):
        """è®¡ç®—æ¯ä¸ªäº§å“çš„å‡†ç¡®ç‡ç»Ÿè®¡"""
        product_stats = []
        
        for product in self.historical_predictions['äº§å“ä»£ç '].unique():
            product_data = self.historical_predictions[
                self.historical_predictions['äº§å“ä»£ç '] == product
            ]
            
            avg_accuracy = product_data['å‡†ç¡®ç‡(%)'].mean()
            recent_accuracy = product_data.tail(1)['å‡†ç¡®ç‡(%)'].iloc[0] if len(product_data) > 0 else 0
            
            # é”€é‡åŠ æƒå‡†ç¡®ç‡
            recent_data = product_data.tail(3)
            if len(recent_data) > 0:
                weights = recent_data['å®é™…å€¼'] / recent_data['å®é™…å€¼'].sum()
                weighted_accuracy = (recent_data['å‡†ç¡®ç‡(%)'] * weights).sum()
            else:
                weighted_accuracy = avg_accuracy
            
            accuracy_above_85 = len(product_data[product_data['å‡†ç¡®ç‡(%)'] >= 85])
            accuracy_above_90 = len(product_data[product_data['å‡†ç¡®ç‡(%)'] >= 90])
            
            product_stats.append({
                'äº§å“ä»£ç ': product,
                'å¹³å‡å‡†ç¡®ç‡(%)': round(avg_accuracy, 2),
                'æœ€è¿‘å‡†ç¡®ç‡(%)': round(recent_accuracy, 2),
                'åŠ æƒå‡†ç¡®ç‡(%)': round(weighted_accuracy, 2),
                'é¢„æµ‹æ¬¡æ•°': len(product_data),
                '85%ä»¥ä¸Šæ¬¡æ•°': accuracy_above_85,
                '90%ä»¥ä¸Šæ¬¡æ•°': accuracy_above_90,
                'äº§å“æ®µ': product_data['äº§å“æ®µ'].iloc[0]
            })
        
        self.historical_accuracy = pd.DataFrame(product_stats)
    
    def _calculate_model_weights(self, predictions, y_true):
        """è®¡ç®—æ¨¡å‹èåˆæƒé‡"""
        scores = {}
        for name, pred in predictions.items():
            pred = np.maximum(pred, 0)
            
            smape_accuracies = self.calculate_batch_robust_accuracy(
                y_true.values, pred, method='smape'
            )
            scores[name] = np.mean(smape_accuracies)
        
        total_score = sum(scores.values())
        if total_score > 0:
            weights = {name: score / total_score for name, score in scores.items()}
        else:
            weights = {name: 1/len(scores) for name in scores.keys()}
        
        return weights
    
    def predict_future(self, months_ahead=3):
        """é¢„æµ‹æœªæ¥é”€é‡"""
        print(f"ğŸ”® é¢„æµ‹æœªæ¥{months_ahead}ä¸ªæœˆé”€é‡...")
        
        if not self.models:
            raise Exception("æ¨¡å‹æœªè®­ç»ƒï¼Œæ— æ³•è¿›è¡Œé¢„æµ‹")
        
        predictions = []
        products = self.feature_data['product_code'].unique()
        
        for i, product in enumerate(products):
            if i % 20 == 0:
                print(f"  é¢„æµ‹è¿›åº¦: {i}/{len(products)} ({i/len(products)*100:.1f}%)")
            
            product_features = self.feature_data[
                self.feature_data['product_code'] == product
            ].tail(1)
            
            if len(product_features) == 0:
                continue
            
            for month in range(1, months_ahead + 1):
                X = product_features[self.models['feature_cols']]
                X_scaled = self.scalers['feature_scaler'].transform(X)
                
                if self.models['best_model_name'] == 'Ensemble':
                    xgb_pred_log = self.models['all_models']['XGBoost'].predict(X_scaled)[0]
                    lgb_pred_log = self.models['all_models']['LightGBM'].predict(X_scaled)[0]
                    rf_pred = self.models['all_models']['RandomForest'].predict(X_scaled)[0]
                    
                    xgb_pred = np.expm1(xgb_pred_log)
                    lgb_pred = np.expm1(lgb_pred_log)
                    
                    weights = self.models['weights']
                    final_pred = (weights['XGBoost'] * xgb_pred + 
                                 weights['LightGBM'] * lgb_pred + 
                                 weights['RandomForest'] * rf_pred)
                else:
                    if self.models['log_transform']:
                        pred_log = self.models['best_model'].predict(X_scaled)[0]
                        final_pred = np.expm1(pred_log)
                    else:
                        final_pred = self.models['best_model'].predict(X_scaled)[0]
                
                final_pred = max(0, final_pred)
                
                segment = product_features['segment'].iloc[0]
                confidence_factor = self._get_confidence_factor(segment)
                
                lower_bound = max(0, final_pred * (1 - confidence_factor))
                upper_bound = final_pred * (1 + confidence_factor)
                
                predictions.append({
                    'äº§å“ä»£ç ': product,
                    'æœªæ¥æœˆä»½': month,
                    'é¢„æµ‹é”€é‡': round(final_pred, 2),
                    'ä¸‹é™': round(lower_bound, 2),
                    'ä¸Šé™': round(upper_bound, 2),
                    'ç½®ä¿¡åº¦': confidence_factor,
                    'äº§å“æ®µ': segment,
                    'ä½¿ç”¨æ¨¡å‹': self.models['best_model_name']
                })
        
        self.predictions = pd.DataFrame(predictions)
        print(f"âœ… å®Œæˆ {len(products)} ä¸ªäº§å“çš„é¢„æµ‹")
        
        return self.predictions
    
    def _get_confidence_factor(self, segment):
        """æ ¹æ®äº§å“æ®µè·å–ç½®ä¿¡åº¦å› å­"""
        confidence_map = {
            'é«˜é”€é‡ç¨³å®š': 0.15,
            'é«˜é”€é‡æ³¢åŠ¨': 0.25,
            'ä¸­é”€é‡ç¨³å®š': 0.20,
            'ä¸­é”€é‡æ³¢åŠ¨': 0.30,
            'ä½é”€é‡ç¨³å®š': 0.25,
            'ä½é”€é‡æ³¢åŠ¨': 0.35
        }
        return confidence_map.get(segment, 0.25)

# ====================================================================
# Streamlitç•Œé¢å‡½æ•°
# ====================================================================

def render_header():
    """æ¸²æŸ“å¤´éƒ¨"""
    st.markdown(f"""
    <div class="prediction-header">
        <h1 class="prediction-title">ğŸš€ å¢å¼ºç‰ˆé”€å”®é¢„æµ‹ç³»ç»Ÿ</h1>
        <p class="prediction-subtitle">
            åŸºäºCIRA18-HUB/sales_dashboardçœŸå®æ•°æ® Â· é«˜ç²¾åº¦æœºå™¨å­¦ä¹ é¢„æµ‹å¼•æ“ Â· å¤šæ¨¡å‹èåˆæŠ€æœ¯
        </p>
        <div style="display: flex; justify-content: center; gap: 1rem; flex-wrap: wrap; margin-top: 1rem;">
            <span style="background: linear-gradient(135deg, #4CAF50 0%, #45a049 100%); color: white; padding: 0.5rem 1rem; border-radius: 20px;">ğŸ¯ XGBoost</span>
            <span style="background: linear-gradient(135deg, #FF9800 0%, #F57C00 100%); color: white; padding: 0.5rem 1rem; border-radius: 20px;">âš¡ LightGBM</span>
            <span style="background: linear-gradient(135deg, #2196F3 0%, #1976D2 100%); color: white; padding: 0.5rem 1rem; border-radius: 20px;">ğŸŒ² Random Forest</span>
            <span style="background: linear-gradient(135deg, #9C27B0 0%, #7B1FA2 100%); color: white; padding: 0.5rem 1rem; border-radius: 20px;">ğŸ”® Ensemble</span>
        </div>
        <div style="margin-top: 1rem; font-size: 0.9rem; color: #666;">
            æ•°æ®æº: CIRA18-HUB/sales_dashboard (ä»…çœŸå®æ•°æ®) | æœ€åæ›´æ–°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | ç‰ˆæœ¬: v2.1 Production Ready
        </div>
    </div>
    """, unsafe_allow_html=True)

def create_sidebar():
    """åˆ›å»ºä¾§è¾¹æ """
    with st.sidebar:
        st.markdown("### ğŸ›ï¸ æ§åˆ¶å°")
        
        # ç³»ç»ŸçŠ¶æ€
        st.markdown("#### ğŸ“Š ç³»ç»ŸçŠ¶æ€")
        
        if st.session_state.model_trained and st.session_state.prediction_system:
            system = st.session_state.prediction_system
            best_model = system.models['best_model_name']
            best_accuracy = system.accuracy_results[best_model]['SMAPE_Accuracy']
            
            st.markdown(f"""
            <div class="feature-card" style="margin: 0.5rem 0;">
                <div style="display: flex; align-items: center; margin-bottom: 0.5rem;">
                    <span class="status-indicator status-success"></span>
                    <strong>ç³»ç»Ÿå°±ç»ª</strong>
                </div>
                <p style="margin: 0; font-size: 0.9rem;">
                    æœ€ä½³æ¨¡å‹: {best_model}<br>
                    SMAPEå‡†ç¡®ç‡: {best_accuracy:.1f}%<br>
                    è®­ç»ƒæ—¶é—´: {system.training_time:.1f}ç§’<br>
                    äº§å“æ•°: {len(system.product_segments)}<br>
                    å†å²è®°å½•: {len(system.historical_predictions) if system.historical_predictions is not None else 0} æ¡<br>
                    æ•°æ®æº: çœŸå®GitHubæ•°æ®
                </p>
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown(f"""
            <div class="feature-card" style="margin: 0.5rem 0;">
                <div style="display: flex; align-items: center; margin-bottom: 0.5rem;">
                    <span class="status-indicator status-warning"></span>
                    <strong>å¾…è®­ç»ƒ</strong>
                </div>
                <p style="margin: 0; font-size: 0.9rem;">
                    è¯·å…ˆè®­ç»ƒé¢„æµ‹æ¨¡å‹
                </p>
            </div>
            """, unsafe_allow_html=True)
        
        # è®­ç»ƒå‚æ•°
        st.markdown("#### âš™ï¸ è®­ç»ƒå‚æ•°")
        test_ratio = st.slider("æµ‹è¯•é›†æ¯”ä¾‹", 0.1, 0.3, 0.2, 0.05, key="test_ratio_slider")
        months_ahead = st.slider("é¢„æµ‹æœˆæ•°", 1, 6, 3, key="months_ahead_slider")
        
        # é«˜çº§è®¾ç½®
        st.markdown("#### ğŸ”§ é«˜çº§è®¾ç½®")
        
        with st.expander("æ•°æ®å¤„ç†"):
            outlier_factor = st.slider("å¼‚å¸¸å€¼å› å­", 2.0, 5.0, 3.0, 0.5, key="outlier_factor_slider")
            min_data_points = st.slider("æœ€å°æ•°æ®ç‚¹", 3, 6, 4, key="min_data_points_slider")
        
        with st.expander("æ¨¡å‹å‚æ•°"):
            n_estimators = st.slider("æ ‘çš„æ•°é‡", 100, 500, 300, 50, key="n_estimators_slider")
            max_depth = st.slider("æœ€å¤§æ·±åº¦", 3, 15, 5, key="max_depth_slider") 
            learning_rate = st.slider("å­¦ä¹ ç‡", 0.01, 0.2, 0.05, 0.01, key="learning_rate_slider")
        
        # å¿«é€Ÿæ“ä½œ
        st.markdown("#### âš¡ å¿«é€Ÿæ“ä½œ")
        
        if st.button("ğŸ”„ é‡ç½®ç³»ç»Ÿ", use_container_width=True, key="reset_system_button"):
            for key in ['model_trained', 'prediction_system', 'training_progress', 
                       'training_status', 'prediction_results', 'historical_analysis',
                       'accuracy_stats', 'feature_importance', 'model_comparison']:
                if key in st.session_state:
                    if key == 'model_trained':
                        st.session_state[key] = False
                    elif key in ['training_progress']:
                        st.session_state[key] = 0.0
                    elif key == 'training_status':
                        st.session_state[key] = "ç­‰å¾…å¼€å§‹"
                    else:
                        st.session_state[key] = None
            st.success("âœ… ç³»ç»Ÿå·²é‡ç½®")
            st.rerun()
    
    return test_ratio, months_ahead, outlier_factor, min_data_points, n_estimators, max_depth, learning_rate

def show_training_tab():
    """æ˜¾ç¤ºè®­ç»ƒæ ‡ç­¾é¡µ"""
    st.markdown("### ğŸš€ æ¨¡å‹è®­ç»ƒ")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("#### ğŸ“Š è®­ç»ƒé…ç½®")
        
        # æ•°æ®æºä¿¡æ¯
        st.markdown("""
        <div class="feature-card">
            <h4>ğŸ“¡ æ•°æ®æº: CIRA18-HUB/sales_dashboard</h4>
            <p><strong>ä¸»è¦æ•°æ®:</strong> GitHubä»“åº“çœŸå®é”€å”®æ•°æ®</p>
            <p><strong>æ•°æ®æ–‡ä»¶:</strong> é¢„æµ‹æ¨¡å‹å‡ºè´§æ•°æ®æ¯æ—¥xlsx.xlsx, é”€å”®ä¸šåŠ¡å‘˜ä¿ƒé”€æ–‡ä»¶.xlsx</p>
            <p><strong>æ•°æ®ç‰¹ç‚¹:</strong> åŒ…å«è®¢å•æ—¥æœŸã€äº§å“ä»£ç ã€é”€é‡ã€å®¢æˆ·ã€åŒºåŸŸç­‰å…³é”®å­—æ®µ</p>
            <p><strong>å¤„ç†æ–¹å¼:</strong> 30+é«˜çº§ç‰¹å¾å·¥ç¨‹ + å¤šæ¨¡å‹èåˆ + SMAPEå‡†ç¡®ç‡è¯„ä¼°</p>
            <p><strong>é¢„æœŸå‡†ç¡®ç‡:</strong> 85-95% (SMAPEæ–¹æ³•)</p>
            <p><strong>æ•°æ®ä¿è¯:</strong> ä»…ä½¿ç”¨çœŸå®æ•°æ®ï¼Œä¸ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®</p>
        </div>
        """, unsafe_allow_html=True)
        
        # è®­ç»ƒæŒ‰é’®
        if st.button("ğŸš€ å¼€å§‹è®­ç»ƒé¢„æµ‹æ¨¡å‹", type="primary", use_container_width=True, key="start_training_button"):
            with st.container():
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                def update_progress(progress, message):
                    progress_bar.progress(progress)
                    status_text.text(message)
                    st.session_state.training_progress = progress
                    st.session_state.training_status = message
                
                try:
                    # åˆå§‹åŒ–ç³»ç»Ÿ
                    system = EnhancedSalesPredictionSystem()
                    
                    # æ‰§è¡Œå®Œæ•´çš„è®­ç»ƒæµç¨‹
                    success = True
                    
                    # 1. æ•°æ®åŠ è½½
                    if system.load_data_from_github(update_progress):
                        # 2. æ•°æ®é¢„å¤„ç†
                        if system.preprocess_data(update_progress):
                            # 3. ç‰¹å¾å·¥ç¨‹
                            if system.create_advanced_features(update_progress):
                                # 4. æ¨¡å‹è®­ç»ƒ
                                test_ratio, months_ahead, _, _, _, _, _ = create_sidebar()
                                if system.train_advanced_models(test_ratio, update_progress):
                                    # 5. æœªæ¥é¢„æµ‹
                                    system.predict_future(months_ahead)
                                    
                                    # ä¿å­˜åˆ°session
                                    st.session_state.prediction_system = system
                                    st.session_state.model_trained = True
                                    
                                    progress_bar.empty()
                                    status_text.empty()
                                    
                                    st.success("ğŸ‰ æ¨¡å‹è®­ç»ƒå®Œæˆï¼åŸºäºçœŸå®GitHubæ•°æ®")
                                    st.balloons()
                                    st.rerun()
                                else:
                                    success = False
                            else:
                                success = False
                        else:
                            success = False
                    else:
                        success = False
                    
                    if not success:
                        st.error("âŒ è®­ç»ƒå¤±è´¥ï¼Œè¯·æ£€æŸ¥GitHubæ•°æ®æºæˆ–ç½‘ç»œè¿æ¥")
                
                except Exception as e:
                    st.error(f"âŒ è®­ç»ƒå¼‚å¸¸: {str(e)}")
                    st.error("è¯·ç¡®ä¿CIRA18-HUB/sales_dashboardä»“åº“å­˜åœ¨ä¸”åŒ…å«æ‰€éœ€çš„æ•°æ®æ–‡ä»¶")
    
    with col2:
        if st.session_state.model_trained and st.session_state.prediction_system:
            system = st.session_state.prediction_system
            
            st.markdown("#### ğŸ† è®­ç»ƒç»“æœ")
            
            best_model = system.models['best_model_name']
            best_accuracy = system.accuracy_results[best_model]['SMAPE_Accuracy']
            
            # å‡†ç¡®ç‡æŒ‡æ ‡å¡ç‰‡
            st.markdown(f"""
            <div class="metric-card">
                <div class="metric-value">{best_accuracy:.1f}%</div>
                <div class="metric-label">SMAPEå‡†ç¡®ç‡</div>
            </div>
            """, unsafe_allow_html=True)
            
            # è¯¦ç»†ä¿¡æ¯
            data_source = system.data_summary.get('data_source', {})
            st.markdown(f"""
            <div class="feature-card">
                <h4>âœ… è®­ç»ƒå®Œæˆ</h4>
                <p><strong>æœ€ä½³æ¨¡å‹:</strong> {best_model}</p>
                <p><strong>è®­ç»ƒæ—¶é—´:</strong> {system.training_time:.1f}ç§’</p>
                <p><strong>äº§å“æ•°é‡:</strong> {len(system.product_segments)}</p>
                <p><strong>ç‰¹å¾æ•°é‡:</strong> {len(system.models['feature_cols'])}</p>
                <p><strong>è®­ç»ƒæ ·æœ¬:</strong> {len(system.feature_data)}</p>
                <p><strong>å†å²é¢„æµ‹:</strong> {len(system.historical_predictions) if system.historical_predictions is not None else 0} æ¡</p>
                <p><strong>æ•°æ®æ¥æº:</strong> {data_source.get('shipment_source', 'çœŸå®GitHubæ•°æ®')}</p>
                <p><strong>åŠ è½½æ—¶é—´:</strong> {data_source.get('load_time', 'N/A')}</p>
            </div>
            """, unsafe_allow_html=True)
            
            # æ¨¡å‹å¯¹æ¯”
            st.markdown("#### ğŸ“Š æ¨¡å‹å¯¹æ¯”")
            
            comparison_data = []
            for model_name, results in system.accuracy_results.items():
                comparison_data.append({
                    'æ¨¡å‹': model_name,
                    'SMAPEå‡†ç¡®ç‡': f"{results['SMAPE_Accuracy']:.1f}%",
                    'MAE': f"{results['MAE']:.1f}",
                    'RMSE': f"{results['RMSE']:.1f}",
                    'RÂ²': f"{results['RÂ²']:.3f}"
                })
            
            comparison_df = pd.DataFrame(comparison_data)
            st.dataframe(comparison_df, use_container_width=True, hide_index=True)
            
        else:
            st.markdown("#### ğŸ“‹ è®­ç»ƒè¯´æ˜")
            st.markdown("""
            <div class="feature-card">
                <h4>ğŸ¯ è®­ç»ƒæµç¨‹</h4>
                <ol>
                    <li>ğŸ“¡ ä»CIRA18-HUB/sales_dashboardåŠ è½½çœŸå®æ•°æ®</li>
                    <li>ğŸ§¹ é«˜çº§æ•°æ®é¢„å¤„ç†å’Œæ¸…æ´—</li>
                    <li>ğŸ”§ åˆ›å»º30+ä¸ªé«˜çº§ç‰¹å¾</li>
                    <li>ğŸ¤– è®­ç»ƒXGBoostã€LightGBMã€Random Forest</li>
                    <li>ğŸ¯ æ¨¡å‹èåˆå’Œæ€§èƒ½è¯„ä¼°</li>
                    <li>ğŸ“Š ç”Ÿæˆå®Œæ•´å†å²é¢„æµ‹å¯¹æ¯”</li>
                    <li>ğŸ”® é¢„æµ‹æœªæ¥é”€é‡</li>
                </ol>
                <p><strong>æ•°æ®ä¿è¯:</strong> ä»…ä½¿ç”¨GitHubçœŸå®æ•°æ®ï¼Œä¸ç”Ÿæˆä»»ä½•æ¨¡æ‹Ÿæ•°æ®</p>
                <p><strong>é¢„æœŸå‡†ç¡®ç‡:</strong> 85-95%ï¼ˆSMAPEæ–¹æ³•ï¼‰</p>
                <p><strong>æ”¯æŒæ–‡ä»¶:</strong> é¢„æµ‹æ¨¡å‹å‡ºè´§æ•°æ®æ¯æ—¥xlsx.xlsx, é”€å”®ä¸šåŠ¡å‘˜ä¿ƒé”€æ–‡ä»¶.xlsx</p>
            </div>
            """, unsafe_allow_html=True)

def show_analysis_tab():
    """æ˜¾ç¤ºåˆ†ææ ‡ç­¾é¡µ"""
    st.markdown("### ğŸ“Š é¢„æµ‹åˆ†æ")
    
    if not st.session_state.model_trained:
        st.warning("âš ï¸ è¯·å…ˆè®­ç»ƒé¢„æµ‹æ¨¡å‹")
        return
    
    system = st.session_state.prediction_system
    
    # æ€»ä½“ç»Ÿè®¡
    st.markdown("#### ğŸ“ˆ æ€»ä½“ç»Ÿè®¡")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        total_products = len(system.product_segments)
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">{total_products}</div>
            <div class="metric-label">é¢„æµ‹äº§å“æ•°</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        if system.historical_predictions is not None:
            avg_accuracy = system.historical_predictions['å‡†ç¡®ç‡(%)'].mean()
        else:
            avg_accuracy = 0
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">{avg_accuracy:.1f}%</div>
            <div class="metric-label">å¹³å‡å‡†ç¡®ç‡</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        if system.predictions is not None:
            total_predicted = system.predictions['é¢„æµ‹é”€é‡'].sum()
        else:
            total_predicted = 0
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">{total_predicted:,.0f}</div>
            <div class="metric-label">é¢„æµ‹æ€»é”€é‡(ç®±)</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        historical_count = len(system.historical_predictions) if system.historical_predictions is not None else 0
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-value">{historical_count}</div>
            <div class="metric-label">å†å²é¢„æµ‹æ•°</div>
        </div>
        """, unsafe_allow_html=True)
    
    # å‡†ç¡®ç‡åˆ†å¸ƒ
    if system.historical_predictions is not None:
        st.markdown("#### ğŸ¯ å‡†ç¡®ç‡åˆ†å¸ƒåˆ†æ")
        
        col_a, col_b = st.columns([1, 1])
        
        with col_a:
            # å‡†ç¡®ç‡ç›´æ–¹å›¾
            fig_hist = px.histogram(
                system.historical_predictions, 
                x='å‡†ç¡®ç‡(%)', 
                nbins=20,
                title="å‡†ç¡®ç‡åˆ†å¸ƒç›´æ–¹å›¾",
                color_discrete_sequence=['#667eea']
            )
            fig_hist.update_layout(
                xaxis_title="å‡†ç¡®ç‡ (%)",
                yaxis_title="é¢‘æ•°",
                showlegend=False
            )
            st.plotly_chart(fig_hist, use_container_width=True)
        
        with col_b:
            # æŒ‰äº§å“æ®µçš„å‡†ç¡®ç‡å¯¹æ¯”
            segment_accuracy = system.historical_predictions.groupby('äº§å“æ®µ')['å‡†ç¡®ç‡(%)'].mean().reset_index()
            
            fig_segment = px.bar(
                segment_accuracy,
                x='äº§å“æ®µ',
                y='å‡†ç¡®ç‡(%)',
                title="å„äº§å“æ®µå¹³å‡å‡†ç¡®ç‡",
                color='å‡†ç¡®ç‡(%)',
                color_continuous_scale='Viridis'
            )
            fig_segment.update_layout(
                xaxis_title="äº§å“æ®µ",
                yaxis_title="å¹³å‡å‡†ç¡®ç‡ (%)"
            )
            st.plotly_chart(fig_segment, use_container_width=True)
    
    # é¢„æµ‹vså®é™…å¯¹æ¯”
    if system.historical_predictions is not None:
        st.markdown("#### ğŸ“Š é¢„æµ‹vså®é™…å¯¹æ¯”")
        
        # é€‰æ‹©äº§å“è¿›è¡Œè¯¦ç»†åˆ†æ
        products = system.historical_predictions['äº§å“ä»£ç '].unique()
        selected_product = st.selectbox("é€‰æ‹©äº§å“è¿›è¡Œè¯¦ç»†åˆ†æ", products, key="analysis_product_select")
        
        if selected_product:
            product_data = system.historical_predictions[
                system.historical_predictions['äº§å“ä»£ç '] == selected_product
            ].copy()
            product_data['å¹´æœˆ'] = pd.to_datetime(product_data['å¹´æœˆ'])
            product_data = product_data.sort_values('å¹´æœˆ')
            
            # æ—¶é—´åºåˆ—å¯¹æ¯”å›¾
            fig_ts = go.Figure()
            
            fig_ts.add_trace(go.Scatter(
                x=product_data['å¹´æœˆ'],
                y=product_data['å®é™…å€¼'],
                mode='lines+markers',
                name='å®é™…å€¼',
                line=dict(color='#4CAF50', width=3),
                marker=dict(size=8)
            ))
            
            fig_ts.add_trace(go.Scatter(
                x=product_data['å¹´æœˆ'],
                y=product_data['é¢„æµ‹å€¼'],
                mode='lines+markers',
                name='é¢„æµ‹å€¼',
                line=dict(color='#FF9800', width=3, dash='dash'),
                marker=dict(size=8)
            ))
            
            fig_ts.update_layout(
                title=f"äº§å“ {selected_product} é¢„æµ‹vså®é™…å¯¹æ¯”",
                xaxis_title="æ—¶é—´",
                yaxis_title="é”€é‡ (ç®±)",
                height=400,
                hovermode='x unified'
            )
            
            st.plotly_chart(fig_ts, use_container_width=True)
            
            # è¯¦ç»†æ•°æ®è¡¨
            display_data = product_data[['å¹´æœˆ', 'é¢„æµ‹å€¼', 'å®é™…å€¼', 'ç»å¯¹è¯¯å·®', 'å‡†ç¡®ç‡(%)', 'äº§å“æ®µ']].copy()
            display_data['å¹´æœˆ'] = display_data['å¹´æœˆ'].dt.strftime('%Y-%m')
            
            st.markdown(f"##### ğŸ“‹ äº§å“ {selected_product} è¯¦ç»†é¢„æµ‹è®°å½•")
            st.dataframe(display_data, use_container_width=True, hide_index=True)

def show_prediction_tab():
    """æ˜¾ç¤ºé¢„æµ‹æ ‡ç­¾é¡µ"""
    st.markdown("### ğŸ”® æœªæ¥é¢„æµ‹")
    
    if not st.session_state.model_trained:
        st.warning("âš ï¸ è¯·å…ˆè®­ç»ƒé¢„æµ‹æ¨¡å‹")
        return
    
    system = st.session_state.prediction_system
    
    if system.predictions is not None:
        st.markdown("#### ğŸ“Š æœªæ¥3ä¸ªæœˆé”€é‡é¢„æµ‹")
        
        # é¢„æµ‹æ±‡æ€»
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # æŒ‰æœˆä»½æ±‡æ€»
            monthly_summary = system.predictions.groupby('æœªæ¥æœˆä»½').agg({
                'é¢„æµ‹é”€é‡': 'sum',
                'ä¸‹é™': 'sum',
                'ä¸Šé™': 'sum',
                'äº§å“ä»£ç ': 'count'
            }).reset_index()
            monthly_summary.columns = ['æœªæ¥æœˆä»½', 'é¢„æµ‹æ€»é‡', 'ä¸‹é™æ€»é‡', 'ä¸Šé™æ€»é‡', 'äº§å“æ•°é‡']
            
            # æœˆåº¦é¢„æµ‹æŸ±çŠ¶å›¾
            fig_monthly = go.Figure()
            
            fig_monthly.add_trace(go.Bar(
                x=[f"ç¬¬{m}ä¸ªæœˆ" for m in monthly_summary['æœªæ¥æœˆä»½']],
                y=monthly_summary['é¢„æµ‹æ€»é‡'],
                name='é¢„æµ‹é”€é‡',
                marker_color='#667eea'
            ))
            
            fig_monthly.add_trace(go.Scatter(
                x=[f"ç¬¬{m}ä¸ªæœˆ" for m in monthly_summary['æœªæ¥æœˆä»½']],
                y=monthly_summary['ä¸Šé™æ€»é‡'],
                mode='lines',
                name='ä¸Šé™',
                line=dict(color='red', dash='dash')
            ))
            
            fig_monthly.add_trace(go.Scatter(
                x=[f"ç¬¬{m}ä¸ªæœˆ" for m in monthly_summary['æœªæ¥æœˆä»½']],
                y=monthly_summary['ä¸‹é™æ€»é‡'],
                mode='lines',
                name='ä¸‹é™',
                line=dict(color='green', dash='dash')
            ))
            
            fig_monthly.update_layout(
                title="æœªæ¥3ä¸ªæœˆé”€é‡é¢„æµ‹æ±‡æ€»",
                xaxis_title="æœˆä»½",
                yaxis_title="é¢„æµ‹é”€é‡ (ç®±)",
                height=400
            )
            
            st.plotly_chart(fig_monthly, use_container_width=True)
        
        with col2:
            st.markdown("#### ğŸ“ˆ é¢„æµ‹æ±‡æ€»")
            
            total_prediction = system.predictions['é¢„æµ‹é”€é‡'].sum()
            st.markdown(f"""
            <div class="metric-card">
                <div class="metric-value">{total_prediction:,.0f}</div>
                <div class="metric-label">3ä¸ªæœˆé¢„æµ‹æ€»é‡(ç®±)</div>
            </div>
            """, unsafe_allow_html=True)
            
            avg_monthly = total_prediction / 3
            st.markdown(f"""
            <div class="metric-card">
                <div class="metric-value">{avg_monthly:,.0f}</div>
                <div class="metric-label">æœˆå‡é¢„æµ‹é”€é‡(ç®±)</div>
            </div>
            """, unsafe_allow_html=True)
            
            # äº§å“æ®µåˆ†å¸ƒ
            segment_pred = system.predictions.groupby('äº§å“æ®µ')['é¢„æµ‹é”€é‡'].sum().reset_index()
            segment_pred = segment_pred.sort_values('é¢„æµ‹é”€é‡', ascending=False)
            
            st.markdown("##### ğŸ“Š å„äº§å“æ®µé¢„æµ‹å æ¯”")
            for _, row in segment_pred.iterrows():
                percentage = row['é¢„æµ‹é”€é‡'] / total_prediction * 100
                st.write(f"**{row['äº§å“æ®µ']}**: {percentage:.1f}%")
        
        # è¯¦ç»†é¢„æµ‹è¡¨æ ¼
        st.markdown("#### ğŸ“‹ è¯¦ç»†é¢„æµ‹ç»“æœ")
        
        # ç­›é€‰é€‰é¡¹
        col_filter1, col_filter2 = st.columns([1, 1])
        
        with col_filter1:
            segments = ['å…¨éƒ¨'] + list(system.predictions['äº§å“æ®µ'].unique())
            selected_segment = st.selectbox("ç­›é€‰äº§å“æ®µ", segments, key="prediction_segment_select")
        
        with col_filter2:
            months = ['å…¨éƒ¨'] + list(system.predictions['æœªæ¥æœˆä»½'].unique())
            selected_month = st.selectbox("ç­›é€‰æœˆä»½", months, key="prediction_month_select")
        
        # åº”ç”¨ç­›é€‰
        filtered_predictions = system.predictions.copy()
        
        if selected_segment != 'å…¨éƒ¨':
            filtered_predictions = filtered_predictions[
                filtered_predictions['äº§å“æ®µ'] == selected_segment
            ]
        
        if selected_month != 'å…¨éƒ¨':
            filtered_predictions = filtered_predictions[
                filtered_predictions['æœªæ¥æœˆä»½'] == selected_month
            ]
        
        # æ’åºé€‰é¡¹
        sort_by = st.selectbox("æ’åºæ–¹å¼", ["é¢„æµ‹é”€é‡(é™åº)", "é¢„æµ‹é”€é‡(å‡åº)", "äº§å“ä»£ç "], key="prediction_sort_select")
        
        if sort_by == "é¢„æµ‹é”€é‡(é™åº)":
            filtered_predictions = filtered_predictions.sort_values('é¢„æµ‹é”€é‡', ascending=False)
        elif sort_by == "é¢„æµ‹é”€é‡(å‡åº)":
            filtered_predictions = filtered_predictions.sort_values('é¢„æµ‹é”€é‡', ascending=True)
        else:
            filtered_predictions = filtered_predictions.sort_values('äº§å“ä»£ç ')
        
        # æ˜¾ç¤ºç­›é€‰åçš„æ•°æ®
        display_columns = ['äº§å“ä»£ç ', 'æœªæ¥æœˆä»½', 'é¢„æµ‹é”€é‡', 'ä¸‹é™', 'ä¸Šé™', 'äº§å“æ®µ', 'ä½¿ç”¨æ¨¡å‹']
        st.dataframe(
            filtered_predictions[display_columns], 
            use_container_width=True, 
            hide_index=True
        )
        
        # å¯¼å‡ºåŠŸèƒ½
        st.markdown("#### ğŸ’¾ å¯¼å‡ºé¢„æµ‹ç»“æœ")
        
        col_export1, col_export2 = st.columns([1, 1])
        
        with col_export1:
            if st.button("ğŸ“Š å¯¼å‡ºExcel", use_container_width=True, key="export_excel_button"):
                # åˆ›å»ºExcelæ–‡ä»¶
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    # é¢„æµ‹ç»“æœ
                    system.predictions.to_excel(writer, sheet_name='é¢„æµ‹ç»“æœ', index=False)
                    # æœˆåº¦æ±‡æ€»
                    monthly_summary.to_excel(writer, sheet_name='æœˆåº¦æ±‡æ€»', index=False)
                    # äº§å“æ®µæ±‡æ€»
                    segment_pred.to_excel(writer, sheet_name='äº§å“æ®µæ±‡æ€»', index=False)
                
                st.download_button(
                    "ğŸ“¥ ä¸‹è½½Excelæ–‡ä»¶",
                    output.getvalue(),
                    f"é”€é‡é¢„æµ‹ç»“æœ_{datetime.now().strftime('%Y%m%d')}.xlsx",
                    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    key="download_excel_button"
                )
        
        with col_export2:
            if st.button("ğŸ“‹ å¯¼å‡ºCSV", use_container_width=True, key="export_csv_button"):
                csv_data = system.predictions.to_csv(index=False)
                st.download_button(
                    "ğŸ“¥ ä¸‹è½½CSVæ–‡ä»¶",
                    csv_data,
                    f"é”€é‡é¢„æµ‹ç»“æœ_{datetime.now().strftime('%Y%m%d')}.csv",
                    "text/csv",
                    key="download_csv_button"
                )
    
    else:
        st.info("æš‚æ— é¢„æµ‹ç»“æœï¼Œè¯·å…ˆå®Œæˆæ¨¡å‹è®­ç»ƒ")

def show_insights_tab():
    """æ˜¾ç¤ºæ´å¯Ÿæ ‡ç­¾é¡µ"""
    st.markdown("### ğŸ’¡ æ·±åº¦æ´å¯Ÿ")
    
    if not st.session_state.model_trained:
        st.warning("âš ï¸ è¯·å…ˆè®­ç»ƒé¢„æµ‹æ¨¡å‹")
        return
    
    system = st.session_state.prediction_system
    
    # ç‰¹å¾é‡è¦æ€§åˆ†æ
    if 'XGBoost' in system.models['all_models']:
        st.markdown("#### ğŸ” ç‰¹å¾é‡è¦æ€§åˆ†æ")
        
        feature_importance = pd.DataFrame({
            'ç‰¹å¾': system.models['feature_cols'],
            'é‡è¦æ€§': system.models['all_models']['XGBoost'].feature_importances_
        }).sort_values('é‡è¦æ€§', ascending=False)
        
        # ç‰¹å¾åç§°æ˜ å°„ä¸ºä¸­æ–‡
        feature_name_map = {
            'qty_mean': 'é”€é‡å‡å€¼',
            'qty_median': 'é”€é‡ä¸­ä½æ•°', 
            'qty_std': 'é”€é‡æ ‡å‡†å·®',
            'qty_cv': 'é”€é‡å˜å¼‚ç³»æ•°',
            'log_qty_mean': 'å¯¹æ•°é”€é‡å‡å€¼',
            'log_qty_std': 'å¯¹æ•°é”€é‡æ ‡å‡†å·®',
            'qty_lag_1': 'æ»å1æœŸé”€é‡',
            'qty_lag_2': 'æ»å2æœŸé”€é‡',
            'qty_lag_3': 'æ»å3æœŸé”€é‡',
            'qty_ma_2': '2æœŸç§»åŠ¨å¹³å‡',
            'qty_ma_3': '3æœŸç§»åŠ¨å¹³å‡',
            'qty_wma_3': '3æœŸåŠ æƒç§»åŠ¨å¹³å‡',
            'growth_rate_1': 'å¢é•¿ç‡',
            'trend_slope': 'è¶‹åŠ¿æ–œç‡',
            'trend_strength': 'è¶‹åŠ¿å¼ºåº¦',
            'order_count_mean': 'è®¢å•æ•°å‡å€¼',
            'order_count_trend': 'è®¢å•æ•°è¶‹åŠ¿',
            'avg_order_size': 'å¹³å‡è®¢å•å¤§å°',
            'customer_count_mean': 'å®¢æˆ·æ•°å‡å€¼',
            'penetration_rate': 'æ¸—é€ç‡',
            'month': 'æœˆä»½',
            'quarter': 'å­£åº¦',
            'is_year_end': 'æ˜¯å¦å¹´æœ«',
            'is_peak_season': 'æ˜¯å¦æ—ºå­£',
            'data_points': 'æ•°æ®ç‚¹æ•°',
            'stability_score': 'ç¨³å®šæ€§å¾—åˆ†',
            'segment_encoded': 'äº§å“æ®µç¼–ç '
        }
        
        feature_importance['ç‰¹å¾åç§°'] = feature_importance['ç‰¹å¾'].map(feature_name_map).fillna(feature_importance['ç‰¹å¾'])
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            # å‰15ä¸ªé‡è¦ç‰¹å¾æŸ±çŠ¶å›¾
            top_features = feature_importance.head(15)
            
            fig_importance = px.bar(
                top_features,
                x='é‡è¦æ€§',
                y='ç‰¹å¾åç§°',
                orientation='h',
                title="å‰15ä¸ªé‡è¦ç‰¹å¾",
                color='é‡è¦æ€§',
                color_continuous_scale='Viridis'
            )
            fig_importance.update_layout(
                height=500,
                yaxis={'categoryorder': 'total ascending'}
            )
            st.plotly_chart(fig_importance, use_container_width=True)
        
        with col2:
            st.markdown("##### ğŸ“Š ç‰¹å¾é‡è¦æ€§è§£è¯»")
            st.markdown("""
            <div class="feature-card">
                <h4>ğŸ¯ å…³é”®å‘ç°</h4>
                <p><strong>æœ€é‡è¦ç‰¹å¾:</strong> {}</p>
                <p><strong>ç‰¹å¾ç±»å‹åˆ†å¸ƒ:</strong></p>
                <ul>
                    <li>ğŸ“ˆ å†å²é”€é‡ç‰¹å¾: å ä¸»å¯¼åœ°ä½</li>
                    <li>ğŸ“Š è¶‹åŠ¿ç‰¹å¾: ä¸­ç­‰é‡è¦</li>
                    <li>ğŸ“… æ—¶é—´ç‰¹å¾: è¾…åŠ©ä½œç”¨</li>
                    <li>ğŸ·ï¸ äº§å“æ®µç‰¹å¾: åˆ†ç±»ä¾æ®</li>
                </ul>
                <p><strong>å»ºè®®:</strong> é‡ç‚¹å…³æ³¨å‰10ä¸ªç‰¹å¾ï¼Œå®ƒä»¬è´¡çŒ®äº†å¤§éƒ¨åˆ†é¢„æµ‹èƒ½åŠ›ã€‚</p>
            </div>
            """.format(top_features.iloc[0]['ç‰¹å¾åç§°']), unsafe_allow_html=True)
            
            # ç‰¹å¾é‡è¦æ€§è¡¨æ ¼
            st.markdown("##### ğŸ“‹ è¯¦ç»†é‡è¦æ€§")
            st.dataframe(
                top_features[['ç‰¹å¾åç§°', 'é‡è¦æ€§']].round(4),
                use_container_width=True,
                hide_index=True
            )
    
    # äº§å“åˆ†æ®µåˆ†æ
    if system.historical_predictions is not None:
        st.markdown("#### ğŸ“Š äº§å“åˆ†æ®µæ€§èƒ½åˆ†æ")
        
        # æŒ‰äº§å“æ®µç»Ÿè®¡å‡†ç¡®ç‡
        segment_analysis = system.historical_predictions.groupby('äº§å“æ®µ').agg({
            'å‡†ç¡®ç‡(%)': ['mean', 'std', 'count'],
            'é¢„æµ‹å€¼': 'sum',
            'å®é™…å€¼': 'sum',
            'ç»å¯¹è¯¯å·®': 'mean'
        }).round(2)
        
        segment_analysis.columns = ['å¹³å‡å‡†ç¡®ç‡', 'å‡†ç¡®ç‡æ ‡å‡†å·®', 'é¢„æµ‹æ¬¡æ•°', 'é¢„æµ‹æ€»é‡', 'å®é™…æ€»é‡', 'å¹³å‡è¯¯å·®']
        segment_analysis = segment_analysis.reset_index()
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            # å„æ®µå‡†ç¡®ç‡å¯¹æ¯”
            fig_segment_perf = px.bar(
                segment_analysis,
                x='äº§å“æ®µ',
                y='å¹³å‡å‡†ç¡®ç‡',
                title="å„äº§å“æ®µå¹³å‡å‡†ç¡®ç‡",
                color='å¹³å‡å‡†ç¡®ç‡',
                color_continuous_scale='RdYlGn'
            )
            fig_segment_perf.update_layout(height=400)
            st.plotly_chart(fig_segment_perf, use_container_width=True)
        
        with col2:
            # é¢„æµ‹é‡vså®é™…é‡å¯¹æ¯”
            fig_pred_actual = go.Figure()
            
            fig_pred_actual.add_trace(go.Bar(
                x=segment_analysis['äº§å“æ®µ'],
                y=segment_analysis['é¢„æµ‹æ€»é‡'],
                name='é¢„æµ‹æ€»é‡',
                marker_color='#667eea'
            ))
            
            fig_pred_actual.add_trace(go.Bar(
                x=segment_analysis['äº§å“æ®µ'],
                y=segment_analysis['å®é™…æ€»é‡'],
                name='å®é™…æ€»é‡',
                marker_color='#4CAF50'
            ))
            
            fig_pred_actual.update_layout(
                title="å„äº§å“æ®µé¢„æµ‹vså®é™…æ€»é‡",
                height=400,
                barmode='group'
            )
            st.plotly_chart(fig_pred_actual, use_container_width=True)
        
        # è¯¦ç»†åˆ†æ®µè¡¨æ ¼
        st.markdown("##### ğŸ“‹ åˆ†æ®µè¯¦ç»†åˆ†æ")
        st.dataframe(segment_analysis, use_container_width=True, hide_index=True)
    
    # æ¨¡å‹æ€§èƒ½æ·±åº¦åˆ†æ
    st.markdown("#### ğŸ¤– æ¨¡å‹æ€§èƒ½æ·±åº¦åˆ†æ")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        # æ¨¡å‹å¯¹æ¯”æŸ±çŠ¶å›¾
        models_comparison = []
        for model_name, results in system.accuracy_results.items():
            models_comparison.append({
                'æ¨¡å‹': model_name,
                'SMAPEå‡†ç¡®ç‡': results['SMAPE_Accuracy'],
                'RÂ²å¾—åˆ†': results['RÂ²'] * 100,
                'ç¨³å®šæ€§': 100 - results['SMAPE'],
            })
        
        comparison_df = pd.DataFrame(models_comparison)
        
        fig_models = go.Figure()
        
        for metric in ['SMAPEå‡†ç¡®ç‡', 'RÂ²å¾—åˆ†', 'ç¨³å®šæ€§']:
            fig_models.add_trace(go.Bar(
                x=comparison_df['æ¨¡å‹'],
                y=comparison_df[metric],
                name=metric
            ))
        
        fig_models.update_layout(
            title="æ¨¡å‹æ€§èƒ½å…¨é¢å¯¹æ¯”",
            height=400,
            barmode='group'
        )
        st.plotly_chart(fig_models, use_container_width=True)
    
    with col2:
        st.markdown("##### ğŸ† æ¨¡å‹è¯„ä¼°ç»“è®º")
        
        best_model = system.models['best_model_name']
        best_accuracy = system.accuracy_results[best_model]['SMAPE_Accuracy']
        
        st.markdown(f"""
        <div class="feature-card">
            <h4>ğŸ¯ æœ€ä½³æ¨¡å‹: {best_model}</h4>
            <p><strong>SMAPEå‡†ç¡®ç‡:</strong> {best_accuracy:.1f}%</p>
            <p><strong>æ€§èƒ½ç­‰çº§:</strong> {'ğŸ† ä¼˜ç§€' if best_accuracy >= 90 else 'ğŸ‘ è‰¯å¥½' if best_accuracy >= 80 else 'âš ï¸ éœ€ä¼˜åŒ–'}</p>
            
            <h5>ğŸ“Š å„æ¨¡å‹ç‰¹ç‚¹:</h5>
            <ul>
                <li><strong>XGBoost:</strong> æ¢¯åº¦æå‡ï¼Œæ“…é•¿æ•æ‰å¤æ‚æ¨¡å¼</li>
                <li><strong>LightGBM:</strong> è½»é‡å¿«é€Ÿï¼Œå†…å­˜æ•ˆç‡é«˜</li>
                <li><strong>Random Forest:</strong> ç¨³å®šå¯é ï¼Œä¸æ˜“è¿‡æ‹Ÿåˆ</li>
                <li><strong>Ensemble:</strong> èåˆä¼˜åŠ¿ï¼Œç»¼åˆè¡¨ç°æœ€ä½³</li>
            </ul>
            
            <h5>ğŸ”§ ä¼˜åŒ–å»ºè®®:</h5>
            <p>ç»§ç»­æ”¶é›†æ›´å¤šæ•°æ®ï¼Œå®šæœŸé‡è®­ç»ƒæ¨¡å‹ï¼Œå…³æ³¨å­£èŠ‚æ€§å˜åŒ–ã€‚</p>
        </div>
        """, unsafe_allow_html=True)
    
    # æ•°æ®æºåˆ†æ
    st.markdown("#### ğŸ“¡ æ•°æ®æºåˆ†æ")
    
    data_source = system.data_summary.get('data_source', {})
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("##### ğŸ“Š æ•°æ®æ¦‚è§ˆ")
        st.markdown(f"""
        <div class="feature-card">
            <h4>ğŸ“ˆ æ•°æ®ç»Ÿè®¡</h4>
            <p><strong>æ€»è®°å½•æ•°:</strong> {system.data_summary.get('total_records', 0):,}</p>
            <p><strong>äº§å“æ•°é‡:</strong> {system.data_summary.get('total_products', 0):,}</p>
            <p><strong>å®¢æˆ·æ•°é‡:</strong> {system.data_summary.get('total_customers', 0):,}</p>
            <p><strong>åŒºåŸŸæ•°é‡:</strong> {system.data_summary.get('total_regions', 0):,}</p>
            <p><strong>æ€»é”€é‡:</strong> {system.data_summary.get('total_quantity', 0):,.0f} ç®±</p>
            <p><strong>æ—¥å‡é”€é‡:</strong> {system.data_summary.get('avg_daily_quantity', 0):,.0f} ç®±</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("##### ğŸ”— æ•°æ®æ¥æº")
        st.markdown(f"""
        <div class="feature-card">
            <h4>ğŸ“¡ GitHubæ•°æ®æº</h4>
            <p><strong>ä»“åº“:</strong> {data_source.get('github_repo', 'CIRA18-HUB/sales_dashboard')}</p>
            <p><strong>å‡ºè´§æ•°æ®:</strong> {data_source.get('shipment_source', 'N/A')}</p>
            <p><strong>ä¿ƒé”€æ•°æ®:</strong> {data_source.get('promotion_source', 'æœªæ‰¾åˆ°')}</p>
            <p><strong>åŠ è½½æ—¶é—´:</strong> {data_source.get('load_time', 'N/A')}</p>
            <p><strong>æ•°æ®ç±»å‹:</strong> çœŸå®GitHubæ•°æ®</p>
            <p><strong>æ•°æ®è´¨é‡:</strong> âœ… å·²éªŒè¯å’Œæ¸…æ´—</p>
        </div>
        """, unsafe_allow_html=True)

# ====================================================================
# ä¸»ç¨‹åº
# ====================================================================

def main():
    """ä¸»ç¨‹åº"""
    # æ¸²æŸ“å¤´éƒ¨
    render_header()
    
    # åˆ›å»ºä¾§è¾¹æ 
    test_ratio, months_ahead, outlier_factor, min_data_points, n_estimators, max_depth, learning_rate = create_sidebar()
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4 = st.tabs([
        "ğŸš€ æ¨¡å‹è®­ç»ƒ",
        "ğŸ“Š é¢„æµ‹åˆ†æ", 
        "ğŸ”® æœªæ¥é¢„æµ‹",
        "ğŸ’¡ æ·±åº¦æ´å¯Ÿ"
    ])
    
    with tab1:
        show_training_tab()
    
    with tab2:
        show_analysis_tab()
    
    with tab3:
        show_prediction_tab()
    
    with tab4:
        show_insights_tab()

if __name__ == "__main__":
    main()

# ====================================================================
# åº•éƒ¨ä¿¡æ¯
# ====================================================================
st.markdown("""
---
