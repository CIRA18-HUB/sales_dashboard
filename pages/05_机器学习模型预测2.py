# production_sales_prediction_system.py
"""
ç”Ÿäº§çº§é”€å”®é¢„æµ‹æ™ºèƒ½ç³»ç»Ÿ - 5æ˜Ÿæ ¸å¿ƒåŠŸèƒ½ç‰ˆ
==================================================

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. ğŸ¯ é¢„æµ‹è·Ÿè¸ªéªŒè¯ç³»ç»Ÿ - å­˜å‚¨é¢„æµ‹ï¼Œè·Ÿè¸ªçœŸå®å‡†ç¡®ç‡
2. ğŸ”” æ™ºèƒ½é¢„è­¦ç³»ç»Ÿ - ç›‘æ§æ¨¡å‹æ€§èƒ½ï¼ŒåŠæ—¶é¢„è­¦
3. ğŸ›ï¸ äº¤äº’å¼é¢„æµ‹è°ƒæ•´ - åœºæ™¯åˆ†æï¼Œä¸šåŠ¡å†³ç­–æ”¯æŒ
4. ğŸ“Š åŸºç¡€é¢„æµ‹å¼•æ“ - æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒå’Œé¢„æµ‹

ä½œè€…: AI Assistant
ç‰ˆæœ¬: v2.0 Production Ready
æ›´æ–°: 2025-06-04
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import warnings
import io
import json
import time
import smtplib


warnings.filterwarnings('ignore')

from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, r2_score
from sklearn.preprocessing import RobustScaler
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb
import lightgbm as lgb

# ====================================================================
# é¡µé¢é…ç½®
# ====================================================================
st.set_page_config(
    page_title="ç”Ÿäº§çº§é”€å”®é¢„æµ‹ç³»ç»Ÿ",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ====================================================================
# æ ·å¼å®šä¹‰
# ====================================================================
production_styles = """
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');

    .stApp {
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        min-height: 100vh;
    }

    .main {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        min-height: 100vh;
    }

    /* å¤´éƒ¨æ ·å¼ */
    .production-header {
        background: rgba(255, 255, 255, 0.95);
        backdrop-filter: blur(25px);
        border-radius: 20px;
        padding: 2rem;
        margin-bottom: 2rem;
        box-shadow: 0 10px 30px rgba(0,0,0,0.1);
        text-align: center;
    }

    .production-title {
        font-size: 3rem;
        font-weight: 800;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 1rem;
    }

    /* åŠŸèƒ½å¡ç‰‡ */
    .feature-card {
        background: rgba(255, 255, 255, 0.95);
        backdrop-filter: blur(25px);
        border-radius: 15px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 8px 25px rgba(0,0,0,0.1);
        border-left: 4px solid #667eea;
        transition: all 0.3s ease;
    }

    .feature-card:hover {
        transform: translateY(-3px);
        box-shadow: 0 12px 35px rgba(0,0,0,0.15);
    }

    /* çŠ¶æ€æŒ‡ç¤ºå™¨ */
    .status-indicator {
        width: 12px;
        height: 12px;
        border-radius: 50%;
        display: inline-block;
        margin-right: 0.5rem;
        animation: pulse 2s infinite;
    }

    .status-success { background-color: #4CAF50; }
    .status-warning { background-color: #FF9800; }
    .status-danger { background-color: #f44336; }

    @keyframes pulse {
        0% { transform: scale(1); opacity: 1; }
        50% { transform: scale(1.1); opacity: 0.8; }
        100% { transform: scale(1); opacity: 1; }
    }

    /* æŒ‡æ ‡å¡ç‰‡ */
    .metric-card {
        background: rgba(255, 255, 255, 0.95);
        border-radius: 15px;
        padding: 1.5rem;
        text-align: center;
        border-left: 4px solid #667eea;
        box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        height: 100%;
    }

    .metric-value {
        font-size: 2.5rem;
        font-weight: bold;
        color: #667eea;
    }

    .metric-label {
        font-size: 1rem;
        color: #666;
        margin-top: 0.5rem;
    }

    /* é¢„è­¦æ ·å¼ */
    .alert-card {
        border-radius: 10px;
        padding: 1rem;
        margin: 0.5rem 0;
        border-left: 4px solid;
    }

    .alert-success {
        background: rgba(76, 175, 80, 0.1);
        border-left-color: #4CAF50;
        color: #2E7D32;
    }

    .alert-warning {
        background: rgba(255, 152, 0, 0.1);
        border-left-color: #FF9800;
        color: #E65100;
    }

    .alert-danger {
        background: rgba(244, 67, 54, 0.1);
        border-left-color: #f44336;
        color: #C62828;
    }

    /* äº¤äº’æ§åˆ¶å™¨ */
    .control-panel {
        background: rgba(255, 255, 255, 0.9);
        border-radius: 10px;
        padding: 1rem;
        margin: 0.5rem 0;
        border-left: 4px solid #667eea;
    }

    /* éªŒè¯çŠ¶æ€ */
    .validation-pending {
        background: rgba(255, 193, 7, 0.1);
        border-left-color: #FFC107;
    }

    .validation-completed {
        background: rgba(76, 175, 80, 0.1);
        border-left-color: #4CAF50;
    }

    .validation-failed {
        background: rgba(244, 67, 54, 0.1);
        border-left-color: #f44336;
    }
</style>
"""

st.markdown(production_styles, unsafe_allow_html=True)


# ====================================================================
# Session State åˆå§‹åŒ–
# ====================================================================
def initialize_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    defaults = {
        'model_trained': False,
        'prediction_system': None,
        'prediction_archives': [],
        'actual_data_records': [],
        'validation_results': [],
        'alerts': [],
        'alert_settings': {
            'accuracy_threshold': 80.0,
            'bias_threshold': 15.0,
            'enable_email': False,
            'email_recipients': []
        },
        'adjustment_history': []
    }

    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value


initialize_session_state()


# ====================================================================
# æ ¸å¿ƒé¢„æµ‹ç³»ç»Ÿç±»
# ====================================================================
class ProductionSalesPredictionSystem:
    """ç”Ÿäº§çº§é”€å”®é¢„æµ‹ç³»ç»Ÿ"""

    def __init__(self):
        self.shipment_data = None
        self.promotion_data = None
        self.feature_data = None
        self.models = {}
        self.scalers = {}
        self.predictions = None
        self.accuracy_results = {}
        self.product_segments = {}
        self.historical_predictions = None
        self.feature_importance = None
        self.training_time = None
        self.data_summary = {}
        self.data_mode = 'sample'

    def load_data(self, use_github=False, shipment_file=None, promotion_file=None):
        """åŠ è½½æ•°æ®"""
        print("ğŸ“‚ åŠ è½½æ•°æ®...")

        if use_github:
            try:
                print("ğŸŒ ä»GitHubåŠ è½½çœŸå®æ•°æ®...")
                github_base_url = "https://github.com/charliedream1/ai_quant_trade/raw/main/ecommerce_ai/sales_forecast"
                shipment_url = f"{github_base_url}/é¢„æµ‹æ¨¡å‹å‡ºè´§æ•°æ®æ¯æ—¥xlsx.xlsx"
                promotion_url = f"{github_base_url}/é”€å”®ä¸šåŠ¡å‘˜ä¿ƒé”€æ–‡ä»¶.xlsx"

                self.shipment_data = pd.read_excel(shipment_url)
                self.promotion_data = pd.read_excel(promotion_url)
                self.data_mode = 'github_real'

                print(f"âœ… GitHubæ•°æ®åŠ è½½æˆåŠŸ: {len(self.shipment_data):,} æ¡è®°å½•")
                return True

            except Exception as e:
                print(f"âŒ GitHubæ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
                return self.load_sample_data()

        elif shipment_file is not None and promotion_file is not None:
            try:
                self.shipment_data = pd.read_excel(shipment_file)
                self.promotion_data = pd.read_excel(promotion_file)
                self.data_mode = 'upload_real'

                print(f"âœ… ä¸Šä¼ æ•°æ®åŠ è½½æˆåŠŸ: {len(self.shipment_data):,} æ¡è®°å½•")
                return True

            except Exception as e:
                print(f"âŒ ä¸Šä¼ æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
                return self.load_sample_data()
        else:
            return self.load_sample_data()

    def load_sample_data(self):
        """ç”Ÿæˆç¤ºä¾‹æ•°æ®"""
        print("ğŸ“‚ ç”Ÿæˆç¤ºä¾‹æ•°æ®...")
        self.data_mode = 'sample'

        try:
            np.random.seed(42)

            # ç”Ÿæˆç¤ºä¾‹å‡ºè´§æ•°æ®
            dates = pd.date_range('2022-01-01', '2025-05-31', freq='D')
            products = [f'F{i:04d}J' for i in range(104, 180)]
            regions = ['ååŒ—', 'åä¸œ', 'åå—', 'è¥¿å—', 'ä¸œåŒ—']
            customers = [f'CU{i:04d}' for i in range(100, 800)]

            data_records = []

            for product in products:
                base_qty = np.random.choice([10, 30, 50, 100, 200], p=[0.3, 0.3, 0.2, 0.15, 0.05])
                seasonal_pattern = np.sin(np.arange(len(dates)) * 2 * np.pi / 365) * 0.3 + 1

                for i, date in enumerate(dates):
                    if np.random.random() > 0.3:
                        continue

                    seasonal_factor = seasonal_pattern[i]
                    random_factor = np.random.normal(1, 0.3)
                    daily_qty = max(1, int(base_qty * seasonal_factor * random_factor))

                    if np.random.random() < 0.05:
                        daily_qty *= np.random.randint(2, 5)

                    data_records.append({
                        'è®¢å•æ—¥æœŸ': date,
                        'æ‰€å±åŒºåŸŸ': np.random.choice(regions),
                        'å®¢æˆ·ä»£ç ': np.random.choice(customers),
                        'äº§å“ä»£ç ': product,
                        'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰': daily_qty
                    })

            self.shipment_data = pd.DataFrame(data_records)

            # ç”Ÿæˆç¤ºä¾‹ä¿ƒé”€æ•°æ®
            promo_records = []
            for _ in range(50):
                start_date = np.random.choice(dates[:-30])
                end_date = start_date + timedelta(days=np.random.randint(7, 30))
                promo_records.append({
                    'ç”³è¯·æ—¶é—´': start_date - timedelta(days=np.random.randint(1, 10)),
                    'ç»é”€å•†ä»£ç ': np.random.choice(customers[:20]),
                    'äº§å“ä»£ç ': np.random.choice(products),
                    'ä¿ƒé”€å¼€å§‹ä¾›è´§æ—¶é—´': start_date,
                    'ä¿ƒé”€ç»“æŸä¾›è´§æ—¶é—´': end_date,
                    'é¢„è®¡é”€é‡ï¼ˆç®±ï¼‰': np.random.randint(100, 1000),
                    'èµ å“æ•°é‡ï¼ˆç®±ï¼‰': np.random.randint(10, 100)
                })

            self.promotion_data = pd.DataFrame(promo_records)

            print(f"âœ… ç¤ºä¾‹æ•°æ®ç”ŸæˆæˆåŠŸ: {len(self.shipment_data):,} æ¡è®°å½•, {len(products)} ä¸ªäº§å“")
            return True

        except Exception as e:
            print(f"âŒ ç¤ºä¾‹æ•°æ®ç”Ÿæˆå¤±è´¥: {str(e)}")
            return False

    def preprocess_data(self, progress_callback=None):
        """æ•°æ®é¢„å¤„ç†"""
        if progress_callback:
            progress_callback(0.3, "æ•°æ®é¢„å¤„ç†ä¸­...")

        print("ğŸ§¹ æ•°æ®é¢„å¤„ç†...")

        # åˆ—åæ ‡å‡†åŒ–
        shipment_columns = {
            'è®¢å•æ—¥æœŸ': 'order_date',
            'æ‰€å±åŒºåŸŸ': 'region',
            'å®¢æˆ·ä»£ç ': 'customer_code',
            'äº§å“ä»£ç ': 'product_code',
            'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰': 'quantity'
        }

        promotion_columns = {
            'ç”³è¯·æ—¶é—´': 'apply_date',
            'ç»é”€å•†ä»£ç ': 'dealer_code',
            'äº§å“ä»£ç ': 'product_code',
            'ä¿ƒé”€å¼€å§‹ä¾›è´§æ—¶é—´': 'promo_start_date',
            'ä¿ƒé”€ç»“æŸä¾›è´§æ—¶é—´': 'promo_end_date',
            'é¢„è®¡é”€é‡ï¼ˆç®±ï¼‰': 'expected_sales',
            'èµ å“æ•°é‡ï¼ˆç®±ï¼‰': 'gift_quantity'
        }

        # é‡å‘½ååˆ—
        for old_col, new_col in shipment_columns.items():
            if old_col in self.shipment_data.columns:
                self.shipment_data = self.shipment_data.rename(columns={old_col: new_col})

        for old_col, new_col in promotion_columns.items():
            if old_col in self.promotion_data.columns:
                self.promotion_data = self.promotion_data.rename(columns={old_col: new_col})

        # æ•°æ®ç±»å‹è½¬æ¢
        self.shipment_data['order_date'] = pd.to_datetime(self.shipment_data['order_date'])
        self.shipment_data['quantity'] = pd.to_numeric(self.shipment_data['quantity'], errors='coerce')

        # æ•°æ®æ¸…æ´—
        original_len = len(self.shipment_data)
        self.shipment_data = self.shipment_data.dropna(subset=['order_date', 'product_code', 'quantity'])
        self.shipment_data = self.shipment_data[self.shipment_data['quantity'] > 0]

        print(f"âœ… åŸºç¡€æ¸…æ´—: {original_len} â†’ {len(self.shipment_data)} è¡Œ")

        # å¼‚å¸¸å€¼å¤„ç†
        self.shipment_data = self._remove_outliers_iqr(self.shipment_data)

        # äº§å“åˆ†æ®µ
        self._segment_products()

        # æ•°æ®æ‘˜è¦
        self.data_summary = {
            'total_records': len(self.shipment_data),
            'total_products': self.shipment_data['product_code'].nunique(),
            'date_range': (self.shipment_data['order_date'].min(), self.shipment_data['order_date'].max()),
            'total_quantity': self.shipment_data['quantity'].sum(),
            'avg_daily_quantity': self.shipment_data.groupby('order_date')['quantity'].sum().mean()
        }

        if progress_callback:
            progress_callback(0.4, f"âœ… é¢„å¤„ç†å®Œæˆ: {len(self.shipment_data)} è¡Œ")

        return True

    def _remove_outliers_iqr(self, data, column='quantity', factor=3.0):
        """IQRå¼‚å¸¸å€¼å¤„ç†"""
        Q1 = data[column].quantile(0.25)
        Q3 = data[column].quantile(0.75)
        IQR = Q3 - Q1

        lower_bound = Q1 - factor * IQR
        upper_bound = Q3 + factor * IQR

        outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]
        data_cleaned = data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]

        print(f"ğŸ”§ å¼‚å¸¸å€¼å¤„ç†: {len(data)} â†’ {len(data_cleaned)} (ç§»é™¤ {len(outliers)} ä¸ª)")

        return data_cleaned

    def _segment_products(self):
        """äº§å“åˆ†æ®µ"""
        print("ğŸ“Š äº§å“åˆ†æ®µ...")

        product_stats = self.shipment_data.groupby('product_code')['quantity'].agg([
            'count', 'mean', 'std', 'sum', 'min', 'max'
        ]).reset_index()

        product_stats['cv'] = product_stats['std'] / product_stats['mean']
        product_stats['cv'] = product_stats['cv'].fillna(0)

        volume_high = product_stats['mean'].quantile(0.67)
        volume_low = product_stats['mean'].quantile(0.33)
        cv_high = product_stats['cv'].quantile(0.67)

        def classify_product(row):
            if row['mean'] >= volume_high:
                return 'é«˜é”€é‡ç¨³å®š' if row['cv'] <= cv_high else 'é«˜é”€é‡æ³¢åŠ¨'
            elif row['mean'] >= volume_low:
                return 'ä¸­é”€é‡ç¨³å®š' if row['cv'] <= cv_high else 'ä¸­é”€é‡æ³¢åŠ¨'
            else:
                return 'ä½é”€é‡ç¨³å®š' if row['cv'] <= cv_high else 'ä½é”€é‡æ³¢åŠ¨'

        product_stats['segment'] = product_stats.apply(classify_product, axis=1)
        self.product_segments = dict(zip(product_stats['product_code'], product_stats['segment']))

        segment_counts = product_stats['segment'].value_counts()
        print("ğŸ“Š äº§å“åˆ†æ®µç»“æœ:")
        for segment, count in segment_counts.items():
            print(f"   {segment}: {count} ä¸ªäº§å“")

        return product_stats

    def create_features(self, progress_callback=None):
        """ç‰¹å¾å·¥ç¨‹"""
        if progress_callback:
            progress_callback(0.5, "ç‰¹å¾å·¥ç¨‹å¤„ç†ä¸­...")

        print("ğŸ”§ ç‰¹å¾å·¥ç¨‹...")

        # æœˆåº¦èšåˆ
        monthly_data = self.shipment_data.groupby([
            'product_code',
            self.shipment_data['order_date'].dt.to_period('M')
        ]).agg({
            'quantity': ['sum', 'count', 'mean', 'std'],
            'customer_code': 'nunique',
            'region': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.iloc[0]
        }).reset_index()

        monthly_data.columns = ['product_code', 'year_month', 'total_qty', 'order_count',
                                'avg_qty', 'std_qty', 'customer_count', 'main_region']
        monthly_data['std_qty'] = monthly_data['std_qty'].fillna(0)
        monthly_data = monthly_data.sort_values(['product_code', 'year_month'])

        print(f"ğŸ“Š æœˆåº¦æ•°æ®: {len(monthly_data)} è¡Œ")

        # ç‰¹å¾åˆ›å»º
        all_features = []

        for segment in self.product_segments.values():
            segment_products = [k for k, v in self.product_segments.items() if v == segment]
            segment_data = monthly_data[monthly_data['product_code'].isin(segment_products)]

            for product in segment_products:
                product_data = segment_data[segment_data['product_code'] == product].copy()

                if len(product_data) < 4:
                    continue

                for idx in range(3, len(product_data)):
                    features = self._create_product_features(
                        product, product_data.iloc[:idx], segment
                    )

                    target_row = product_data.iloc[idx]
                    features['target'] = target_row['total_qty']
                    features['target_month'] = str(target_row['year_month'])
                    features['segment'] = segment

                    all_features.append(features)

        self.feature_data = pd.DataFrame(all_features)

        if len(self.feature_data) == 0:
            print("âŒ ç‰¹å¾åˆ›å»ºå¤±è´¥")
            return False

        print(f"âœ… ç‰¹å¾æ•°æ®: {len(self.feature_data)} è¡Œ, {len(self.feature_data.columns) - 4} ä¸ªç‰¹å¾")

        self._post_process_features()

        if progress_callback:
            progress_callback(0.6, f"âœ… ç‰¹å¾å®Œæˆ: {len(self.feature_data)} æ ·æœ¬")

        return True

    def _create_product_features(self, product_code, historical_data, segment):
        """åˆ›å»ºäº§å“ç‰¹å¾"""
        features = {'product_code': product_code}

        if len(historical_data) < 3:
            return features

        qty_values = historical_data['total_qty'].values
        order_counts = historical_data['order_count'].values
        customer_counts = historical_data['customer_count'].values

        # é”€é‡ç‰¹å¾
        log_qty = np.log1p(qty_values)

        features.update({
            'qty_mean': np.mean(qty_values),
            'qty_median': np.median(qty_values),
            'qty_std': np.std(qty_values),
            'qty_cv': np.std(qty_values) / (np.mean(qty_values) + 1),
            'log_qty_mean': np.mean(log_qty),
            'log_qty_std': np.std(log_qty),
            'qty_lag_1': qty_values[-1],
            'qty_lag_2': qty_values[-2] if len(qty_values) > 1 else 0,
            'qty_lag_3': qty_values[-3] if len(qty_values) > 2 else 0,
            'qty_ma_2': np.mean(qty_values[-2:]),
            'qty_ma_3': np.mean(qty_values[-3:]),
            'qty_wma_3': np.average(qty_values[-3:], weights=[1, 2, 3]) if len(qty_values) >= 3 else np.mean(
                qty_values),
        })

        # è¶‹åŠ¿ç‰¹å¾
        if len(qty_values) > 1:
            features['growth_rate_1'] = (qty_values[-1] - qty_values[-2]) / (qty_values[-2] + 1)

            if len(qty_values) > 2:
                x = np.arange(len(qty_values))
                trend_coef = np.polyfit(x, qty_values, 1)[0]
                features['trend_slope'] = trend_coef

                y_pred = np.polyval([trend_coef, np.mean(qty_values)], x)
                ss_res = np.sum((qty_values - y_pred) ** 2)
                ss_tot = np.sum((qty_values - np.mean(qty_values)) ** 2)
                features['trend_strength'] = 1 - (ss_res / (ss_tot + 1e-8))
            else:
                features['trend_slope'] = 0
                features['trend_strength'] = 0
        else:
            features['growth_rate_1'] = 0
            features['trend_slope'] = 0
            features['trend_strength'] = 0

        # è®¢å•ç‰¹å¾
        features.update({
            'order_count_mean': np.mean(order_counts),
            'order_count_trend': order_counts[-1] - order_counts[0] if len(order_counts) > 1 else 0,
            'avg_order_size': features['qty_mean'] / (np.mean(order_counts) + 1),
            'customer_count_mean': np.mean(customer_counts),
            'penetration_rate': np.mean(customer_counts) / (np.max(customer_counts) + 1)
        })

        # æ—¶é—´ç‰¹å¾
        last_month = historical_data.iloc[-1]['year_month']
        features.update({
            'month': last_month.month,
            'quarter': last_month.quarter,
            'is_year_end': 1 if last_month.month in [11, 12] else 0,
            'is_peak_season': 1 if last_month.month in [3, 4, 10, 11] else 0,
        })

        # ç¨³å®šæ€§ç‰¹å¾
        features.update({
            'data_points': len(qty_values),
            'stability_score': 1 / (1 + features['qty_cv']),
            'consistency_score': len(qty_values[qty_values > 0]) / len(qty_values),
        })

        # äº§å“æ®µç‰¹å¾
        segment_map = {
            'é«˜é”€é‡ç¨³å®š': 1, 'é«˜é”€é‡æ³¢åŠ¨': 2,
            'ä¸­é”€é‡ç¨³å®š': 3, 'ä¸­é”€é‡æ³¢åŠ¨': 4,
            'ä½é”€é‡ç¨³å®š': 5, 'ä½é”€é‡æ³¢åŠ¨': 6
        }
        features['segment_encoded'] = segment_map.get(segment, 0)

        return features

    def _post_process_features(self):
        """ç‰¹å¾åå¤„ç†"""
        print("ğŸ”§ ç‰¹å¾åå¤„ç†...")

        feature_cols = [col for col in self.feature_data.columns
                        if col not in ['product_code', 'target', 'target_month', 'segment']]

        self.feature_data[feature_cols] = self.feature_data[feature_cols].replace([np.inf, -np.inf], np.nan)
        self.feature_data[feature_cols] = self.feature_data[feature_cols].fillna(0)

        constant_features = []
        for col in feature_cols:
            if self.feature_data[col].std() == 0:
                constant_features.append(col)

        if constant_features:
            print(f"  ç§»é™¤å¸¸æ•°ç‰¹å¾: {constant_features}")
            self.feature_data = self.feature_data.drop(columns=constant_features)

        print(
            f"âœ… æœ€ç»ˆç‰¹å¾æ•°: {len([col for col in self.feature_data.columns if col not in ['product_code', 'target', 'target_month', 'segment']])}")

    def train_models(self, test_ratio=0.2, progress_callback=None):
        """è®­ç»ƒæ¨¡å‹"""
        if progress_callback:
            progress_callback(0.7, "æ¨¡å‹è®­ç»ƒä¸­...")

        print("ğŸš€ æ¨¡å‹è®­ç»ƒ...")
        start_time = time.time()

        if self.feature_data is None or len(self.feature_data) == 0:
            print("âŒ æ²¡æœ‰ç‰¹å¾æ•°æ®")
            return False

        feature_cols = [col for col in self.feature_data.columns
                        if col not in ['product_code', 'target', 'target_month', 'segment']]

        X = self.feature_data[feature_cols]
        y = self.feature_data['target']
        y_log = np.log1p(y)

        print(f"ğŸ“Š è®­ç»ƒæ•°æ®: {len(X)} æ ·æœ¬, {len(feature_cols)} ç‰¹å¾")

        # æ—¶é—´åºåˆ—åˆ†å‰²
        n_samples = len(X)
        split_point = int(n_samples * (1 - test_ratio))

        X_train, X_test = X[:split_point], X[split_point:]
        y_train, y_test = y[:split_point], y[split_point:]
        y_log_train, y_log_test = y_log[:split_point], y_log[split_point:]

        # ç‰¹å¾æ ‡å‡†åŒ–
        scaler = RobustScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        self.scalers['feature_scaler'] = scaler

        print(f"ğŸ“ˆ è®­ç»ƒé›†: {len(X_train)}, æµ‹è¯•é›†: {len(X_test)}")

        # è®­ç»ƒæ¨¡å‹
        models = {}
        predictions = {}
        random_state = 42

        # XGBoost
        if progress_callback:
            progress_callback(0.75, "è®­ç»ƒXGBoost...")

        print("ğŸ¯ XGBoostè®­ç»ƒ...")
        xgb_model = xgb.XGBRegressor(
            n_estimators=300,
            max_depth=5,
            learning_rate=0.05,
            subsample=0.8,
            colsample_bytree=0.8,
            reg_alpha=0.1,
            reg_lambda=0.1,
            random_state=random_state,
            n_jobs=-1
        )
        xgb_model.fit(X_train_scaled, y_log_train, verbose=False)
        xgb_pred = np.expm1(xgb_model.predict(X_test_scaled))

        models['XGBoost'] = xgb_model
        predictions['XGBoost'] = xgb_pred

        # LightGBM
        if progress_callback:
            progress_callback(0.85, "è®­ç»ƒLightGBM...")

        print("ğŸ¯ LightGBMè®­ç»ƒ...")
        lgb_model = lgb.LGBMRegressor(
            n_estimators=300,
            max_depth=5,
            learning_rate=0.05,
            subsample=0.8,
            colsample_bytree=0.8,
            reg_alpha=0.1,
            reg_lambda=0.1,
            random_state=random_state,
            n_jobs=-1,
            verbose=-1
        )
        lgb_model.fit(X_train_scaled, y_log_train)
        lgb_pred = np.expm1(lgb_model.predict(X_test_scaled))

        models['LightGBM'] = lgb_model
        predictions['LightGBM'] = lgb_pred

        # Random Forest
        if progress_callback:
            progress_callback(0.9, "è®­ç»ƒRandom Forest...")

        print("ğŸ¯ Random Forestè®­ç»ƒ...")
        rf_model = RandomForestRegressor(
            n_estimators=200,
            max_depth=10,
            min_samples_split=5,
            min_samples_leaf=2,
            random_state=random_state,
            n_jobs=-1
        )
        rf_model.fit(X_train_scaled, y_train)
        rf_pred = rf_model.predict(X_test_scaled)

        models['RandomForest'] = rf_model
        predictions['RandomForest'] = rf_pred

        # æ¨¡å‹è¯„ä¼°
        results = {}

        for model_name, pred in predictions.items():
            pred = np.maximum(pred, 0)

            mae = np.mean(np.abs(y_test - pred))
            rmse = np.sqrt(mean_squared_error(y_test, pred))

            # SMAPEå‡†ç¡®ç‡
            smape_accuracies = self.calculate_batch_robust_accuracy(
                y_test.values, pred, method='smape'
            )
            smape_accuracy = np.mean(smape_accuracies)

            r2 = r2_score(y_test, pred)

            results[model_name] = {
                'SMAPE_Accuracy': smape_accuracy,
                'MAE': mae,
                'RMSE': rmse,
                'RÂ²': r2
            }

            print(f"  {model_name}: SMAPEå‡†ç¡®ç‡ {smape_accuracy:.1f}%")

        # é€‰æ‹©æœ€ä½³æ¨¡å‹
        best_model_name = max(results.keys(), key=lambda x: results[x]['SMAPE_Accuracy'])

        # ç”Ÿæˆå†å²é¢„æµ‹
        if progress_callback:
            progress_callback(0.95, "ç”Ÿæˆå†å²é¢„æµ‹...")

        self._generate_historical_predictions(
            models[best_model_name], best_model_name, feature_cols, scaler
        )

        # ä¿å­˜æ¨¡å‹
        self.models = {
            'best_model': models[best_model_name],
            'best_model_name': best_model_name,
            'all_models': models,
            'feature_cols': feature_cols,
            'log_transform': best_model_name in ['XGBoost', 'LightGBM']
        }

        self.accuracy_results = results
        self.training_time = time.time() - start_time

        # ç‰¹å¾é‡è¦æ€§
        if 'XGBoost' in models:
            self.feature_importance = pd.DataFrame({
                'ç‰¹å¾': feature_cols,
                'é‡è¦æ€§': models['XGBoost'].feature_importances_
            }).sort_values('é‡è¦æ€§', ascending=False)

        if progress_callback:
            best_accuracy = results[best_model_name]['SMAPE_Accuracy']
            progress_callback(1.0, f"âœ… è®­ç»ƒå®Œæˆ! {best_model_name}: {best_accuracy:.1f}%")

        print(f"ğŸ† æœ€ä½³æ¨¡å‹: {best_model_name} (å‡†ç¡®ç‡: {results[best_model_name]['SMAPE_Accuracy']:.1f}%)")

        return True

    def calculate_robust_accuracy(self, actual_value, predicted_value, method='smape'):
        """è®¡ç®—å‡†ç¡®ç‡"""
        if method == 'smape':
            if actual_value == 0 and predicted_value == 0:
                return 100.0
            smape = 200 * abs(actual_value - predicted_value) / (abs(actual_value) + abs(predicted_value) + 1e-8)
            return max(0, 100 - smape)

        return 0.0

    def calculate_batch_robust_accuracy(self, actual_values, predicted_values, method='smape'):
        """æ‰¹é‡è®¡ç®—å‡†ç¡®ç‡"""
        actual_values = np.array(actual_values)
        predicted_values = np.array(predicted_values)

        if method == 'smape':
            both_zero = (actual_values == 0) & (predicted_values == 0)
            smape = 200 * np.abs(actual_values - predicted_values) / (
                    np.abs(actual_values) + np.abs(predicted_values) + 1e-8
            )
            accuracy = np.maximum(0, 100 - smape)
            accuracy[both_zero] = 100.0
            return accuracy

        return np.zeros_like(actual_values)

    def _generate_historical_predictions(self, model, model_name, feature_cols, scaler):
        """ç”Ÿæˆå†å²é¢„æµ‹"""
        print("ğŸ“Š ç”Ÿæˆå†å²é¢„æµ‹...")

        all_predictions = []
        products = self.feature_data['product_code'].unique()

        for i, product in enumerate(products):
            if i % 20 == 0:
                print(f"  è¿›åº¦: {i}/{len(products)}")

            product_monthly = self.shipment_data[
                self.shipment_data['product_code'] == product
                ].copy()

            product_monthly['year_month'] = product_monthly['order_date'].dt.to_period('M')
            monthly_agg = product_monthly.groupby('year_month').agg({
                'quantity': ['sum', 'count', 'mean', 'std'],
                'customer_code': 'nunique',
                'region': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.iloc[0]
            }).reset_index()

            monthly_agg.columns = ['year_month', 'total_qty', 'order_count',
                                   'avg_qty', 'std_qty', 'customer_count', 'main_region']
            monthly_agg['std_qty'] = monthly_agg['std_qty'].fillna(0)
            monthly_agg = monthly_agg.sort_values('year_month')

            if len(monthly_agg) < 4:
                continue

            segment = self.product_segments.get(product, 'ä¸­é”€é‡ç¨³å®š')

            for j in range(3, len(monthly_agg)):
                historical_data = monthly_agg.iloc[:j]
                features = self._create_product_features(product, historical_data, segment)

                feature_vector = pd.DataFrame([features])[feature_cols]
                X_scaled = scaler.transform(feature_vector)

                if model_name in ['XGBoost', 'LightGBM']:
                    pred_log = model.predict(X_scaled)[0]
                    pred_value = np.expm1(pred_log)
                else:
                    pred_value = model.predict(X_scaled)[0]

                pred_value = max(0, pred_value)
                actual_value = monthly_agg.iloc[j]['total_qty']
                target_month = monthly_agg.iloc[j]['year_month']

                accuracy = self.calculate_robust_accuracy(actual_value, pred_value, method='smape')
                error = abs(actual_value - pred_value)

                all_predictions.append({
                    'äº§å“ä»£ç ': product,
                    'å¹´æœˆ': str(target_month),
                    'é¢„æµ‹å€¼': round(pred_value, 2),
                    'å®é™…å€¼': round(actual_value, 2),
                    'ç»å¯¹è¯¯å·®': round(error, 2),
                    'å‡†ç¡®ç‡(%)': round(accuracy, 2),
                    'äº§å“æ®µ': segment
                })

        self.historical_predictions = pd.DataFrame(all_predictions)
        print(f"âœ… ç”Ÿæˆ {len(all_predictions)} æ¡å†å²é¢„æµ‹")

    def predict_future(self, months_ahead=3, product_list=None):
        """é¢„æµ‹æœªæ¥é”€é‡"""
        print(f"ğŸ”® é¢„æµ‹æœªæ¥{months_ahead}ä¸ªæœˆ...")

        if not self.models:
            print("âŒ æ¨¡å‹æœªè®­ç»ƒ")
            return None

        predictions = []

        if product_list is None:
            product_list = list(self.product_segments.keys())

        for product in product_list:
            if product not in self.product_segments:
                continue

            product_features = self.feature_data[
                self.feature_data['product_code'] == product
                ].tail(1)

            if len(product_features) == 0:
                continue

            segment = self.product_segments[product]

            for month in range(1, months_ahead + 1):
                X = product_features[self.models['feature_cols']]
                X_scaled = self.scalers['feature_scaler'].transform(X)

                if self.models['log_transform']:
                    pred_log = self.models['best_model'].predict(X_scaled)[0]
                    final_pred = np.expm1(pred_log)
                else:
                    final_pred = self.models['best_model'].predict(X_scaled)[0]

                final_pred = max(0, final_pred)

                confidence_factor = self._get_confidence_factor(segment)
                lower_bound = max(0, final_pred * (1 - confidence_factor))
                upper_bound = final_pred * (1 + confidence_factor)

                predictions.append({
                    'äº§å“ä»£ç ': product,
                    'æœªæ¥æœˆä»½': month,
                    'é¢„æµ‹é”€é‡': round(final_pred, 2),
                    'ä¸‹é™': round(lower_bound, 2),
                    'ä¸Šé™': round(upper_bound, 2),
                    'ç½®ä¿¡åº¦': f"{(1 - confidence_factor) * 100:.1f}%",
                    'äº§å“æ®µ': segment,
                    'æ¨¡å‹': self.models['best_model_name']
                })

        self.predictions = pd.DataFrame(predictions)
        print(f"âœ… å®Œæˆ {len(product_list)} ä¸ªäº§å“é¢„æµ‹")

        return self.predictions

    def _get_confidence_factor(self, segment):
        """è·å–ç½®ä¿¡åº¦å› å­"""
        confidence_map = {
            'é«˜é”€é‡ç¨³å®š': 0.15,
            'é«˜é”€é‡æ³¢åŠ¨': 0.25,
            'ä¸­é”€é‡ç¨³å®š': 0.20,
            'ä¸­é”€é‡æ³¢åŠ¨': 0.30,
            'ä½é”€é‡ç¨³å®š': 0.25,
            'ä½é”€é‡æ³¢åŠ¨': 0.35
        }
        return confidence_map.get(segment, 0.25)


# ====================================================================
# é¢„æµ‹è·Ÿè¸ªéªŒè¯ç³»ç»Ÿ
# ====================================================================
class PredictionTrackingSystem:
    """é¢„æµ‹è·Ÿè¸ªéªŒè¯ç³»ç»Ÿ"""

    def __init__(self):
        pass

    def save_prediction_archive(self, predictions_df, model_info):
        """ä¿å­˜é¢„æµ‹æ¡£æ¡ˆ"""
        prediction_id = f"PRED_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        archive = {
            'prediction_id': prediction_id,
            'creation_date': datetime.now(),
            'prediction_months': predictions_df['æœªæ¥æœˆä»½'].unique().tolist(),
            'target_months': self._calculate_target_months(predictions_df),
            'model_info': model_info,
            'predictions_data': predictions_df.to_dict('records'),
            'product_count': len(predictions_df['äº§å“ä»£ç '].unique()),
            'total_predicted_volume': predictions_df['é¢„æµ‹é”€é‡'].sum(),
            'status': 'pending_validation',
            'validation_progress': 0.0
        }

        return archive

    def _calculate_target_months(self, predictions_df):
        """è®¡ç®—ç›®æ ‡æœˆä»½"""
        base_date = datetime.now()
        target_months = []

        for month_ahead in predictions_df['æœªæ¥æœˆä»½'].unique():
            target_date = base_date + timedelta(days=30 * month_ahead)
            target_months.append({
                'month_ahead': month_ahead,
                'target_month': target_date.strftime('%Y-%m'),
                'target_date': target_date,
                'due_date': target_date + timedelta(days=45)
            })

        return target_months

    def add_actual_data(self, actual_data_df, reference_month):
        """æ·»åŠ å®é™…é”€å”®æ•°æ®"""
        record = {
            'record_id': f"ACTUAL_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            'input_date': datetime.now(),
            'reference_month': reference_month,
            'actual_data': actual_data_df.to_dict('records'),
            'product_count': len(actual_data_df['äº§å“ä»£ç '].unique()),
            'total_actual_volume': actual_data_df['å®é™…é”€é‡'].sum()
        }

        return record

    def validate_prediction(self, prediction_archive, actual_record, base_system):
        """éªŒè¯é¢„æµ‹å‡†ç¡®ç‡"""
        predictions_data = pd.DataFrame(prediction_archive['predictions_data'])
        actual_data = pd.DataFrame(actual_record['actual_data'])

        # åŒ¹é…é¢„æµ‹å’Œå®é™…æ•°æ®
        merged_data = predictions_data.merge(
            actual_data,
            on='äº§å“ä»£ç ',
            how='inner'
        )

        if len(merged_data) == 0:
            return None

        # è®¡ç®—éªŒè¯æŒ‡æ ‡
        predicted = merged_data['é¢„æµ‹é”€é‡'].values
        actual = merged_data['å®é™…é”€é‡'].values

        # è®¡ç®—å‡†ç¡®ç‡
        accuracies = base_system.calculate_batch_robust_accuracy(actual, predicted, method='smape')

        mae = np.mean(np.abs(actual - predicted))
        rmse = np.sqrt(np.mean((actual - predicted) ** 2))

        validation_result = {
            'smape_accuracy': np.mean(accuracies),
            'mae': mae,
            'rmse': rmse,
            'predictions_count': len(merged_data),
            'individual_accuracies': accuracies.tolist()
        }

        validation_record = {
            'validation_id': f"VAL_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            'prediction_id': prediction_archive['prediction_id'],
            'actual_record_id': actual_record['record_id'],
            'validation_date': datetime.now(),
            'validation_month': actual_record['reference_month'],
            'metrics': validation_result,
            'matched_products': len(merged_data),
            'detailed_results': merged_data.to_dict('records')
        }

        return validation_record


# ====================================================================
# æ™ºèƒ½é¢„è­¦ç³»ç»Ÿ
# ====================================================================
class IntelligentAlertSystem:
    """æ™ºèƒ½é¢„è­¦ç³»ç»Ÿ"""

    def __init__(self, base_system):
        self.base_system = base_system
        self.alerts = []

    def check_all_alerts(self, alert_settings):
        """æ£€æŸ¥æ‰€æœ‰é¢„è­¦æ¡ä»¶"""
        self.alerts = []

        # 1. å‡†ç¡®ç‡é¢„è­¦
        self._check_accuracy_alerts(alert_settings)

        # 2. é¢„æµ‹åå·®é¢„è­¦
        self._check_bias_alerts(alert_settings)

        # 3. æ•°æ®è´¨é‡é¢„è­¦
        self._check_data_quality_alerts()

        return self.alerts

    def _check_accuracy_alerts(self, settings):
        """æ£€æŸ¥å‡†ç¡®ç‡é¢„è­¦"""
        if self.base_system.historical_predictions is not None:
            recent_accuracy = self.base_system.historical_predictions.tail(50)['å‡†ç¡®ç‡(%)'].mean()
            threshold = settings.get('accuracy_threshold', 80.0)

            if recent_accuracy < threshold * 0.7:  # ä¸¥é‡é¢„è­¦
                self.alerts.append({
                    'level': 'danger',
                    'type': 'accuracy',
                    'title': 'ğŸš¨ å‡†ç¡®ç‡ä¸¥é‡ä¸‹é™',
                    'message': f'æœ€è¿‘é¢„æµ‹å‡†ç¡®ç‡é™è‡³{recent_accuracy:.1f}%ï¼Œä½äºé˜ˆå€¼{threshold}%',
                    'recommendation': 'ç«‹å³æ£€æŸ¥æ¨¡å‹å’Œæ•°æ®ï¼Œå¯èƒ½éœ€è¦é‡æ–°è®­ç»ƒ',
                    'timestamp': datetime.now()
                })
            elif recent_accuracy < threshold:  # ä¸€èˆ¬é¢„è­¦
                self.alerts.append({
                    'level': 'warning',
                    'type': 'accuracy',
                    'title': 'âš ï¸ å‡†ç¡®ç‡ä¸‹é™',
                    'message': f'æœ€è¿‘é¢„æµ‹å‡†ç¡®ç‡ä¸º{recent_accuracy:.1f}%ï¼Œä½äºé˜ˆå€¼{threshold}%',
                    'recommendation': 'å…³æ³¨æ¨¡å‹è¡¨ç°ï¼Œè€ƒè™‘ä¼˜åŒ–',
                    'timestamp': datetime.now()
                })

    def _check_bias_alerts(self, settings):
        """æ£€æŸ¥é¢„æµ‹åå·®é¢„è­¦"""
        if self.base_system.historical_predictions is not None:
            df = self.base_system.historical_predictions
            bias = df['é¢„æµ‹å€¼'] - df['å®é™…å€¼']
            recent_bias = bias.tail(30).mean()
            threshold = settings.get('bias_threshold', 15.0)

            if abs(recent_bias) > threshold:
                level = 'warning' if abs(recent_bias) < threshold * 1.5 else 'danger'
                direction = 'é«˜ä¼°' if recent_bias > 0 else 'ä½ä¼°'

                self.alerts.append({
                    'level': level,
                    'type': 'bias',
                    'title': f'ğŸ“Š é¢„æµ‹{direction}åå·®',
                    'message': f'æœ€è¿‘é¢„æµ‹å¹³å‡{direction}{abs(recent_bias):.1f}ç®±ï¼Œè¶…è¿‡é˜ˆå€¼{threshold}',
                    'recommendation': f'æ¨¡å‹å­˜åœ¨ç³»ç»Ÿæ€§{direction}ï¼Œå»ºè®®è°ƒæ•´å‚æ•°',
                    'timestamp': datetime.now()
                })

    def _check_data_quality_alerts(self):
        """æ£€æŸ¥æ•°æ®è´¨é‡é¢„è­¦"""
        if hasattr(self.base_system, 'data_summary'):
            summary = self.base_system.data_summary

            # æ£€æŸ¥æ•°æ®æ–°é²œåº¦
            latest_date = summary.get('date_range', (None, None))[1]
            if latest_date:
                days_since_latest = (datetime.now().date() - latest_date.date()).days

                if days_since_latest > 7:
                    self.alerts.append({
                        'level': 'warning',
                        'type': 'data_quality',
                        'title': 'ğŸ“… æ•°æ®æ›´æ–°æ»å',
                        'message': f'æœ€æ–°æ•°æ®æ—¶é—´ä¸º{latest_date.date()}ï¼Œå·²æœ‰{days_since_latest}å¤©æœªæ›´æ–°',
                        'recommendation': 'å»ºè®®æ£€æŸ¥æ•°æ®æºï¼Œç¡®ä¿åŠæ—¶æ›´æ–°',
                        'timestamp': datetime.now()
                    })

    def send_alert_notification(self, alert, settings):
        """å‘é€é¢„è­¦é€šçŸ¥"""
        if settings.get('enable_email', False):
            self._send_email_alert(alert, settings)

        # è¿™é‡Œå¯ä»¥æ·»åŠ å…¶ä»–é€šçŸ¥æ–¹å¼ï¼šé’‰é’‰ã€ä¼ä¸šå¾®ä¿¡ç­‰

    def _send_email_alert(self, alert, settings):
        """å‘é€é‚®ä»¶é¢„è­¦"""
        try:
            # é‚®ä»¶é…ç½®ï¼ˆå®é™…ä½¿ç”¨æ—¶éœ€è¦é…ç½®çœŸå®çš„SMTPæœåŠ¡å™¨ï¼‰
            smtp_server = "your_smtp_server.com"
            smtp_port = 587
            username = "your_email@company.com"
            password = "your_password"

            recipients = settings.get('email_recipients', [])

            if not recipients:
                return

            msg = MimeMultipart()
            msg['From'] = username
            msg['To'] = ', '.join(recipients)
            msg['Subject'] = f"é”€å”®é¢„æµ‹ç³»ç»Ÿé¢„è­¦: {alert['title']}"

            body = f"""
            é¢„è­¦æ—¶é—´: {alert['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}
            é¢„è­¦çº§åˆ«: {alert['level'].upper()}
            é¢„è­¦ç±»å‹: {alert['type']}

            é—®é¢˜æè¿°:
            {alert['message']}

            å»ºè®®æªæ–½:
            {alert['recommendation']}

            è¯·åŠæ—¶å¤„ç†ã€‚

            é”€å”®é¢„æµ‹ç³»ç»Ÿ
            """

            msg.attach(MimeText(body, 'plain', 'utf-8'))

            # å‘é€é‚®ä»¶ï¼ˆç¤ºä¾‹ä»£ç ï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦é…ç½®ï¼‰
            # server = smtplib.SMTP(smtp_server, smtp_port)
            # server.starttls()
            # server.login(username, password)
            # text = msg.as_string()
            # server.sendmail(username, recipients, text)
            # server.quit()

            print(f"ğŸ“§ é¢„è­¦é‚®ä»¶å·²å‘é€: {alert['title']}")

        except Exception as e:
            print(f"âŒ é‚®ä»¶å‘é€å¤±è´¥: {str(e)}")


# ====================================================================
# äº¤äº’å¼é¢„æµ‹è°ƒæ•´å™¨
# ====================================================================
class InteractivePredictionAdjuster:
    """äº¤äº’å¼é¢„æµ‹è°ƒæ•´å™¨"""

    def __init__(self, base_system):
        self.base_system = base_system

    def create_adjustment_interface(self):
        """åˆ›å»ºè°ƒæ•´ç•Œé¢"""
        st.markdown("### ğŸ›ï¸ äº¤äº’å¼é¢„æµ‹è°ƒæ•´")

        if self.base_system.predictions is not None:
            col1, col2 = st.columns([1, 1])

            with col1:
                st.markdown("#### ğŸ“Š è°ƒæ•´å‚æ•°")

                # å…¨å±€è°ƒæ•´
                global_factor = st.slider(
                    "æ•´ä½“é”€é‡è°ƒæ•´ (%)",
                    min_value=-50, max_value=50, value=0, step=5,
                    help="è°ƒæ•´æ‰€æœ‰äº§å“çš„é¢„æµ‹é”€é‡"
                )

                # ä¿ƒé”€å½±å“
                promo_boost = st.slider(
                    "ä¿ƒé”€æ´»åŠ¨å½±å“ (%)",
                    min_value=0, max_value=100, value=0, step=10,
                    help="å‡è®¾ä¿ƒé”€æ´»åŠ¨å¯¹é”€é‡çš„æå‡"
                )

                # å­£èŠ‚æ€§è°ƒæ•´
                seasonal_factor = st.selectbox(
                    "å­£èŠ‚æ€§å› å­",
                    ["æ— è°ƒæ•´", "æ·¡å­£(-20%)", "æ—ºå­£(+30%)", "èŠ‚å‡æ—¥(+50%)"]
                )

                # å¸‚åœºç¯å¢ƒ
                market_condition = st.selectbox(
                    "å¸‚åœºç¯å¢ƒ",
                    ["æ­£å¸¸", "ä¹è§‚(+15%)", "æ‚²è§‚(-15%)", "ç»æµå±æœº(-30%)"]
                )

                # äº§å“é€‰æ‹©
                all_products = self.base_system.predictions['äº§å“ä»£ç '].unique()
                selected_products = st.multiselect(
                    "é€‰æ‹©è°ƒæ•´çš„äº§å“",
                    all_products,
                    default=all_products[:5],
                    help="é€‰æ‹©è¦è¿›è¡Œè°ƒæ•´çš„äº§å“"
                )

            with col2:
                st.markdown("#### ğŸ“ˆ è°ƒæ•´ç»“æœ")

                if selected_products:
                    # è®¡ç®—è°ƒæ•´åçš„é¢„æµ‹
                    adjusted_predictions = self._apply_adjustments(
                        global_factor, promo_boost, seasonal_factor,
                        market_condition, selected_products
                    )

                    # æ˜¾ç¤ºè°ƒæ•´å‰åå¯¹æ¯”
                    original_total = self.base_system.predictions[
                        self.base_system.predictions['äº§å“ä»£ç '].isin(selected_products)
                    ]['é¢„æµ‹é”€é‡'].sum()

                    adjusted_total = adjusted_predictions['è°ƒæ•´åé¢„æµ‹'].sum()
                    change_pct = (adjusted_total - original_total) / original_total * 100

                    # æŒ‡æ ‡å±•ç¤º
                    metric_col1, metric_col2 = st.columns(2)

                    with metric_col1:
                        st.metric(
                            "åŸé¢„æµ‹æ€»é‡",
                            f"{original_total:,.0f} ç®±"
                        )

                    with metric_col2:
                        st.metric(
                            "è°ƒæ•´åæ€»é‡",
                            f"{adjusted_total:,.0f} ç®±",
                            f"{change_pct:+.1f}%"
                        )

                    # è¯¦ç»†å¯¹æ¯”è¡¨æ ¼
                    st.markdown("##### ğŸ“‹ è¯¦ç»†å¯¹æ¯”")
                    display_columns = ['äº§å“ä»£ç ', 'åŸé¢„æµ‹', 'è°ƒæ•´åé¢„æµ‹', 'å˜åŒ–é‡', 'å˜åŒ–ç‡']
                    st.dataframe(
                        adjusted_predictions[display_columns],
                        use_container_width=True,
                        hide_index=True
                    )

                    # ä¿å­˜è°ƒæ•´è®°å½•
                    if st.button("ğŸ’¾ ä¿å­˜è°ƒæ•´æ–¹æ¡ˆ", use_container_width=True):
                        adjustment_record = {
                            'timestamp': datetime.now(),
                            'global_factor': global_factor,
                            'promo_boost': promo_boost,
                            'seasonal_factor': seasonal_factor,
                            'market_condition': market_condition,
                            'selected_products': selected_products,
                            'original_total': original_total,
                            'adjusted_total': adjusted_total,
                            'change_percent': change_pct,
                            'adjusted_data': adjusted_predictions.to_dict('records')
                        }

                        st.session_state.adjustment_history.append(adjustment_record)
                        st.success("âœ… è°ƒæ•´æ–¹æ¡ˆå·²ä¿å­˜åˆ°å†å²è®°å½•")

                        # å¯é€‰ï¼šæ›´æ–°å½“å‰é¢„æµ‹
                        if st.checkbox("åº”ç”¨åˆ°å½“å‰é¢„æµ‹"):
                            # è¿™é‡Œå¯ä»¥æ›´æ–°ä¸»é¢„æµ‹ç³»ç»Ÿçš„é¢„æµ‹ç»“æœ
                            st.info("ğŸ”„ è°ƒæ•´å·²åº”ç”¨åˆ°å½“å‰é¢„æµ‹")
                else:
                    st.warning("âš ï¸ è¯·é€‰æ‹©è¦è°ƒæ•´çš„äº§å“")
        else:
            st.warning("âš ï¸ è¯·å…ˆç”ŸæˆåŸºç¡€é¢„æµ‹ç»“æœ")

    def _apply_adjustments(self, global_factor, promo_boost, seasonal_factor,
                           market_condition, selected_products):
        """åº”ç”¨è°ƒæ•´å› å­"""
        df = self.base_system.predictions[
            self.base_system.predictions['äº§å“ä»£ç '].isin(selected_products)
        ].copy()

        # è§£æè°ƒæ•´å› å­
        seasonal_multiplier = 1.0
        if seasonal_factor == "æ·¡å­£(-20%)":
            seasonal_multiplier = 0.8
        elif seasonal_factor == "æ—ºå­£(+30%)":
            seasonal_multiplier = 1.3
        elif seasonal_factor == "èŠ‚å‡æ—¥(+50%)":
            seasonal_multiplier = 1.5

        market_multiplier = 1.0
        if market_condition == "ä¹è§‚(+15%)":
            market_multiplier = 1.15
        elif market_condition == "æ‚²è§‚(-15%)":
            market_multiplier = 0.85
        elif market_condition == "ç»æµå±æœº(-30%)":
            market_multiplier = 0.7

        # è®¡ç®—æ€»è°ƒæ•´å› å­
        total_multiplier = (1 + global_factor / 100) * (1 + promo_boost / 100) * seasonal_multiplier * market_multiplier

        # åº”ç”¨è°ƒæ•´
        df['åŸé¢„æµ‹'] = df['é¢„æµ‹é”€é‡']
        df['è°ƒæ•´åé¢„æµ‹'] = df['é¢„æµ‹é”€é‡'] * total_multiplier
        df['å˜åŒ–é‡'] = df['è°ƒæ•´åé¢„æµ‹'] - df['åŸé¢„æµ‹']
        df['å˜åŒ–ç‡'] = f"{(total_multiplier - 1) * 100:+.1f}%"

        return df

    def show_adjustment_history(self):
        """æ˜¾ç¤ºè°ƒæ•´å†å²"""
        if st.session_state.adjustment_history:
            st.markdown("#### ğŸ“œ è°ƒæ•´å†å²è®°å½•")

            for i, record in enumerate(reversed(st.session_state.adjustment_history)):
                with st.expander(
                        f"è°ƒæ•´è®°å½• {len(st.session_state.adjustment_history) - i}: {record['timestamp'].strftime('%Y-%m-%d %H:%M')}"):
                    col1, col2 = st.columns(2)

                    with col1:
                        st.write("**è°ƒæ•´å‚æ•°:**")
                        st.write(f"- æ•´ä½“è°ƒæ•´: {record['global_factor']:+}%")
                        st.write(f"- ä¿ƒé”€å½±å“: {record['promo_boost']}%")
                        st.write(f"- å­£èŠ‚å› å­: {record['seasonal_factor']}")
                        st.write(f"- å¸‚åœºç¯å¢ƒ: {record['market_condition']}")

                    with col2:
                        st.write("**è°ƒæ•´ç»“æœ:**")
                        st.write(f"- åŸé¢„æµ‹: {record['original_total']:,.0f} ç®±")
                        st.write(f"- è°ƒæ•´å: {record['adjusted_total']:,.0f} ç®±")
                        st.write(f"- å˜åŒ–: {record['change_percent']:+.1f}%")
                        st.write(f"- äº§å“æ•°: {len(record['selected_products'])}")
        else:
            st.info("æš‚æ— è°ƒæ•´å†å²è®°å½•")


# ====================================================================
# ä¸»ç•Œé¢
# ====================================================================
def render_production_header():
    """æ¸²æŸ“ç”Ÿäº§çº§å¤´éƒ¨"""
    st.markdown(f"""
    <div class="production-header">
        <h1 class="production-title">ğŸš€ ç”Ÿäº§çº§é”€å”®é¢„æµ‹ç³»ç»Ÿ</h1>
        <p style="font-size: 1.2rem; color: #666; margin-bottom: 1rem;">
            é›†æˆé¢„æµ‹è·Ÿè¸ªéªŒè¯ã€æ™ºèƒ½é¢„è­¦ã€äº¤äº’å¼è°ƒæ•´ç­‰5æ˜Ÿæ ¸å¿ƒåŠŸèƒ½
        </p>
        <div style="display: flex; justify-content: center; gap: 1rem; flex-wrap: wrap; margin-top: 1rem;">
            <span style="background: linear-gradient(135deg, #4CAF50 0%, #45a049 100%); color: white; padding: 0.5rem 1rem; border-radius: 20px;">ğŸ¯ é¢„æµ‹è·Ÿè¸ª</span>
            <span style="background: linear-gradient(135deg, #FF9800 0%, #F57C00 100%); color: white; padding: 0.5rem 1rem; border-radius: 20px;">ğŸ”” æ™ºèƒ½é¢„è­¦</span>
            <span style="background: linear-gradient(135deg, #2196F3 0%, #1976D2 100%); color: white; padding: 0.5rem 1rem; border-radius: 20px;">ğŸ›ï¸ äº¤äº’è°ƒæ•´</span>
            <span style="background: linear-gradient(135deg, #9C27B0 0%, #7B1FA2 100%); color: white; padding: 0.5rem 1rem; border-radius: 20px;">ğŸ“Š æœºå™¨å­¦ä¹ </span>
        </div>
        <div style="margin-top: 1rem; font-size: 0.9rem; color: #666;">
            æœ€åæ›´æ–°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | ç‰ˆæœ¬: v2.0 Production Ready
        </div>
    </div>
    """, unsafe_allow_html=True)


# ====================================================================
# ä¾§è¾¹æ 
# ====================================================================
def create_production_sidebar():
    """åˆ›å»ºç”Ÿäº§çº§ä¾§è¾¹æ """
    with st.sidebar:
        st.markdown("### ğŸ›ï¸ ç³»ç»Ÿæ§åˆ¶å°")

        # ç³»ç»ŸçŠ¶æ€
        st.markdown("#### ğŸ“Š ç³»ç»ŸçŠ¶æ€")

        if st.session_state.model_trained:
            system = st.session_state.prediction_system
            st.markdown(f"""
            <div class="feature-card" style="margin: 0.5rem 0;">
                <div style="display: flex; align-items: center; margin-bottom: 0.5rem;">
                    <span class="status-indicator status-success"></span>
                    <strong>ç³»ç»Ÿå°±ç»ª</strong>
                </div>
                <p style="margin: 0; font-size: 0.9rem;">
                    æ¨¡å‹: {system.models['best_model_name']}<br>
                    å‡†ç¡®ç‡: {system.accuracy_results[system.models['best_model_name']]['SMAPE_Accuracy']:.1f}%<br>
                    æ•°æ®: {system.data_mode}<br>
                    å†å²è®°å½•: {len(system.historical_predictions) if system.historical_predictions is not None else 0} æ¡
                </p>
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown(f"""
            <div class="feature-card" style="margin: 0.5rem 0;">
                <div style="display: flex; align-items: center; margin-bottom: 0.5rem;">
                    <span class="status-indicator status-warning"></span>
                    <strong>å¾…è®­ç»ƒ</strong>
                </div>
                <p style="margin: 0; font-size: 0.9rem;">
                    è¯·å…ˆè®­ç»ƒåŸºç¡€é¢„æµ‹æ¨¡å‹
                </p>
            </div>
            """, unsafe_allow_html=True)

        # æ•°æ®æºé€‰æ‹©
        st.markdown("#### ğŸ“‚ æ•°æ®æº")
        data_mode = st.radio(
            "é€‰æ‹©æ•°æ®æº",
            ["GitHubçœŸå®æ•°æ®", "ä¸Šä¼ Excelæ–‡ä»¶", "ç¤ºä¾‹æ•°æ®"],
            help="é€‰æ‹©è®­ç»ƒæ•°æ®æ¥æº"
        )

        shipment_file = None
        promotion_file = None
        use_github = False

        if data_mode == "GitHubçœŸå®æ•°æ®":
            use_github = True
            st.info("ğŸ“¡ å°†ä»GitHubåŠ è½½çœŸå®Excelæ•°æ®")
        elif data_mode == "ä¸Šä¼ Excelæ–‡ä»¶":
            shipment_file = st.file_uploader("å‡ºè´§æ•°æ®", type=['xlsx', 'xls'])
            promotion_file = st.file_uploader("ä¿ƒé”€æ•°æ®", type=['xlsx', 'xls'])
        else:
            st.info("ğŸ² å°†ç”Ÿæˆæ¨¡æ‹Ÿç¤ºä¾‹æ•°æ®")

        # è®­ç»ƒå‚æ•°
        st.markdown("#### âš™ï¸ è®­ç»ƒå‚æ•°")
        test_ratio = st.slider("æµ‹è¯•é›†æ¯”ä¾‹", 0.1, 0.3, 0.2, 0.05)
        months_ahead = st.slider("é¢„æµ‹æœˆæ•°", 1, 6, 3)

        # é¢„è­¦è®¾ç½®
        st.markdown("#### ğŸ”” é¢„è­¦è®¾ç½®")

        accuracy_threshold = st.slider(
            "å‡†ç¡®ç‡é¢„è­¦é˜ˆå€¼ (%)",
            60.0, 95.0,
            st.session_state.alert_settings['accuracy_threshold'],
            5.0
        )

        bias_threshold = st.slider(
            "åå·®é¢„è­¦é˜ˆå€¼",
            5.0, 30.0,
            st.session_state.alert_settings['bias_threshold'],
            5.0
        )

        enable_email = st.checkbox(
            "å¯ç”¨é‚®ä»¶é¢„è­¦",
            st.session_state.alert_settings['enable_email']
        )

        # æ›´æ–°é¢„è­¦è®¾ç½®
        st.session_state.alert_settings.update({
            'accuracy_threshold': accuracy_threshold,
            'bias_threshold': bias_threshold,
            'enable_email': enable_email
        })

        # å¿«é€Ÿæ“ä½œ
        st.markdown("#### âš¡ å¿«é€Ÿæ“ä½œ")

        if st.button("ğŸ”„ é‡ç½®ç³»ç»Ÿ", use_container_width=True):
            # é‡ç½®æ‰€æœ‰çŠ¶æ€
            for key in ['model_trained', 'prediction_system', 'prediction_archives',
                        'actual_data_records', 'validation_results', 'alerts', 'adjustment_history']:
                if key in st.session_state:
                    if key in ['prediction_archives', 'actual_data_records', 'validation_results', 'alerts',
                               'adjustment_history']:
                        st.session_state[key] = []
                    else:
                        st.session_state[key] = None if key == 'prediction_system' else False
            st.success("âœ… ç³»ç»Ÿå·²é‡ç½®")
            st.rerun()

        # å½“å‰é¢„è­¦æ•°é‡
        if st.session_state.alerts:
            danger_count = len([a for a in st.session_state.alerts if a['level'] == 'danger'])
            warning_count = len([a for a in st.session_state.alerts if a['level'] == 'warning'])

            if danger_count > 0:
                st.error(f"ğŸš¨ {danger_count} ä¸ªä¸¥é‡é¢„è­¦")
            if warning_count > 0:
                st.warning(f"âš ï¸ {warning_count} ä¸ªä¸€èˆ¬é¢„è­¦")

    return data_mode, use_github, shipment_file, promotion_file, test_ratio, months_ahead


# ====================================================================
# ä¸»ç¨‹åº
# ====================================================================
def main():
    """ä¸»ç¨‹åº"""
    # æ¸²æŸ“å¤´éƒ¨
    render_production_header()

    # åˆ›å»ºä¾§è¾¹æ 
    data_mode, use_github, shipment_file, promotion_file, test_ratio, months_ahead = create_production_sidebar()

    # åˆ›å»ºTabé¡µé¢
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸš€ åŸºç¡€é¢„æµ‹è®­ç»ƒ",
        "ğŸ¯ é¢„æµ‹è·Ÿè¸ªéªŒè¯",
        "ğŸ”” æ™ºèƒ½é¢„è­¦ä¸­å¿ƒ",
        "ğŸ›ï¸ äº¤äº’å¼è°ƒæ•´",
        "ğŸ“Š ç³»ç»Ÿç›‘æ§"
    ])

    # Tab 1: åŸºç¡€é¢„æµ‹è®­ç»ƒ
    with tab1:
        st.markdown("### ğŸš€ åŸºç¡€é¢„æµ‹æ¨¡å‹è®­ç»ƒ")

        col1, col2 = st.columns([2, 1])

        with col1:
            # æ£€æŸ¥è®­ç»ƒæ¡ä»¶
            can_train = True
            if data_mode == "ä¸Šä¼ Excelæ–‡ä»¶" and (shipment_file is None or promotion_file is None):
                can_train = False
                st.warning("âš ï¸ è¯·ä¸Šä¼ Excelæ–‡ä»¶")

            if st.button("ğŸš€ å¼€å§‹è®­ç»ƒé¢„æµ‹æ¨¡å‹", type="primary", use_container_width=True, disabled=not can_train):
                with st.container():
                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    def update_progress(progress, message):
                        progress_bar.progress(progress)
                        status_text.text(message)

                    # åˆå§‹åŒ–ç³»ç»Ÿ
                    system = ProductionSalesPredictionSystem()

                    try:
                        success = True

                        # æ•°æ®åŠ è½½
                        if data_mode == "GitHubçœŸå®æ•°æ®":
                            success = system.load_data(use_github=True)
                        elif data_mode == "ä¸Šä¼ Excelæ–‡ä»¶":
                            success = system.load_data(shipment_file=shipment_file, promotion_file=promotion_file)
                        else:
                            success = system.load_sample_data()

                        if success:
                            update_progress(0.2, f"âœ… æ•°æ®åŠ è½½: {len(system.shipment_data):,} æ¡")

                            # é¢„å¤„ç†
                            if system.preprocess_data(update_progress):
                                # ç‰¹å¾å·¥ç¨‹
                                if system.create_features(update_progress):
                                    # æ¨¡å‹è®­ç»ƒ
                                    if system.train_models(test_ratio, update_progress):
                                        # é¢„æµ‹æœªæ¥
                                        system.predict_future(months_ahead)

                                        # ä¿å­˜åˆ°session
                                        st.session_state.prediction_system = system
                                        st.session_state.model_trained = True

                                        progress_bar.empty()
                                        status_text.empty()

                                        st.success("ğŸ‰ æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
                                        st.balloons()
                                        st.rerun()
                                    else:
                                        success = False
                                else:
                                    success = False
                            else:
                                success = False

                        if not success:
                            st.error("âŒ è®­ç»ƒå¤±è´¥")

                    except Exception as e:
                        st.error(f"âŒ è®­ç»ƒå¼‚å¸¸: {str(e)}")

        with col2:
            if st.session_state.model_trained:
                system = st.session_state.prediction_system

                st.markdown("#### ğŸ“Š è®­ç»ƒç»“æœ")

                best_model = system.models['best_model_name']
                best_accuracy = system.accuracy_results[best_model]['SMAPE_Accuracy']

                st.markdown(f"""
                <div class="metric-card">
                    <div class="metric-value">{best_accuracy:.1f}%</div>
                    <div class="metric-label">é¢„æµ‹å‡†ç¡®ç‡</div>
                </div>
                """, unsafe_allow_html=True)

                st.markdown(f"""
                <div class="feature-card">
                    <h4>âœ… è®­ç»ƒå®Œæˆ</h4>
                    <p><strong>æœ€ä½³æ¨¡å‹:</strong> {best_model}</p>
                    <p><strong>æ•°æ®æ¨¡å¼:</strong> {system.data_mode}</p>
                    <p><strong>äº§å“æ•°é‡:</strong> {len(system.product_segments)}</p>
                    <p><strong>è®­ç»ƒæ—¶é—´:</strong> {system.training_time:.1f}ç§’</p>
                    <p><strong>å†å²é¢„æµ‹:</strong> {len(system.historical_predictions) if system.historical_predictions is not None else 0} æ¡</p>
                </div>
                """, unsafe_allow_html=True)

                # é¢„æµ‹ç»“æœé¢„è§ˆ
                if system.predictions is not None:
                    st.markdown("#### ğŸ”® é¢„æµ‹ç»“æœé¢„è§ˆ")
                    st.dataframe(system.predictions.head(), use_container_width=True)
            else:
                st.markdown("""
                <div class="feature-card">
                    <h4>ğŸ“‹ è®­ç»ƒè¯´æ˜</h4>
                    <p>æ­¤ç³»ç»ŸåŒ…å«å®Œæ•´çš„æœºå™¨å­¦ä¹ æµæ°´çº¿ï¼š</p>
                    <ul>
                        <li>ğŸ§¹ æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†</li>
                        <li>ğŸ”§ é«˜çº§ç‰¹å¾å·¥ç¨‹</li>
                        <li>ğŸ¤– å¤šæ¨¡å‹è®­ç»ƒå’Œèåˆ</li>
                        <li>ğŸ“Š å‡†ç¡®ç‡è¯„ä¼°</li>
                        <li>ğŸ”® æœªæ¥é”€é‡é¢„æµ‹</li>
                    </ul>
                    <p>è¯·ç‚¹å‡»"å¼€å§‹è®­ç»ƒ"æŒ‰é’®å¯åŠ¨è®­ç»ƒæµç¨‹ã€‚</p>
                </div>
                """, unsafe_allow_html=True)

    # Tab 2: é¢„æµ‹è·Ÿè¸ªéªŒè¯
    with tab2:
        st.markdown("### ğŸ¯ é¢„æµ‹è·Ÿè¸ªéªŒè¯ç³»ç»Ÿ")

        if not st.session_state.model_trained:
            st.warning("âš ï¸ è¯·å…ˆè®­ç»ƒé¢„æµ‹æ¨¡å‹")
        else:
            tracking_system = PredictionTrackingSystem()
            system = st.session_state.prediction_system

            col1, col2 = st.columns([1, 1])

            with col1:
                st.markdown("#### ğŸ“Š ä¿å­˜é¢„æµ‹æ¡£æ¡ˆ")

                if st.button("ğŸ’¾ ä¿å­˜å½“å‰é¢„æµ‹åˆ°æ¡£æ¡ˆ", type="primary"):
                    if system.predictions is not None:
                        model_info = {
                            'model_name': system.models['best_model_name'],
                            'accuracy': system.accuracy_results[system.models['best_model_name']]['SMAPE_Accuracy'],
                            'training_date': datetime.now()
                        }

                        archive = tracking_system.save_prediction_archive(system.predictions, model_info)
                        st.session_state.prediction_archives.append(archive)

                        st.success(f"âœ… é¢„æµ‹æ¡£æ¡ˆå·²ä¿å­˜: {archive['prediction_id']}")
                        st.rerun()
                    else:
                        st.error("âŒ æ²¡æœ‰å¯ä¿å­˜çš„é¢„æµ‹ç»“æœ")

                # æ˜¾ç¤ºé¢„æµ‹æ¡£æ¡ˆ
                st.markdown("#### ğŸ“‹ é¢„æµ‹æ¡£æ¡ˆåˆ—è¡¨")

                if st.session_state.prediction_archives:
                    for archive in st.session_state.prediction_archives:
                        status_class = {
                            'pending_validation': 'validation-pending',
                            'partial_validated': 'validation-completed',
                            'fully_validated': 'validation-completed'
                        }.get(archive['status'], 'validation-pending')

                        st.markdown(f"""
                        <div class="feature-card {status_class}">
                            <h4>{archive['prediction_id']}</h4>
                            <p><strong>åˆ›å»ºæ—¶é—´:</strong> {archive['creation_date'].strftime('%Y-%m-%d %H:%M')}</p>
                            <p><strong>äº§å“æ•°:</strong> {archive['product_count']}</p>
                            <p><strong>é¢„æµ‹æ€»é‡:</strong> {archive['total_predicted_volume']:,.0f} ç®±</p>
                            <p><strong>çŠ¶æ€:</strong> {'â³ å¾…éªŒè¯' if archive['status'] == 'pending_validation' else 'âœ… å·²éªŒè¯'}</p>
                        </div>
                        """, unsafe_allow_html=True)
                else:
                    st.info("æš‚æ— é¢„æµ‹æ¡£æ¡ˆ")

            with col2:
                st.markdown("#### ğŸ“ å®é™…æ•°æ®å½•å…¥")

                if st.session_state.prediction_archives:
                    # é€‰æ‹©æ¡£æ¡ˆ
                    archive_options = [f"{a['prediction_id']} ({a['creation_date'].strftime('%m-%d')})"
                                       for a in st.session_state.prediction_archives]

                    selected_idx = st.selectbox("é€‰æ‹©é¢„æµ‹æ¡£æ¡ˆ", range(len(archive_options)),
                                                format_func=lambda x: archive_options[x])

                    selected_archive = st.session_state.prediction_archives[selected_idx]

                    # æ˜¾ç¤ºé¢„æµ‹è¯¦æƒ…
                    st.markdown("##### ğŸ“Š é¢„æµ‹è¯¦æƒ…")
                    predictions_df = pd.DataFrame(selected_archive['predictions_data'])
                    st.dataframe(predictions_df.head(), use_container_width=True)

                    # å½•å…¥æ–¹å¼
                    input_method = st.radio("å½•å…¥æ–¹å¼", ["ç”Ÿæˆç¤ºä¾‹", "æ‰‹åŠ¨å½•å…¥", "CSVä¸Šä¼ "])

                    if input_method == "ç”Ÿæˆç¤ºä¾‹":
                        reference_month = st.text_input("å‚è€ƒæœˆä»½", value="2025-07")

                        if st.button("ğŸ² ç”Ÿæˆç¤ºä¾‹å®é™…æ•°æ®"):
                            # ç”Ÿæˆç¤ºä¾‹å®é™…æ•°æ®
                            actual_data = []
                            for _, row in predictions_df.iterrows():
                                # æ·»åŠ éšæœºè¯¯å·®æ¨¡æ‹Ÿå®é™…é”€é‡
                                noise = np.random.normal(1.0, 0.2)
                                actual_qty = max(0, row['é¢„æµ‹é”€é‡'] * noise)

                                actual_data.append({
                                    'äº§å“ä»£ç ': row['äº§å“ä»£ç '],
                                    'å®é™…é”€é‡': round(actual_qty, 1)
                                })

                            actual_df = pd.DataFrame(actual_data)
                            actual_record = tracking_system.add_actual_data(actual_df, reference_month)

                            st.session_state.actual_data_records.append(actual_record)
                            st.success(f"âœ… ç¤ºä¾‹æ•°æ®å·²ç”Ÿæˆ: {actual_record['record_id']}")

                            # æ‰§è¡ŒéªŒè¯
                            validation_result = tracking_system.validate_prediction(
                                selected_archive, actual_record, system
                            )

                            if validation_result:
                                st.session_state.validation_results.append(validation_result)

                                accuracy = validation_result['metrics']['smape_accuracy']
                                st.success(f"ğŸ¯ éªŒè¯å®Œæˆï¼å‡†ç¡®ç‡: {accuracy:.1f}%")

                                # æ˜¾ç¤ºéªŒè¯ç»“æœ
                                col_a, col_b, col_c = st.columns(3)

                                with col_a:
                                    st.metric("å‡†ç¡®ç‡", f"{accuracy:.1f}%")

                                with col_b:
                                    st.metric("MAE", f"{validation_result['metrics']['mae']:.1f}")

                                with col_c:
                                    st.metric("éªŒè¯äº§å“", validation_result['matched_products'])

                    elif input_method == "æ‰‹åŠ¨å½•å…¥":
                        st.markdown("##### âœï¸ æ‰‹åŠ¨å½•å…¥ï¼ˆå‰5ä¸ªäº§å“ï¼‰")

                        with st.form("manual_input"):
                            actual_data = []

                            for _, row in predictions_df.head(5).iterrows():
                                product = row['äº§å“ä»£ç ']
                                predicted = row['é¢„æµ‹é”€é‡']

                                actual_qty = st.number_input(
                                    f"{product} (é¢„æµ‹: {predicted:.0f})",
                                    min_value=0.0,
                                    value=float(predicted),
                                    step=1.0,
                                    key=f"manual_{product}"
                                )

                                actual_data.append({
                                    'äº§å“ä»£ç ': product,
                                    'å®é™…é”€é‡': actual_qty
                                })

                            reference_month = st.text_input("å‚è€ƒæœˆä»½", value="2025-07", key="manual_month")

                            if st.form_submit_button("ğŸ’¾ ä¿å­˜å®é™…æ•°æ®"):
                                actual_df = pd.DataFrame(actual_data)
                                actual_record = tracking_system.add_actual_data(actual_df, reference_month)

                                st.session_state.actual_data_records.append(actual_record)
                                st.success(f"âœ… å®é™…æ•°æ®å·²ä¿å­˜: {actual_record['record_id']}")

                    else:  # CSVä¸Šä¼ 
                        uploaded_file = st.file_uploader("ä¸Šä¼ CSVæ–‡ä»¶", type=['csv'])

                        if uploaded_file:
                            try:
                                actual_df = pd.read_csv(uploaded_file)
                                st.write("é¢„è§ˆ:")
                                st.dataframe(actual_df.head())

                                reference_month = st.text_input("å‚è€ƒæœˆä»½", value="2025-07", key="csv_month")

                                if st.button("ğŸ’¾ ä¿å­˜CSVæ•°æ®"):
                                    actual_record = tracking_system.add_actual_data(actual_df, reference_month)
                                    st.session_state.actual_data_records.append(actual_record)
                                    st.success(f"âœ… CSVæ•°æ®å·²ä¿å­˜: {actual_record['record_id']}")

                            except Exception as e:
                                st.error(f"âŒ CSVå¤„ç†å¤±è´¥: {str(e)}")
                else:
                    st.info("è¯·å…ˆä¿å­˜é¢„æµ‹æ¡£æ¡ˆ")

                # æ˜¾ç¤ºéªŒè¯ç»“æœ
                if st.session_state.validation_results:
                    st.markdown("#### ğŸ¯ éªŒè¯ç»“æœ")

                    latest_result = st.session_state.validation_results[-1]
                    metrics = latest_result['metrics']

                    st.markdown(f"""
                    <div class="feature-card validation-completed">
                        <h4>æœ€æ–°éªŒè¯ç»“æœ</h4>
                        <p><strong>éªŒè¯æ—¶é—´:</strong> {latest_result['validation_date'].strftime('%Y-%m-%d %H:%M')}</p>
                        <p><strong>å‡†ç¡®ç‡:</strong> {metrics['smape_accuracy']:.1f}%</p>
                        <p><strong>MAE:</strong> {metrics['mae']:.1f}</p>
                        <p><strong>éªŒè¯äº§å“:</strong> {latest_result['matched_products']}</p>
                    </div>
                    """, unsafe_allow_html=True)

    # Tab 3: æ™ºèƒ½é¢„è­¦ä¸­å¿ƒ
    with tab3:
        st.markdown("### ğŸ”” æ™ºèƒ½é¢„è­¦ä¸­å¿ƒ")

        if not st.session_state.model_trained:
            st.warning("âš ï¸ è¯·å…ˆè®­ç»ƒé¢„æµ‹æ¨¡å‹")
        else:
            system = st.session_state.prediction_system
            alert_system = IntelligentAlertSystem(system)

            # æ£€æŸ¥é¢„è­¦
            current_alerts = alert_system.check_all_alerts(st.session_state.alert_settings)
            st.session_state.alerts = current_alerts

            # é¢„è­¦ä»ªè¡¨ç›˜
            st.markdown("#### ğŸš¨ é¢„è­¦ä»ªè¡¨ç›˜")

            col1, col2, col3, col4 = st.columns(4)

            danger_alerts = [a for a in current_alerts if a['level'] == 'danger']
            warning_alerts = [a for a in current_alerts if a['level'] == 'warning']

            with col1:
                st.markdown(f"""
                <div class="metric-card" style="border-left-color: #f44336;">
                    <div class="metric-value" style="color: #f44336;">{len(danger_alerts)}</div>
                    <div class="metric-label">ä¸¥é‡é¢„è­¦</div>
                </div>
                """, unsafe_allow_html=True)

            with col2:
                st.markdown(f"""
                <div class="metric-card" style="border-left-color: #FF9800;">
                    <div class="metric-value" style="color: #FF9800;">{len(warning_alerts)}</div>
                    <div class="metric-label">ä¸€èˆ¬é¢„è­¦</div>
                </div>
                """, unsafe_allow_html=True)

            with col3:
                total_predictions = len(
                    system.historical_predictions) if system.historical_predictions is not None else 0
                st.markdown(f"""
                <div class="metric-card">
                    <div class="metric-value">{total_predictions}</div>
                    <div class="metric-label">ç›‘æ§é¢„æµ‹æ•°</div>
                </div>
                """, unsafe_allow_html=True)

            with col4:
                avg_accuracy = system.historical_predictions[
                    'å‡†ç¡®ç‡(%)'].mean() if system.historical_predictions is not None else 0
                st.markdown(f"""
                <div class="metric-card">
                    <div class="metric-value">{avg_accuracy:.1f}%</div>
                    <div class="metric-label">å¹³å‡å‡†ç¡®ç‡</div>
                </div>
                """, unsafe_allow_html=True)

            # å…·ä½“é¢„è­¦ä¿¡æ¯
            if current_alerts:
                st.markdown("#### âš ï¸ å½“å‰é¢„è­¦")

                for alert in current_alerts:
                    alert_class = f"alert-{alert['level']}"

                    st.markdown(f"""
                    <div class="alert-card {alert_class}">
                        <h4>{alert['title']}</h4>
                        <p><strong>é—®é¢˜:</strong> {alert['message']}</p>
                        <p><strong>å»ºè®®:</strong> {alert['recommendation']}</p>
                        <p><strong>æ—¶é—´:</strong> {alert['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}</p>
                    </div>
                    """, unsafe_allow_html=True)

                    # å‘é€é€šçŸ¥é€‰é¡¹
                    if st.button(f"ğŸ“§ å‘é€é€šçŸ¥ - {alert['title'][:20]}...", key=f"alert_{alert['timestamp']}"):
                        alert_system.send_alert_notification(alert, st.session_state.alert_settings)
                        st.success("âœ… é¢„è­¦é€šçŸ¥å·²å‘é€")
            else:
                st.markdown("""
                <div class="alert-card alert-success">
                    <h4>âœ… ç³»ç»Ÿè¿è¡Œæ­£å¸¸</h4>
                    <p>å½“å‰æ²¡æœ‰æ£€æµ‹åˆ°é¢„è­¦ä¿¡å·ï¼Œæ‰€æœ‰æŒ‡æ ‡è¿è¡Œæ­£å¸¸ã€‚</p>
                </div>
                """, unsafe_allow_html=True)

            # é¢„è­¦è®¾ç½®
            st.markdown("#### âš™ï¸ é¢„è­¦è®¾ç½®")

            with st.expander("ğŸ“§ é‚®ä»¶é€šçŸ¥è®¾ç½®"):
                email_recipients = st.text_area(
                    "æ”¶ä»¶äººé‚®ç®± (æ¯è¡Œä¸€ä¸ª)",
                    value="\n".join(st.session_state.alert_settings.get('email_recipients', [])),
                    help="è¾“å…¥æ¥æ”¶é¢„è­¦é‚®ä»¶çš„é‚®ç®±åœ°å€"
                )

                if st.button("ğŸ’¾ ä¿å­˜é‚®ä»¶è®¾ç½®"):
                    recipients = [email.strip() for email in email_recipients.split('\n') if email.strip()]
                    st.session_state.alert_settings['email_recipients'] = recipients
                    st.success(f"âœ… å·²ä¿å­˜ {len(recipients)} ä¸ªæ”¶ä»¶äºº")

    # Tab 4: äº¤äº’å¼è°ƒæ•´
    with tab4:
        st.markdown("### ğŸ›ï¸ äº¤äº’å¼é¢„æµ‹è°ƒæ•´")

        if not st.session_state.model_trained:
            st.warning("âš ï¸ è¯·å…ˆè®­ç»ƒé¢„æµ‹æ¨¡å‹")
        else:
            system = st.session_state.prediction_system
            adjuster = InteractivePredictionAdjuster(system)

            # åˆ›å»ºè°ƒæ•´ç•Œé¢
            adjuster.create_adjustment_interface()

            st.markdown("---")

            # æ˜¾ç¤ºè°ƒæ•´å†å²
            adjuster.show_adjustment_history()

    # Tab 5: ç³»ç»Ÿç›‘æ§
    with tab5:
        st.markdown("### ğŸ“Š ç³»ç»Ÿç›‘æ§")

        if not st.session_state.model_trained:
            st.warning("âš ï¸ è¯·å…ˆè®­ç»ƒé¢„æµ‹æ¨¡å‹")
        else:
            system = st.session_state.prediction_system

            # ç³»ç»Ÿæ¦‚è§ˆ
            st.markdown("#### ğŸ“‹ ç³»ç»Ÿæ¦‚è§ˆ")

            col1, col2, col3 = st.columns(3)

            with col1:
                st.markdown("**ğŸ¯ é¢„æµ‹ç³»ç»Ÿ**")
                st.write(f"- æ¨¡å‹: {system.models['best_model_name']}")
                st.write(
                    f"- å‡†ç¡®ç‡: {system.accuracy_results[system.models['best_model_name']]['SMAPE_Accuracy']:.1f}%")
                st.write(f"- è®­ç»ƒæ—¶é—´: {system.training_time:.1f}ç§’")
                st.write(f"- äº§å“æ•°: {len(system.product_segments)}")

            with col2:
                st.markdown("**ğŸ“Š è·Ÿè¸ªéªŒè¯**")
                st.write(f"- é¢„æµ‹æ¡£æ¡ˆ: {len(st.session_state.prediction_archives)}")
                st.write(f"- å®é™…è®°å½•: {len(st.session_state.actual_data_records)}")
                st.write(f"- éªŒè¯ç»“æœ: {len(st.session_state.validation_results)}")
                st.write(f"- è°ƒæ•´è®°å½•: {len(st.session_state.adjustment_history)}")

            with col3:
                st.markdown("**ğŸ”” é¢„è­¦ç³»ç»Ÿ**")
                danger_count = len([a for a in st.session_state.alerts if a['level'] == 'danger'])
                warning_count = len([a for a in st.session_state.alerts if a['level'] == 'warning'])
                st.write(f"- ä¸¥é‡é¢„è­¦: {danger_count}")
                st.write(f"- ä¸€èˆ¬é¢„è­¦: {warning_count}")
                st.write(f"- é‚®ä»¶é€šçŸ¥: {'å¯ç”¨' if st.session_state.alert_settings['enable_email'] else 'ç¦ç”¨'}")
                st.write(f"- æ”¶ä»¶äºº: {len(st.session_state.alert_settings.get('email_recipients', []))}")

            # æ€§èƒ½è¶‹åŠ¿
            if st.session_state.validation_results:
                st.markdown("#### ğŸ“ˆ æ€§èƒ½è¶‹åŠ¿")

                trend_data = []
                for result in st.session_state.validation_results:
                    trend_data.append({
                        'éªŒè¯æ—¶é—´': result['validation_date'],
                        'å‡†ç¡®ç‡': result['metrics']['smape_accuracy'],
                        'MAE': result['metrics']['mae'],
                        'éªŒè¯äº§å“æ•°': result['matched_products']
                    })

                trend_df = pd.DataFrame(trend_data)

                # å‡†ç¡®ç‡è¶‹åŠ¿å›¾
                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    x=trend_df['éªŒè¯æ—¶é—´'],
                    y=trend_df['å‡†ç¡®ç‡'],
                    mode='lines+markers',
                    name='å‡†ç¡®ç‡',
                    line=dict(color='#4CAF50', width=3)
                ))

                fig.update_layout(
                    title="éªŒè¯å‡†ç¡®ç‡è¶‹åŠ¿",
                    xaxis_title="éªŒè¯æ—¶é—´",
                    yaxis_title="å‡†ç¡®ç‡ (%)",
                    height=400
                )

                st.plotly_chart(fig, use_container_width=True)

            # æ•°æ®å¯¼å‡º
            st.markdown("#### ğŸ“¥ æ•°æ®å¯¼å‡º")

            col_a, col_b = st.columns(2)

            with col_a:
                if st.button("ğŸ“Š å¯¼å‡ºé¢„æµ‹æ¡£æ¡ˆ"):
                    if st.session_state.prediction_archives:
                        export_data = []
                        for archive in st.session_state.prediction_archives:
                            export_data.append({
                                'prediction_id': archive['prediction_id'],
                                'creation_date': archive['creation_date'],
                                'product_count': archive['product_count'],
                                'total_volume': archive['total_predicted_volume'],
                                'status': archive['status']
                            })

                        export_df = pd.DataFrame(export_data)
                        csv_data = export_df.to_csv(index=False)

                        st.download_button(
                            "ğŸ“ ä¸‹è½½é¢„æµ‹æ¡£æ¡ˆ",
                            csv_data,
                            f"prediction_archives_{datetime.now().strftime('%Y%m%d')}.csv",
                            "text/csv"
                        )
                    else:
                        st.info("æš‚æ— é¢„æµ‹æ¡£æ¡ˆ")

            with col_b:
                if st.button("ğŸ¯ å¯¼å‡ºéªŒè¯ç»“æœ"):
                    if st.session_state.validation_results:
                        export_data = []
                        for result in st.session_state.validation_results:
                            export_data.append({
                                'validation_id': result['validation_id'],
                                'validation_date': result['validation_date'],
                                'accuracy': result['metrics']['smape_accuracy'],
                                'mae': result['metrics']['mae'],
                                'matched_products': result['matched_products']
                            })

                        export_df = pd.DataFrame(export_data)
                        csv_data = export_df.to_csv(index=False)

                        st.download_button(
                            "ğŸ“ ä¸‹è½½éªŒè¯ç»“æœ",
                            csv_data,
                            f"validation_results_{datetime.now().strftime('%Y%m%d')}.csv",
                            "text/csv"
                        )
                    else:
                        st.info("æš‚æ— éªŒè¯ç»“æœ")


# ====================================================================
# ç¨‹åºå…¥å£
# ====================================================================
if __name__ == "__main__":
    main()

# ====================================================================
# åº•éƒ¨ä¿¡æ¯
# ====================================================================
st.markdown("""
---
### ğŸ’¡ ç”Ÿäº§çº§é”€å”®é¢„æµ‹ç³»ç»Ÿ

**ğŸŒŸ 5æ˜Ÿæ ¸å¿ƒåŠŸèƒ½:**
- ğŸ¯ **é¢„æµ‹è·Ÿè¸ªéªŒè¯**: å­˜å‚¨é¢„æµ‹â†’ç­‰å¾…å®é™…â†’éªŒè¯å‡†ç¡®ç‡â†’ç›‘æ§æ€§èƒ½
- ğŸ”” **æ™ºèƒ½é¢„è­¦ç³»ç»Ÿ**: å‡†ç¡®ç‡ç›‘æ§â†’åå·®æ£€æµ‹â†’è‡ªåŠ¨é€šçŸ¥â†’é£é™©é¢„è­¦
- ğŸ›ï¸ **äº¤äº’å¼è°ƒæ•´**: åœºæ™¯åˆ†æâ†’å‚æ•°è°ƒæ•´â†’å½±å“è¯„ä¼°â†’å†³ç­–æ”¯æŒ

**ğŸš€ æŠ€æœ¯ç‰¹æ€§:**
- ç”Ÿäº§å°±ç»ªçš„ä»£ç æ¶æ„
- å®Œæ•´çš„é”™è¯¯å¤„ç†æœºåˆ¶
- å®æ—¶æ€§èƒ½ç›‘æ§
- æ•°æ®æŒä¹…åŒ–å­˜å‚¨
- ç”¨æˆ·å‹å¥½çš„ç•Œé¢è®¾è®¡

**ğŸ“§ è”ç³»æ”¯æŒ:** å¦‚æœ‰é—®é¢˜è¯·è”ç³»æŠ€æœ¯æ”¯æŒå›¢é˜Ÿ
""")
