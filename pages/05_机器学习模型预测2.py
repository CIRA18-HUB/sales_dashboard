# 5_æœºå™¨å­¦ä¹ æ¨¡å‹é¢„æµ‹.py - åŸºäºGitHubæ•°æ®çš„æœºå™¨å­¦ä¹ é¢„æµ‹ç³»ç»Ÿ
import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import warnings
import time
import io
import json
import pickle
import hashlib
from data_storage import storage

warnings.filterwarnings('ignore')

# æœºå™¨å­¦ä¹ åº“
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, r2_score
from sklearn.preprocessing import RobustScaler, StandardScaler
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb
import lightgbm as lgb

# ====================================================================
# é¡µé¢é…ç½®
# ====================================================================
st.set_page_config(
    page_title="ğŸ¤– æœºå™¨å­¦ä¹ æ¨¡å‹é¢„æµ‹",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# éšè—Streamlité»˜è®¤å…ƒç´ 
hide_elements = """
<style>
    #MainMenu {visibility: hidden !important;}
    footer {visibility: hidden !important;}
    header {visibility: hidden !important;}
    .stAppHeader {display: none !important;}
    .stDeployButton {display: none !important;}
    .stToolbar {display: none !important;}
</style>
"""
st.markdown(hide_elements, unsafe_allow_html=True)

# ====================================================================
# æ ·å¼å®šä¹‰
# ====================================================================
modern_ml_styles = """
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');

    .stApp {
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        min-height: 100vh;
    }

    .main {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        min-height: 100vh;
    }

    /* å¤´éƒ¨æ ·å¼ */
    .ml-header {
        background: rgba(255, 255, 255, 0.95);
        backdrop-filter: blur(25px);
        border-radius: 20px;
        padding: 2rem;
        margin-bottom: 2rem;
        box-shadow: 0 10px 30px rgba(0,0,0,0.1);
        text-align: center;
    }

    .ml-title {
        font-size: 3rem;
        font-weight: 800;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 1rem;
    }

    .ml-subtitle {
        font-size: 1.2rem;
        color: #666;
        margin-bottom: 1rem;
    }

    /* åŠŸèƒ½å¡ç‰‡ */
    .feature-card {
        background: rgba(255, 255, 255, 0.95);
        backdrop-filter: blur(25px);
        border-radius: 15px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 8px 25px rgba(0,0,0,0.1);
        border-left: 4px solid #667eea;
        transition: all 0.3s ease;
    }

    .feature-card:hover {
        transform: translateY(-3px);
        box-shadow: 0 12px 35px rgba(0,0,0,0.15);
    }

    /* æŒ‡æ ‡å¡ç‰‡ */
    .metric-card {
        background: rgba(255, 255, 255, 0.95);
        border-radius: 15px;
        padding: 1.5rem;
        text-align: center;
        border-left: 4px solid #667eea;
        box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        height: 100%;
    }

    .metric-value {
        font-size: 2.5rem;
        font-weight: bold;
        color: #667eea;
    }

    .metric-label {
        font-size: 1rem;
        color: #666;
        margin-top: 0.5rem;
    }

    /* çŠ¶æ€æŒ‡ç¤ºå™¨ */
    .status-indicator {
        width: 12px;
        height: 12px;
        border-radius: 50%;
        display: inline-block;
        margin-right: 0.5rem;
        animation: pulse 2s infinite;
    }

    .status-success { background-color: #4CAF50; }
    .status-warning { background-color: #FF9800; }
    .status-danger { background-color: #f44336; }

    @keyframes pulse {
        0% { transform: scale(1); opacity: 1; }
        50% { transform: scale(1.1); opacity: 0.8; }
        100% { transform: scale(1); opacity: 1; }
    }

    /* è¿›åº¦æ¡æ ·å¼ */
    .stProgress > div > div > div > div {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    }

    /* æŒ‰é’®æ ·å¼ */
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 10px;
        font-weight: 500;
        transition: all 0.3s ease;
    }

    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 5px 15px rgba(0,0,0,0.2);
    }

    .error-card {
        background: rgba(255, 82, 82, 0.1);
        border: 1px solid #ff5252;
        border-radius: 10px;
        padding: 1rem;
        margin: 1rem 0;
    }

    .warning-card {
        background: rgba(255, 193, 7, 0.1);
        border: 1px solid #ffc107;
        border-radius: 10px;
        padding: 1rem;
        margin: 1rem 0;
    }

    .success-card {
        background: rgba(76, 175, 80, 0.1);
        border: 1px solid #4caf50;
        border-radius: 10px;
        padding: 1rem;
        margin: 1rem 0;
    }
</style>
"""

st.markdown(modern_ml_styles, unsafe_allow_html=True)

# ====================================================================
# è®¤è¯æ£€æŸ¥
# ====================================================================
def check_authentication():
    """æ£€æŸ¥ç”¨æˆ·è®¤è¯çŠ¶æ€"""
    return (
        'authenticated' in st.session_state and 
        st.session_state.authenticated and
        'username' in st.session_state and
        st.session_state.username != ""
    )

# å¦‚æœæœªè®¤è¯ï¼Œé‡å®šå‘åˆ°ç™»å½•é¡µé¢
if not check_authentication():
    st.markdown("""
    <div class="error-card">
        <h3>ğŸ”’ è®¿é—®å—é™</h3>
        <p>æ‚¨éœ€è¦å…ˆç™»å½•æ‰èƒ½è®¿é—®æœºå™¨å­¦ä¹ é¢„æµ‹ç³»ç»Ÿã€‚</p>
        <p>è¯·è¿”å›ç™»å½•é¡µé¢å®Œæˆèº«ä»½éªŒè¯ã€‚</p>
    </div>
    """, unsafe_allow_html=True)
    
    if st.button("ğŸ”‘ è¿”å›ç™»å½•é¡µé¢"):
        st.session_state.clear()
        st.rerun()
    
    st.stop()

# ====================================================================
# Session State åˆå§‹åŒ–
# ====================================================================
def initialize_ml_session_state():
    """åˆå§‹åŒ–æœºå™¨å­¦ä¹ ä¼šè¯çŠ¶æ€"""
    defaults = {
        'ml_model_trained': False,
        'ml_prediction_system': None,
        'ml_training_progress': 0.0,
        'ml_training_status': "ç­‰å¾…å¼€å§‹",
        'ml_prediction_results': None,
        'ml_historical_analysis': None,
        'ml_accuracy_stats': None,
        'ml_feature_importance': None,
        'ml_model_comparison': None,
        'ml_data_loaded': False,
        'ml_data_validation_passed': False,
        # è®­ç»ƒå‚æ•°
        'ml_test_ratio': 0.2,
        'ml_months_ahead': 3,
        'ml_outlier_factor': 3.0,
        'ml_min_data_points': 4,
        'ml_n_estimators': 300,
        'ml_max_depth': 5,
        'ml_learning_rate': 0.05,
        # GitHubé…ç½®
        'github_repo': 'CIRA18-HUB/sales_dashboard',
        'github_branch': 'main',
        'data_file_path': 'pages/2409-2502å‡ºè´§æ•°æ®é›†.xlsx'
    }
    
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

initialize_ml_session_state()

# ====================================================================
# GitHubæ•°æ®åŠ è½½ç³»ç»Ÿ
# ====================================================================
class GitHubDataLoader:
    """GitHubæ•°æ®åŠ è½½å™¨"""
    
    def __init__(self, repo, branch='main'):
        self.repo = repo
        self.branch = branch
        self.base_url = f"https://raw.githubusercontent.com/{repo}/{branch}/"
    
    def load_excel_from_github(self, file_path, progress_callback=None):
        """ä»GitHubåŠ è½½Excelæ–‡ä»¶"""
        try:
            if progress_callback:
                progress_callback(0.1, "ğŸ”— è¿æ¥GitHubä»“åº“...")
            
            url = self.base_url + file_path
            
            if progress_callback:
                progress_callback(0.3, f"ğŸ“¥ ä¸‹è½½æ–‡ä»¶: {file_path}")
            
            # è¯»å–Excelæ–‡ä»¶
            df = pd.read_excel(url)
            
            if progress_callback:
                progress_callback(0.5, f"âœ… æˆåŠŸåŠ è½½: {len(df)} è¡Œæ•°æ®")
            
            return df, {
                'source': 'GitHub',
                'repo': self.repo,
                'branch': self.branch,
                'file_path': file_path,
                'url': url,
                'rows': len(df),
                'columns': len(df.columns),
                'load_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
        except Exception as e:
            error_msg = f"ä»GitHubåŠ è½½æ•°æ®å¤±è´¥: {str(e)}"
            if progress_callback:
                progress_callback(0.1, f"âŒ {error_msg}")
            raise Exception(error_msg)

# ====================================================================
# æœºå™¨å­¦ä¹ é¢„æµ‹ç³»ç»Ÿç±»
# ====================================================================
class GitHubMLPredictionSystem:
    """åŸºäºGitHubæ•°æ®çš„æœºå™¨å­¦ä¹ é¢„æµ‹ç³»ç»Ÿ"""
    
    def __init__(self):
        self.shipment_data = None
        self.feature_data = None
        self.models = {}
        self.scalers = {}
        self.predictions = None
        self.accuracy_results = {}
        self.product_segments = {}
        self.historical_predictions = None
        self.historical_accuracy = None
        self.data_summary = {}
        self.training_time = None
        self.data_source_info = {}
        
    def load_data_from_github(self, progress_callback=None):
        """ä»GitHubåŠ è½½æ•°æ®"""
        try:
            loader = GitHubDataLoader(
                st.session_state.github_repo, 
                st.session_state.github_branch
            )
            
            # åŠ è½½æ•°æ®
            self.shipment_data, self.data_source_info = loader.load_excel_from_github(
                st.session_state.data_file_path,
                progress_callback
            )
            
            if progress_callback:
                progress_callback(0.6, "ğŸ§¹ æ•°æ®æ¸…ç†ä¸­...")
            
            # éªŒè¯å’Œæ¸…ç†æ•°æ®
            self.shipment_data = self._validate_and_clean_data(self.shipment_data)
            
            if progress_callback:
                progress_callback(0.8, f"âœ… æ•°æ®å‡†å¤‡å®Œæˆ: {len(self.shipment_data)} æ¡è®°å½•")
            
            return True
            
        except Exception as e:
            error_msg = f"GitHubæ•°æ®åŠ è½½å¤±è´¥: {str(e)}"
            if progress_callback:
                progress_callback(0.1, f"âŒ {error_msg}")
            raise Exception(error_msg)
    
    def _validate_and_clean_data(self, raw_data):
        """éªŒè¯å’Œæ¸…ç†æ•°æ®"""
        if len(raw_data) == 0:
            raise Exception("GitHubæ•°æ®æ–‡ä»¶ä¸ºç©º")
        
        # åˆ—åæ ‡å‡†åŒ–
        column_mapping = {
            'è®¢å•æ—¥æœŸ': 'order_date', 'å‡ºè´§æ—¥æœŸ': 'order_date', 'æ—¥æœŸ': 'order_date',
            'åŒºåŸŸ': 'region', 'åœ°åŒº': 'region',
            'å®¢æˆ·ä»£ç ': 'customer_code', 'å®¢æˆ·ç¼–ç ': 'customer_code', 'ç»é”€å•†ä»£ç ': 'customer_code',
            'äº§å“ä»£ç ': 'product_code', 'äº§å“ç¼–ç ': 'product_code', 'è´§å·': 'product_code',
            'æ•°é‡': 'quantity', 'é”€é‡': 'quantity', 'å‡ºè´§é‡': 'quantity', 'ç®±æ•°': 'quantity',
        }
        
        cleaned_data = raw_data.copy()
        
        # åº”ç”¨åˆ—åæ˜ å°„
        for original_col in raw_data.columns:
            col_lower = str(original_col).lower().strip()
            for pattern, target in column_mapping.items():
                if pattern in col_lower or col_lower in pattern:
                    cleaned_data = cleaned_data.rename(columns={original_col: target})
                    break
        
        # æ£€æŸ¥å¿…è¦å­—æ®µ
        required_fields = ['order_date', 'product_code', 'quantity']
        missing_fields = [field for field in required_fields if field not in cleaned_data.columns]
        
        if missing_fields:
            raise Exception(f"GitHubæ•°æ®ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_fields}")
        
        # æ·»åŠ é»˜è®¤å­—æ®µ
        if 'customer_code' not in cleaned_data.columns:
            cleaned_data['customer_code'] = 'DEFAULT_CUSTOMER'
        if 'region' not in cleaned_data.columns:
            cleaned_data['region'] = 'DEFAULT_REGION'
        
        # æ•°æ®ç±»å‹è½¬æ¢
        cleaned_data['order_date'] = pd.to_datetime(cleaned_data['order_date'], errors='coerce')
        cleaned_data['quantity'] = pd.to_numeric(cleaned_data['quantity'], errors='coerce')
        
        # æ¸…ç†æ— æ•ˆæ•°æ®
        cleaned_data = cleaned_data.dropna(subset=['order_date', 'product_code', 'quantity'])
        cleaned_data = cleaned_data[cleaned_data['quantity'] > 0]
        
        return cleaned_data
    
    def preprocess_data(self, progress_callback=None):
        """æ•°æ®é¢„å¤„ç†"""
        if progress_callback:
            progress_callback(0.1, "ğŸ§¹ æ•°æ®é¢„å¤„ç†ä¸­...")
        
        # å¼‚å¸¸å€¼å¤„ç†
        original_len = len(self.shipment_data)
        self.shipment_data = self._remove_outliers_iqr(self.shipment_data)
        
        # äº§å“åˆ†æ®µ
        self._segment_products()
        
        # æ•°æ®æ‘˜è¦
        self.data_summary = {
            'total_records': len(self.shipment_data),
            'total_products': self.shipment_data['product_code'].nunique(),
            'total_customers': self.shipment_data['customer_code'].nunique(),
            'date_range': (self.shipment_data['order_date'].min(), self.shipment_data['order_date'].max()),
            'total_quantity': self.shipment_data['quantity'].sum(),
            'avg_daily_quantity': self.shipment_data.groupby('order_date')['quantity'].sum().mean(),
            'data_source': self.data_source_info,
            'outliers_removed': original_len - len(self.shipment_data),
            'data_quality_score': self._calculate_data_quality_score()
        }
        
        if progress_callback:
            progress_callback(0.5, f"âœ… é¢„å¤„ç†å®Œæˆ: {len(self.shipment_data)} è¡Œä¼˜è´¨æ•°æ®")
        
        return True
    
    def _remove_outliers_iqr(self, data, column='quantity', factor=3.0):
        """ä½¿ç”¨IQRæ–¹æ³•ç§»é™¤å¼‚å¸¸å€¼"""
        Q1 = data[column].quantile(0.25)
        Q3 = data[column].quantile(0.75)
        IQR = Q3 - Q1
        
        lower_bound = Q1 - factor * IQR
        upper_bound = Q3 + factor * IQR
        
        return data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]
    
    def _segment_products(self):
        """äº§å“åˆ†æ®µ"""
        product_stats = self.shipment_data.groupby('product_code')['quantity'].agg([
            'count', 'mean', 'std', 'min', 'max', 'sum'
        ]).reset_index()
        
        product_stats['cv'] = product_stats['std'] / product_stats['mean']
        product_stats['cv'] = product_stats['cv'].fillna(0)
        
        # åˆ†æ®µé€»è¾‘
        volume_high = product_stats['mean'].quantile(0.67)
        volume_low = product_stats['mean'].quantile(0.33)
        cv_high = product_stats['cv'].quantile(0.67)
        
        def classify_product(row):
            if row['mean'] >= volume_high:
                return 'é«˜é”€é‡ç¨³å®š' if row['cv'] <= cv_high else 'é«˜é”€é‡æ³¢åŠ¨'
            elif row['mean'] >= volume_low:
                return 'ä¸­é”€é‡ç¨³å®š' if row['cv'] <= cv_high else 'ä¸­é”€é‡æ³¢åŠ¨'
            else:
                return 'ä½é”€é‡ç¨³å®š' if row['cv'] <= cv_high else 'ä½é”€é‡æ³¢åŠ¨'
        
        product_stats['segment'] = product_stats.apply(classify_product, axis=1)
        self.product_segments = dict(zip(product_stats['product_code'], product_stats['segment']))
        
        return product_stats
    
    def _calculate_data_quality_score(self):
        """è®¡ç®—æ•°æ®è´¨é‡è¯„åˆ†"""
        score = 100
        
        # æ—¶é—´è·¨åº¦æ£€æŸ¥
        days_span = (self.data_summary['date_range'][1] - self.data_summary['date_range'][0]).days
        if days_span < 90:
            score -= 20
        elif days_span < 180:
            score -= 10
        
        # äº§å“æ•°é‡æ£€æŸ¥
        if self.data_summary['total_products'] < 5:
            score -= 20
        elif self.data_summary['total_products'] < 10:
            score -= 10
        
        # æ•°æ®é‡æ£€æŸ¥
        if self.data_summary['total_records'] < 100:
            score -= 20
        elif self.data_summary['total_records'] < 500:
            score -= 10
        
        return max(0, score)
    
    def create_features(self, progress_callback=None):
        """åˆ›å»ºç‰¹å¾"""
        if progress_callback:
            progress_callback(0.1, "ğŸ”§ ç‰¹å¾å·¥ç¨‹ä¸­...")
        
        # åˆ›å»ºæœˆåº¦æ•°æ®
        monthly_data = self.shipment_data.groupby([
            'product_code',
            self.shipment_data['order_date'].dt.to_period('M')
        ]).agg({
            'quantity': ['sum', 'count', 'mean', 'std'],
            'customer_code': 'nunique',
            'region': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.iloc[0]
        }).reset_index()
        
        monthly_data.columns = ['product_code', 'year_month', 'total_qty', 'order_count',
                               'avg_qty', 'std_qty', 'customer_count', 'main_region']
        monthly_data['std_qty'] = monthly_data['std_qty'].fillna(0)
        monthly_data = monthly_data.sort_values(['product_code', 'year_month'])
        
        # åˆ›å»ºç‰¹å¾
        all_features = []
        
        for product in self.product_segments.keys():
            product_data = monthly_data[monthly_data['product_code'] == product].copy()
            
            if len(product_data) < st.session_state.ml_min_data_points:
                continue
            
            # æ—¶é—´åºåˆ—ç‰¹å¾åˆ›å»º
            for idx in range(3, len(product_data)):
                historical_data = product_data.iloc[:idx].copy()
                
                features = self._create_time_series_features(
                    product, historical_data, self.product_segments[product]
                )
                
                # ç›®æ ‡å˜é‡
                target_row = product_data.iloc[idx]
                features['target'] = target_row['total_qty']
                features['target_month'] = str(target_row['year_month'])
                features['segment'] = self.product_segments[product]
                
                all_features.append(features)
        
        self.feature_data = pd.DataFrame(all_features)
        
        if len(self.feature_data) == 0:
            raise Exception("æ— æ³•åˆ›å»ºç‰¹å¾æ•°æ®ï¼Œè¯·æ£€æŸ¥GitHubæ•°æ®è´¨é‡å’Œå®Œæ•´æ€§")
        
        # ç‰¹å¾åå¤„ç†
        self._post_process_features()
        
        if progress_callback:
            progress_callback(0.8, f"âœ… ç‰¹å¾å®Œæˆ: {len(self.feature_data)} æ—¶é—´åºåˆ—æ ·æœ¬")
        
        return True
    
    def _create_time_series_features(self, product_code, historical_data, segment):
        """åˆ›å»ºæ—¶é—´åºåˆ—ç‰¹å¾"""
        features = {'product_code': product_code}
        
        if len(historical_data) < 3:
            return features
        
        qty_values = historical_data['total_qty'].values
        
        # åŸºç¡€ç»Ÿè®¡ç‰¹å¾
        features.update({
            'qty_mean': np.mean(qty_values),
            'qty_median': np.median(qty_values),
            'qty_std': np.std(qty_values),
            'qty_cv': np.std(qty_values) / (np.mean(qty_values) + 1),
            
            # æ»åç‰¹å¾
            'qty_lag_1': qty_values[-1],
            'qty_lag_2': qty_values[-2] if len(qty_values) > 1 else 0,
            'qty_lag_3': qty_values[-3] if len(qty_values) > 2 else 0,
            
            # ç§»åŠ¨å¹³å‡
            'qty_ma_2': np.mean(qty_values[-2:]),
            'qty_ma_3': np.mean(qty_values[-3:]) if len(qty_values) >= 3 else np.mean(qty_values),
        })
        
        # è¶‹åŠ¿ç‰¹å¾
        if len(qty_values) > 2:
            x = np.arange(len(qty_values))
            trend_coef = np.polyfit(x, qty_values, 1)[0]
            features['trend_slope'] = trend_coef
            
            recent_growth = (qty_values[-1] - qty_values[-2]) / (qty_values[-2] + 1)
            features['recent_growth'] = recent_growth
            
            features['stability_score'] = 1 / (1 + features['qty_cv'])
        else:
            features.update({
                'trend_slope': 0,
                'recent_growth': 0,
                'stability_score': 0.5
            })
        
        # æ—¶é—´ç‰¹å¾
        last_period = historical_data.iloc[-1]['year_month']
        features.update({
            'month': last_period.month,
            'quarter': last_period.quarter,
            'is_year_end': 1 if last_period.month in [11, 12] else 0,
            'is_peak_season': 1 if last_period.month in [3, 4, 10, 11] else 0,
        })
        
        # äº§å“æ®µç‰¹å¾
        segment_map = {
            'é«˜é”€é‡ç¨³å®š': 1, 'é«˜é”€é‡æ³¢åŠ¨': 2, 'ä¸­é”€é‡ç¨³å®š': 3,
            'ä¸­é”€é‡æ³¢åŠ¨': 4, 'ä½é”€é‡ç¨³å®š': 5, 'ä½é”€é‡æ³¢åŠ¨': 6
        }
        features['segment_encoded'] = segment_map.get(segment, 0)
        
        # æ•°æ®è´¨é‡ç‰¹å¾
        features.update({
            'data_points': len(qty_values),
            'consistency_score': len(qty_values[qty_values > 0]) / len(qty_values)
        })
        
        return features
    
    def _post_process_features(self):
        """ç‰¹å¾åå¤„ç†"""
        feature_cols = [col for col in self.feature_data.columns 
                       if col not in ['product_code', 'target', 'target_month', 'segment']]
        
        # å¤„ç†å¼‚å¸¸å€¼
        self.feature_data[feature_cols] = self.feature_data[feature_cols].replace([np.inf, -np.inf], np.nan)
        self.feature_data[feature_cols] = self.feature_data[feature_cols].fillna(0)
        
        # ç§»é™¤å¸¸æ•°ç‰¹å¾
        constant_features = [col for col in feature_cols if self.feature_data[col].std() == 0]
        if constant_features:
            self.feature_data = self.feature_data.drop(columns=constant_features)
    
    def train_models(self, progress_callback=None):
        """è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹"""
        if progress_callback:
            progress_callback(0.1, "ğŸš€ å¼€å§‹è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹...")
        
        start_time = time.time()
        
        # å‡†å¤‡æ•°æ®
        feature_cols = [col for col in self.feature_data.columns 
                       if col not in ['product_code', 'target', 'target_month', 'segment']]
        
        X = self.feature_data[feature_cols]
        y = self.feature_data['target']
        
        # æ—¶é—´åºåˆ—åˆ†å‰²
        self.feature_data['target_month_dt'] = pd.to_datetime(self.feature_data['target_month'])
        sorted_indices = self.feature_data.sort_values('target_month_dt').index
        
        X = X.loc[sorted_indices]
        y = y.loc[sorted_indices]
        
        # è®­ç»ƒæµ‹è¯•åˆ†å‰²
        n_samples = len(X)
        split_point = int(n_samples * (1 - st.session_state.ml_test_ratio))
        
        X_train, X_test = X.iloc[:split_point], X.iloc[split_point:]
        y_train, y_test = y.iloc[:split_point], y.iloc[split_point:]
        
        # ç‰¹å¾ç¼©æ”¾
        scaler = RobustScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        self.scalers['feature_scaler'] = scaler
        
        # è®­ç»ƒæ¨¡å‹
        models = {}
        predictions = {}
        
        # XGBoost
        if progress_callback:
            progress_callback(0.3, "ğŸ¯ è®­ç»ƒXGBoostæ¨¡å‹...")
        
        xgb_model = xgb.XGBRegressor(
            n_estimators=st.session_state.ml_n_estimators,
            max_depth=st.session_state.ml_max_depth,
            learning_rate=st.session_state.ml_learning_rate,
            subsample=0.8,
            colsample_bytree=0.8,
            reg_alpha=0.1,
            reg_lambda=0.1,
            random_state=42,
            n_jobs=-1
        )
        
        xgb_model.fit(X_train_scaled, y_train, verbose=False)
        xgb_pred = np.maximum(xgb_model.predict(X_test_scaled), 0)
        
        models['XGBoost'] = xgb_model
        predictions['XGBoost'] = xgb_pred
        
        # LightGBM
        if progress_callback:
            progress_callback(0.5, "ğŸ¯ è®­ç»ƒLightGBMæ¨¡å‹...")
        
        lgb_model = lgb.LGBMRegressor(
            n_estimators=st.session_state.ml_n_estimators,
            max_depth=st.session_state.ml_max_depth,
            learning_rate=st.session_state.ml_learning_rate,
            subsample=0.8,
            colsample_bytree=0.8,
            reg_alpha=0.1,
            reg_lambda=0.1,
            random_state=42,
            n_jobs=-1,
            verbose=-1
        )
        
        lgb_model.fit(X_train_scaled, y_train)
        lgb_pred = np.maximum(lgb_model.predict(X_test_scaled), 0)
        
        models['LightGBM'] = lgb_model
        predictions['LightGBM'] = lgb_pred
        
        # Random Forest
        if progress_callback:
            progress_callback(0.7, "ğŸ¯ è®­ç»ƒRandom Forestæ¨¡å‹...")
        
        rf_model = RandomForestRegressor(
            n_estimators=int(st.session_state.ml_n_estimators * 0.7),
            max_depth=st.session_state.ml_max_depth + 5,
            min_samples_split=5,
            min_samples_leaf=2,
            random_state=42,
            n_jobs=-1
        )
        
        rf_model.fit(X_train_scaled, y_train)
        rf_pred = np.maximum(rf_model.predict(X_test_scaled), 0)
        
        models['RandomForest'] = rf_model
        predictions['RandomForest'] = rf_pred
        
        # æ¨¡å‹èåˆ
        weights = self._calculate_model_weights(predictions, y_test)
        ensemble_pred = (weights['XGBoost'] * predictions['XGBoost'] + 
                        weights['LightGBM'] * predictions['LightGBM'] + 
                        weights['RandomForest'] * predictions['RandomForest'])
        
        predictions['Ensemble'] = ensemble_pred
        
        # æ¨¡å‹è¯„ä¼°
        results = {}
        for model_name, pred in predictions.items():
            smape_accuracies = self.calculate_batch_robust_accuracy(y_test.values, pred)
            smape_accuracy = np.mean(smape_accuracies)
            
            mae = np.mean(np.abs(y_test - pred))
            rmse = np.sqrt(mean_squared_error(y_test, pred))
            r2 = r2_score(y_test, pred)
            
            results[model_name] = {
                'SMAPE_Accuracy': smape_accuracy,
                'MAE': mae,
                'RMSE': rmse,
                'RÂ²': r2
            }
        
        # é€‰æ‹©æœ€ä½³æ¨¡å‹
        best_model_name = max(results.keys(), key=lambda x: results[x]['SMAPE_Accuracy'])
        
        self.models = {
            'best_model': models[best_model_name],
            'best_model_name': best_model_name,
            'all_models': models,
            'feature_cols': feature_cols,
            'weights': weights if best_model_name == 'Ensemble' else None
        }
        
        self.accuracy_results = results
        self.training_time = time.time() - start_time
        
        if progress_callback:
            best_accuracy = results[best_model_name]['SMAPE_Accuracy']
            progress_callback(1.0, f"âœ… è®­ç»ƒå®Œæˆ! {best_model_name}: {best_accuracy:.1f}%")
        
        return True
    
    def calculate_batch_robust_accuracy(self, actual_values, predicted_values):
        """æ‰¹é‡è®¡ç®—SMAPEå‡†ç¡®ç‡"""
        actual_values = np.array(actual_values)
        predicted_values = np.array(predicted_values)
        
        both_zero = (actual_values == 0) & (predicted_values == 0)
        
        smape = 200 * np.abs(actual_values - predicted_values) / (
            np.abs(actual_values) + np.abs(predicted_values) + 1e-8
        )
        accuracy = np.maximum(0, 100 - smape)
        accuracy[both_zero] = 100.0
        
        return accuracy
    
    def _calculate_model_weights(self, predictions, y_true):
        """è®¡ç®—æ¨¡å‹èåˆæƒé‡"""
        scores = {}
        for name, pred in predictions.items():
            smape_accuracies = self.calculate_batch_robust_accuracy(y_true.values, pred)
            scores[name] = np.mean(smape_accuracies)
        
        total_score = sum(scores.values())
        if total_score > 0:
            weights = {name: score / total_score for name, score in scores.items()}
        else:
            weights = {name: 1/len(scores) for name in scores.keys()}
        
        return weights
    
    def predict_future(self, months_ahead=None):
        """é¢„æµ‹æœªæ¥é”€é‡"""
        if months_ahead is None:
            months_ahead = st.session_state.ml_months_ahead
        
        predictions = []
        products = self.feature_data['product_code'].unique()
        
        for product in products:
            product_features = self.feature_data[
                self.feature_data['product_code'] == product
            ].tail(1)
            
            if len(product_features) == 0:
                continue
            
            for month in range(1, months_ahead + 1):
                X = product_features[self.models['feature_cols']]
                X_scaled = self.scalers['feature_scaler'].transform(X)
                
                # é¢„æµ‹
                if self.models['best_model_name'] == 'Ensemble':
                    xgb_pred = self.models['all_models']['XGBoost'].predict(X_scaled)[0]
                    lgb_pred = self.models['all_models']['LightGBM'].predict(X_scaled)[0]
                    rf_pred = self.models['all_models']['RandomForest'].predict(X_scaled)[0]
                    
                    weights = self.models['weights']
                    final_pred = (weights['XGBoost'] * xgb_pred + 
                                 weights['LightGBM'] * lgb_pred + 
                                 weights['RandomForest'] * rf_pred)
                else:
                    final_pred = self.models['best_model'].predict(X_scaled)[0]
                
                final_pred = max(0, final_pred)
                
                # ç½®ä¿¡åŒºé—´
                segment = product_features['segment'].iloc[0]
                confidence_factor = self._get_confidence_factor(segment)
                lower_bound = max(0, final_pred * (1 - confidence_factor))
                upper_bound = final_pred * (1 + confidence_factor)
                
                # ç›®æ ‡æœˆä»½
                target_month = datetime.now().replace(day=1) + timedelta(days=32*month)
                target_month_str = target_month.strftime('%Y-%m')
                
                predictions.append({
                    'äº§å“ä»£ç ': product,
                    'æœªæ¥æœˆä»½': month,
                    'ç›®æ ‡æœˆä»½': target_month_str,
                    'é¢„æµ‹é”€é‡': round(final_pred, 2),
                    'ä¸‹é™': round(lower_bound, 2),
                    'ä¸Šé™': round(upper_bound, 2),
                    'ç½®ä¿¡åº¦': confidence_factor,
                    'äº§å“æ®µ': segment,
                    'ä½¿ç”¨æ¨¡å‹': self.models['best_model_name']
                })
        
        self.predictions = pd.DataFrame(predictions)
        return self.predictions
    
    def _get_confidence_factor(self, segment):
        """è·å–ç½®ä¿¡åº¦å› å­"""
        confidence_map = {
            'é«˜é”€é‡ç¨³å®š': 0.15,
            'é«˜é”€é‡æ³¢åŠ¨': 0.25,
            'ä¸­é”€é‡ç¨³å®š': 0.20,
            'ä¸­é”€é‡æ³¢åŠ¨': 0.30,
            'ä½é”€é‡ç¨³å®š': 0.25,
            'ä½é”€é‡æ³¢åŠ¨': 0.35
        }
        return confidence_map.get(segment, 0.25)

# ====================================================================
# ç•Œé¢å‡½æ•°
# ====================================================================

def render_ml_header():
    """æ¸²æŸ“æœºå™¨å­¦ä¹ å¤´éƒ¨"""
    user_display = st.session_state.get('display_name', st.session_state.get('username', 'ç”¨æˆ·'))
    
    st.markdown(f"""
    <div class="ml-header">
        <h1 class="ml-title">ğŸ¤– æœºå™¨å­¦ä¹ æ¨¡å‹é¢„æµ‹</h1>
        <p class="ml-subtitle">
            åŸºäºGitHubæ•°æ®çš„æ™ºèƒ½é”€é‡é¢„æµ‹ç³»ç»Ÿ | æ¬¢è¿ {user_display}
        </p>
        <div style="display: flex; justify-content: center; gap: 1rem; flex-wrap: wrap; margin-top: 1rem;">
            <span style="background: linear-gradient(135deg, #4CAF50 0%, #45a049 100%); color: white; padding: 0.5rem 1rem; border-radius: 20px;">âœ… GitHubæ•°æ®æº</span>
            <span style="background: linear-gradient(135deg, #FF9800 0%, #F57C00 100%); color: white; padding: 0.5rem 1rem; border-radius: 20px;">ğŸ¤– å¤šæ¨¡å‹èåˆ</span>
            <span style="background: linear-gradient(135deg, #2196F3 0%, #1976D2 100%); color: white; padding: 0.5rem 1rem; border-radius: 20px;">ğŸ“Š æ—¶åºåˆ†æ</span>
            <span style="background: linear-gradient(135deg, #9C27B0 0%, #7B1FA2 100%); color: white; padding: 0.5rem 1rem; border-radius: 20px;">ğŸ¯ æ™ºèƒ½é¢„æµ‹</span>
        </div>
        <div style="margin-top: 1rem; font-size: 0.9rem; color: #666;">
            æ•°æ®æº: {st.session_state.github_repo} | æ–‡ä»¶: {st.session_state.data_file_path}
        </div>
    </div>
    """, unsafe_allow_html=True)

def show_data_loading_tab():
    """æ•°æ®åŠ è½½æ ‡ç­¾é¡µ"""
    st.markdown("### ğŸ“ GitHubæ•°æ®åŠ è½½")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("#### ğŸ”— GitHubæ•°æ®æºé…ç½®")
        
        # GitHubé…ç½®
        st.session_state.github_repo = st.text_input(
            "GitHubä»“åº“", 
            value=st.session_state.github_repo,
            help="æ ¼å¼: ç”¨æˆ·å/ä»“åº“å"
        )
        
        st.session_state.github_branch = st.text_input(
            "åˆ†æ”¯åç§°", 
            value=st.session_state.github_branch
        )
        
        st.session_state.data_file_path = st.text_input(
            "æ•°æ®æ–‡ä»¶è·¯å¾„", 
            value=st.session_state.data_file_path,
            help="ç›¸å¯¹äºä»“åº“æ ¹ç›®å½•çš„æ–‡ä»¶è·¯å¾„"
        )
        
        # æ•°æ®åŠ è½½æŒ‰é’®
        if st.button("ğŸ” åŠ è½½GitHubæ•°æ®", type="primary", use_container_width=True):
            try:
                with st.spinner("æ­£åœ¨ä»GitHubåŠ è½½æ•°æ®..."):
                    # åˆå§‹åŒ–ç³»ç»Ÿ
                    system = GitHubMLPredictionSystem()
                    
                    # åˆ›å»ºè¿›åº¦æ˜¾ç¤º
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    def update_progress(progress, message):
                        progress_bar.progress(progress)
                        status_text.text(message)
                    
                    # åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
                    if system.load_data_from_github(update_progress):
                        system.preprocess_data(update_progress)
                        
                        # ä¿å­˜åˆ°session state
                        st.session_state.ml_prediction_system = system
                        st.session_state.ml_data_loaded = True
                        st.session_state.ml_data_validation_passed = True
                        
                        progress_bar.empty()
                        status_text.empty()
                        
                        # æ˜¾ç¤ºæ•°æ®æ‘˜è¦
                        st.success("âœ… GitHubæ•°æ®åŠ è½½æˆåŠŸï¼")
                        
                        summary = system.data_summary
                        
                        st.markdown(f"""
                        <div class="success-card">
                            <h4>ğŸ“Š GitHubæ•°æ®æ‘˜è¦</h4>
                            <p><strong>ä»“åº“:</strong> {summary['data_source']['repo']}</p>
                            <p><strong>æ–‡ä»¶:</strong> {summary['data_source']['file_path']}</p>
                            <p><strong>æ•°æ®è®°å½•:</strong> {summary['total_records']:,} æ¡</p>
                            <p><strong>äº§å“æ•°é‡:</strong> {summary['total_products']} ä¸ª</p>
                            <p><strong>å®¢æˆ·æ•°é‡:</strong> {summary['total_customers']} ä¸ª</p>
                            <p><strong>æ—¶é—´è·¨åº¦:</strong> {summary['date_range'][0].strftime('%Y-%m-%d')} è‡³ {summary['date_range'][1].strftime('%Y-%m-%d')}</p>
                            <p><strong>æ€»é”€é‡:</strong> {summary['total_quantity']:,.0f} ç®±</p>
                            <p><strong>æ•°æ®è´¨é‡:</strong> {summary['data_quality_score']}/100</p>
                            <p><strong>åŠ è½½æ—¶é—´:</strong> {summary['data_source']['load_time']}</p>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # æ•°æ®é¢„è§ˆ
                        st.markdown("##### ğŸ“‹ GitHubæ•°æ®é¢„è§ˆ")
                        st.dataframe(system.shipment_data.head(10), use_container_width=True)
                        
            except Exception as e:
                st.error(f"âŒ GitHubæ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
                st.markdown(f"""
                <div class="error-card">
                    <h4>ğŸ’¡ GitHubæ•°æ®åŠ è½½å»ºè®®</h4>
                    <p>è¯·æ£€æŸ¥ä»¥ä¸‹è®¾ç½®:</p>
                    <ul>
                        <li>GitHubä»“åº“åç§°æ˜¯å¦æ­£ç¡®</li>
                        <li>åˆ†æ”¯åç§°æ˜¯å¦å­˜åœ¨</li>
                        <li>æ•°æ®æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®</li>
                        <li>æ–‡ä»¶æ˜¯å¦ä¸ºExcelæ ¼å¼(.xlsx)</li>
                        <li>ä»“åº“æ˜¯å¦ä¸ºå…¬å¼€ä»“åº“</li>
                    </ul>
                    <p><strong>å½“å‰é…ç½®:</strong></p>
                    <p>ä»“åº“: {st.session_state.github_repo}</p>
                    <p>åˆ†æ”¯: {st.session_state.github_branch}</p>
                    <p>æ–‡ä»¶: {st.session_state.data_file_path}</p>
                </div>
                """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("#### ğŸ“‹ GitHubé…ç½®è¯´æ˜")
        
        requirements = f"""
        <div class="feature-card">
            <h4>âœ… å½“å‰é…ç½®</h4>
            <p><strong>ä»“åº“:</strong> {st.session_state.github_repo}</p>
            <p><strong>åˆ†æ”¯:</strong> {st.session_state.github_branch}</p>
            <p><strong>æ–‡ä»¶:</strong> {st.session_state.data_file_path}</p>
            
            <h4>ğŸ”§ é…ç½®è¦æ±‚</h4>
            <ul>
                <li>å…¬å¼€GitHubä»“åº“</li>
                <li>Excelæ ¼å¼(.xlsx)æ–‡ä»¶</li>
                <li>åŒ…å«é”€å”®æ•°æ®åˆ—</li>
                <li>æ­£ç¡®çš„æ–‡ä»¶è·¯å¾„</li>
            </ul>
            
            <h4>ğŸ“Š æ•°æ®è¦æ±‚</h4>
            <ul>
                <li>æ—¥æœŸåˆ—ï¼ˆè®¢å•æ—¥æœŸï¼‰</li>
                <li>äº§å“ä»£ç åˆ—</li>
                <li>é”€é‡/æ•°é‡åˆ—</li>
                <li>è‡³å°‘3ä¸ªæœˆæ•°æ®</li>
            </ul>
        </div>
        """
        
        st.markdown(requirements, unsafe_allow_html=True)
        
        # GitHub URLé¢„è§ˆ
        if st.session_state.github_repo and st.session_state.data_file_path:
            github_url = f"https://raw.githubusercontent.com/{st.session_state.github_repo}/{st.session_state.github_branch}/{st.session_state.data_file_path}"
            
            st.markdown("#### ğŸ”— æ•°æ®æºURL")
            st.code(github_url, language="text")

def show_ml_training_tab():
    """æœºå™¨å­¦ä¹ è®­ç»ƒæ ‡ç­¾é¡µ"""
    st.markdown("### ğŸš€ æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒ")
    
    if not st.session_state.ml_data_loaded:
        st.warning("âš ï¸ è¯·å…ˆåŠ è½½GitHubæ•°æ®")
        return
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("#### ğŸ¯ å¤šæ¨¡å‹èåˆè®­ç»ƒ")
        
        # è®­ç»ƒè¯´æ˜
        st.markdown("""
        <div class="feature-card">
            <h4>ğŸ¤– æœºå™¨å­¦ä¹ æ¨¡å‹</h4>
            <ul>
                <li>ğŸŸ¦ <strong>XGBoost:</strong> æ¢¯åº¦æå‡æ ‘æ¨¡å‹ï¼Œå¤„ç†éçº¿æ€§å…³ç³»</li>
                <li>ğŸŸ© <strong>LightGBM:</strong> è½»é‡çº§æ¢¯åº¦æå‡ï¼Œå¿«é€Ÿè®­ç»ƒ</li>
                <li>ğŸŸ¨ <strong>Random Forest:</strong> éšæœºæ£®æ—æ¨¡å‹ï¼Œé²æ£’æ€§å¼º</li>
                <li>ğŸŸª <strong>Ensemble:</strong> å¤šæ¨¡å‹èåˆï¼Œæå‡é¢„æµ‹ç²¾åº¦</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
        
        # è®­ç»ƒæŒ‰é’®
        if st.button("ğŸš€ å¼€å§‹æœºå™¨å­¦ä¹ è®­ç»ƒ", type="primary", use_container_width=True):
            try:
                system = st.session_state.ml_prediction_system
                
                with st.container():
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    def update_progress(progress, message):
                        progress_bar.progress(progress)
                        status_text.text(message)
                    
                    # ç‰¹å¾å·¥ç¨‹
                    if system.create_features(update_progress):
                        # æ¨¡å‹è®­ç»ƒ
                        if system.train_models(update_progress):
                            # é¢„æµ‹æœªæ¥
                            system.predict_future()
                            
                            # ä¿å­˜ç³»ç»Ÿ
                            st.session_state.ml_prediction_system = system
                            st.session_state.ml_model_trained = True
                            
                            progress_bar.empty()
                            status_text.empty()
                            
                            st.success("ğŸ‰ æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
                            st.balloons()
                            st.rerun()
                
            except Exception as e:
                st.error(f"âŒ è®­ç»ƒå¤±è´¥: {str(e)}")
    
    with col2:
        if st.session_state.ml_model_trained and st.session_state.ml_prediction_system:
            system = st.session_state.ml_prediction_system
            
            st.markdown("#### ğŸ† è®­ç»ƒç»“æœ")
            
            best_model = system.models['best_model_name']
            best_accuracy = system.accuracy_results[best_model]['SMAPE_Accuracy']
            
            # å‡†ç¡®ç‡å¡ç‰‡
            st.markdown(f"""
            <div class="metric-card">
                <div class="metric-value">{best_accuracy:.1f}%</div>
                <div class="metric-label">SMAPEå‡†ç¡®ç‡</div>
            </div>
            """, unsafe_allow_html=True)
            
            # è®­ç»ƒæ‘˜è¦
            st.markdown(f"""
            <div class="feature-card">
                <h4>âœ… è®­ç»ƒå®Œæˆ</h4>
                <p><strong>æœ€ä½³æ¨¡å‹:</strong> {best_model}</p>
                <p><strong>è®­ç»ƒæ—¶é—´:</strong> {system.training_time:.1f}ç§’</p>
                <p><strong>ç‰¹å¾æ•°:</strong> {len(system.models['feature_cols'])}</p>
                <p><strong>è®­ç»ƒæ ·æœ¬:</strong> {len(system.feature_data)}</p>
                <p><strong>æ•°æ®è´¨é‡:</strong> {system.data_summary['data_quality_score']}/100</p>
                <p><strong>æ•°æ®æº:</strong> GitHub</p>
            </div>
            """, unsafe_allow_html=True)
            
            # æ¨¡å‹å¯¹æ¯”
            st.markdown("#### ğŸ“Š æ¨¡å‹å¯¹æ¯”")
            comparison_data = []
            for model_name, results in system.accuracy_results.items():
                comparison_data.append({
                    'æ¨¡å‹': model_name,
                    'SMAPEå‡†ç¡®ç‡': f"{results['SMAPE_Accuracy']:.1f}%",
                    'MAE': f"{results['MAE']:.1f}",
                    'RÂ²': f"{results['RÂ²']:.3f}"
                })
            
            comparison_df = pd.DataFrame(comparison_data)
            st.dataframe(comparison_df, use_container_width=True, hide_index=True)
        
        else:
            system = st.session_state.ml_prediction_system
            summary = system.data_summary
            
            st.markdown("#### ğŸ“Š è®­ç»ƒå‡†å¤‡å°±ç»ª")
            st.markdown(f"""
            <div class="feature-card">
                <h4>ğŸ¯ GitHubæ•°æ®å°±ç»ª</h4>
                <p><strong>æ•°æ®æº:</strong> {summary['data_source']['repo']}</p>
                <p><strong>è®°å½•æ•°:</strong> {summary['total_records']:,}</p>
                <p><strong>äº§å“æ•°:</strong> {summary['total_products']}</p>
                <p><strong>è´¨é‡è¯„åˆ†:</strong> {summary['data_quality_score']}/100</p>
                <p><strong>æ—¶é—´è·¨åº¦:</strong> {(summary['date_range'][1] - summary['date_range'][0]).days} å¤©</p>
                
                <h5>ğŸ”§ è®­ç»ƒç‰¹ç‚¹:</h5>
                <ul>
                    <li>å¤šæ¨¡å‹èåˆè®­ç»ƒ</li>
                    <li>æ—¶é—´åºåˆ—ç‰¹å¾å·¥ç¨‹</li>
                    <li>SMAPEå‡†ç¡®ç‡è¯„ä¼°</li>
                    <li>è‡ªé€‚åº”æƒé‡ä¼˜åŒ–</li>
                </ul>
            </div>
            """, unsafe_allow_html=True)

def show_ml_prediction_tab():
    """æœºå™¨å­¦ä¹ é¢„æµ‹ç»“æœæ ‡ç­¾é¡µ"""
    st.markdown("### ğŸ”® æ™ºèƒ½é¢„æµ‹ç»“æœ")
    
    if not st.session_state.ml_model_trained:
        st.warning("âš ï¸ è¯·å…ˆå®Œæˆæœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒ")
        return
    
    system = st.session_state.ml_prediction_system
    
    # é¢„æµ‹ç»“æœå±•ç¤º
    if system.predictions is not None:
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # é¢„æµ‹æ±‡æ€»å›¾
            monthly_summary = system.predictions.groupby('æœªæ¥æœˆä»½').agg({
                'é¢„æµ‹é”€é‡': 'sum',
                'ä¸‹é™': 'sum',
                'ä¸Šé™': 'sum'
            }).reset_index()
            
            fig = go.Figure()
            fig.add_trace(go.Bar(
                x=[f"ç¬¬{m}ä¸ªæœˆ" for m in monthly_summary['æœªæ¥æœˆä»½']],
                y=monthly_summary['é¢„æµ‹é”€é‡'],
                name='é¢„æµ‹é”€é‡',
                marker_color='#667eea'
            ))
            
            fig.add_trace(go.Scatter(
                x=[f"ç¬¬{m}ä¸ªæœˆ" for m in monthly_summary['æœªæ¥æœˆä»½']],
                y=monthly_summary['ä¸Šé™'],
                mode='lines',
                name='ä¸Šé™',
                line=dict(color='red', dash='dash')
            ))
            
            fig.add_trace(go.Scatter(
                x=[f"ç¬¬{m}ä¸ªæœˆ" for m in monthly_summary['æœªæ¥æœˆä»½']],
                y=monthly_summary['ä¸‹é™'],
                mode='lines',
                name='ä¸‹é™',
                line=dict(color='green', dash='dash')
            ))
            
            fig.update_layout(
                title="ğŸ¤– æœºå™¨å­¦ä¹ æ™ºèƒ½é¢„æµ‹æ±‡æ€»",
                xaxis_title="æœˆä»½",
                yaxis_title="é¢„æµ‹é”€é‡",
                height=400
            )
            
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            total_pred = system.predictions['é¢„æµ‹é”€é‡'].sum()
            
            st.markdown(f"""
            <div class="metric-card">
                <div class="metric-value">{total_pred:,.0f}</div>
                <div class="metric-label">æ€»é¢„æµ‹é”€é‡(ç®±)</div>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown(f"""
            <div class="feature-card">
                <h4>ğŸ¤– æ™ºèƒ½é¢„æµ‹æ‘˜è¦</h4>
                <p><strong>é¢„æµ‹äº§å“:</strong> {system.predictions['äº§å“ä»£ç '].nunique()} ä¸ª</p>
                <p><strong>é¢„æµ‹æœˆæ•°:</strong> {system.predictions['æœªæ¥æœˆä»½'].max()} ä¸ªæœˆ</p>
                <p><strong>æœ€ä½³æ¨¡å‹:</strong> {system.models['best_model_name']}</p>
                <p><strong>é¢„æµ‹è®°å½•:</strong> {len(system.predictions)} æ¡</p>
                <p><strong>æ•°æ®æ¥æº:</strong> GitHub</p>
                <p><strong>ç½®ä¿¡åŒºé—´:</strong> å·²è®¡ç®—</p>
            </div>
            """, unsafe_allow_html=True)
        
        # äº§å“æ®µé¢„æµ‹åˆ†æ
        st.markdown("#### ğŸ“Š äº§å“æ®µé¢„æµ‹åˆ†æ")
        
        segment_summary = system.predictions.groupby('äº§å“æ®µ').agg({
            'é¢„æµ‹é”€é‡': ['sum', 'mean', 'count']
        }).round(2)
        
        segment_summary.columns = ['æ€»é¢„æµ‹é‡', 'å¹³å‡é¢„æµ‹é‡', 'äº§å“æ•°']
        segment_summary = segment_summary.reset_index()
        
        fig_segment = px.pie(
            segment_summary, 
            values='æ€»é¢„æµ‹é‡', 
            names='äº§å“æ®µ',
            title="ğŸ“ˆ å„äº§å“æ®µé¢„æµ‹é”€é‡åˆ†å¸ƒ"
        )
        st.plotly_chart(fig_segment, use_container_width=True)
        
        # è¯¦ç»†é¢„æµ‹è¡¨æ ¼
        st.markdown("#### ğŸ“‹ è¯¦ç»†é¢„æµ‹è®°å½•")
        
        display_columns = ['äº§å“ä»£ç ', 'æœªæ¥æœˆä»½', 'ç›®æ ‡æœˆä»½', 'é¢„æµ‹é”€é‡', 'ä¸‹é™', 'ä¸Šé™', 'äº§å“æ®µ', 'ä½¿ç”¨æ¨¡å‹']
        st.dataframe(
            system.predictions[display_columns],
            use_container_width=True,
            hide_index=True
        )
        
        # å¯¼å‡ºåŠŸèƒ½
        col1, col2, col3 = st.columns(3)
        
        with col1:
            csv = system.predictions.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½CSVæ ¼å¼",
                data=csv,
                file_name=f"MLé¢„æµ‹ç»“æœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )
        
        with col2:
            # åˆ›å»ºExcelæ–‡ä»¶
            excel_buffer = io.BytesIO()
            with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                system.predictions.to_excel(writer, sheet_name='é¢„æµ‹ç»“æœ', index=False)
                segment_summary.to_excel(writer, sheet_name='äº§å“æ®µæ±‡æ€»', index=False)
            excel_data = excel_buffer.getvalue()
            
            st.download_button(
                label="ğŸ“Š ä¸‹è½½Excelæ ¼å¼",
                data=excel_data,
                file_name=f"MLé¢„æµ‹ç»“æœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        
        with col3:
            # é¢„æµ‹æ‘˜è¦JSON
            prediction_summary = {
                'prediction_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'model_used': system.models['best_model_name'],
                'total_prediction': float(total_pred),
                'products_count': int(system.predictions['äº§å“ä»£ç '].nunique()),
                'months_ahead': int(system.predictions['æœªæ¥æœˆä»½'].max()),
                'data_source': system.data_source_info,
                'accuracy': system.accuracy_results[system.models['best_model_name']]
            }
            
            st.download_button(
                label="ğŸ“‹ ä¸‹è½½é¢„æµ‹æ‘˜è¦",
                data=json.dumps(prediction_summary, ensure_ascii=False, indent=2),
                file_name=f"MLé¢„æµ‹æ‘˜è¦_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )

def create_ml_sidebar():
    """åˆ›å»ºæœºå™¨å­¦ä¹ ä¾§è¾¹æ """
    with st.sidebar:
        st.markdown("### ğŸ›ï¸ MLæ§åˆ¶å°")
        
        # ç”¨æˆ·ä¿¡æ¯
        user_display = st.session_state.get('display_name', st.session_state.get('username', 'ç”¨æˆ·'))
        st.markdown(f"ğŸ‘‹ æ¬¢è¿, {user_display}")
        
        # ç³»ç»ŸçŠ¶æ€
        st.markdown("#### ğŸ“Š ç³»ç»ŸçŠ¶æ€")
        
        if st.session_state.ml_data_loaded:
            data_color = "success"
            data_text = "GitHubæ•°æ®å·²åŠ è½½"
        else:
            data_color = "warning"
            data_text = "ç­‰å¾…åŠ è½½æ•°æ®"
        
        if st.session_state.ml_model_trained:
            model_color = "success"
            model_text = "MLæ¨¡å‹å·²è®­ç»ƒ"
        else:
            model_color = "warning"
            model_text = "ç­‰å¾…æ¨¡å‹è®­ç»ƒ"
        
        st.markdown(f"""
        <div class="feature-card">
            <div style="display: flex; align-items: center; margin-bottom: 0.5rem;">
                <span class="status-indicator status-{data_color}"></span>
                <strong>{data_text}</strong>
            </div>
            <div style="display: flex; align-items: center;">
                <span class="status-indicator status-{model_color}"></span>
                <strong>{model_text}</strong>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        # MLè®­ç»ƒå‚æ•°
        st.markdown("#### âš™ï¸ MLå‚æ•°")
        st.session_state.ml_test_ratio = st.slider("æµ‹è¯•é›†æ¯”ä¾‹", 0.1, 0.3, st.session_state.ml_test_ratio, 0.05)
        st.session_state.ml_months_ahead = st.slider("é¢„æµ‹æœˆæ•°", 1, 6, st.session_state.ml_months_ahead)
        
        with st.expander("é«˜çº§MLå‚æ•°"):
            st.session_state.ml_outlier_factor = st.slider("å¼‚å¸¸å€¼å› å­", 2.0, 5.0, st.session_state.ml_outlier_factor, 0.5)
            st.session_state.ml_min_data_points = st.slider("æœ€å°æ•°æ®ç‚¹", 3, 6, st.session_state.ml_min_data_points)
            st.session_state.ml_n_estimators = st.slider("æ ‘çš„æ•°é‡", 100, 500, st.session_state.ml_n_estimators, 50)
            st.session_state.ml_max_depth = st.slider("æœ€å¤§æ·±åº¦", 3, 15, st.session_state.ml_max_depth)
            st.session_state.ml_learning_rate = st.slider("å­¦ä¹ ç‡", 0.01, 0.2, st.session_state.ml_learning_rate, 0.01)
        
        # å¿«æ·æ“ä½œ
        st.markdown("#### âš¡ å¿«æ·æ“ä½œ")
        
        if st.button("ğŸ“Š è¿”å›ä¸»é¡µ", use_container_width=True):
            # æ¸…é™¤å½“å‰é¡µé¢çŠ¶æ€ï¼Œè¿”å›ä¸»ç™»å½•åé¡µé¢
            for key in list(st.session_state.keys()):
                if key.startswith('ml_'):
                    del st.session_state[key]
            st.rerun()
        
        if st.button("ğŸ”„ é‡ç½®MLç³»ç»Ÿ", use_container_width=True):
            for key in ['ml_model_trained', 'ml_prediction_system', 'ml_data_loaded', 
                       'ml_data_validation_passed']:
                if key in st.session_state:
                    if key in ['ml_model_trained', 'ml_data_loaded', 'ml_data_validation_passed']:
                        st.session_state[key] = False
                    else:
                        st.session_state[key] = None
            st.success("âœ… MLç³»ç»Ÿå·²é‡ç½®")
            st.rerun()
        
        if st.button("ğŸšª é€€å‡ºç™»å½•", use_container_width=True):
            st.session_state.clear()
            st.success("ğŸ‘‹ å·²é€€å‡ºç™»å½•")
            st.rerun()

# ====================================================================
# ä¸»ç¨‹åº
# ====================================================================

def main():
    """ä¸»ç¨‹åº"""
    render_ml_header()
    create_ml_sidebar()
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4 = st.tabs([
        "ğŸ“ GitHubæ•°æ®",
        "ğŸš€ MLè®­ç»ƒ", 
        "ğŸ”® æ™ºèƒ½é¢„æµ‹",
        "ğŸ” ç³»ç»Ÿä¿¡æ¯"
    ])
    
    with tab1:
        show_data_loading_tab()
    
    with tab2:
        show_ml_training_tab()
    
    with tab3:
        show_ml_prediction_tab()
    
    with tab4:
        if st.session_state.ml_model_trained:
            system = st.session_state.ml_prediction_system
            
            st.markdown("### ğŸ” æœºå™¨å­¦ä¹ ç³»ç»Ÿä¿¡æ¯")
            
            # GitHubæ•°æ®æºä¿¡æ¯
            st.markdown("#### ğŸ“Š GitHubæ•°æ®æº")
            source_info = system.data_summary['data_source']
            st.json(source_info)
            
            # MLæ¨¡å‹ä¿¡æ¯
            st.markdown("#### ğŸ¤– MLæ¨¡å‹ä¿¡æ¯")
            model_info = {
                'best_model': system.models['best_model_name'],
                'feature_count': len(system.models['feature_cols']),
                'training_time': f"{system.training_time:.2f}ç§’",
                'data_quality_score': system.data_summary['data_quality_score'],
                'github_repo': st.session_state.github_repo,
                'data_file': st.session_state.data_file_path
            }
            st.json(model_info)
            
            # å‡†ç¡®ç‡è¯¦æƒ…
            st.markdown("#### ğŸ¯ æ¨¡å‹å‡†ç¡®ç‡è¯¦æƒ…")
            st.json(system.accuracy_results)
            
            # ç‰¹å¾é‡è¦æ€§ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if hasattr(system.models['best_model'], 'feature_importances_'):
                st.markdown("#### ğŸ“ˆ ç‰¹å¾é‡è¦æ€§")
                feature_importance = pd.DataFrame({
                    'feature': system.models['feature_cols'],
                    'importance': system.models['best_model'].feature_importances_
                }).sort_values('importance', ascending=False)
                
                fig_importance = px.bar(
                    feature_importance.head(10), 
                    x='importance', 
                    y='feature',
                    orientation='h',
                    title="Top 10 ç‰¹å¾é‡è¦æ€§"
                )
                st.plotly_chart(fig_importance, use_container_width=True)
            
        else:
            st.info("è¯·å…ˆå®Œæˆæœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒä»¥æŸ¥çœ‹ç³»ç»Ÿä¿¡æ¯")

if __name__ == "__main__":
    main()
