# pages/05_æœºå™¨å­¦ä¹ æ¨¡å‹é¢„æµ‹_é‡æ„ç‰ˆ.py
"""
é‡æ„ä¼˜åŒ–çš„é”€å”®é¢„æµ‹ç³»ç»Ÿ - ç›®æ ‡å‡†ç¡®ç‡ï¼š85-90%
ä¿®å¤æ—¶é—´åºåˆ—å¤„ç†ã€å¢å¼ºç‰¹å¾å·¥ç¨‹ã€ç§‘å­¦è¯„ä¼°æ–¹æ³•
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, r2_score
from sklearn.preprocessing import RobustScaler
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb
import lightgbm as lgb
import os
import time
# ç§»é™¤ä¸å¿…è¦çš„importä»¥åŠ é€ŸåŠ è½½
# from scipy import stats
# from scipy.stats import boxcox  
# from statsmodels.tsa.seasonal import seasonal_decompose

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="é‡æ„ç‰ˆ - æœºå™¨å­¦ä¹ æ¨¡å‹é¢„æµ‹",
    page_icon="ğŸš€",
    layout="wide"
)

# æƒé™æ£€æŸ¥å‡½æ•°
def check_admin_access():
    """æ£€æŸ¥ç®¡ç†å‘˜æƒé™"""
    if not hasattr(st.session_state, 'authenticated') or not st.session_state.authenticated:
        st.error("âŒ æœªç™»å½•ï¼Œè¯·å…ˆä»ä¸»é¡µç™»å½•")
        st.stop()
    
    if not hasattr(st.session_state, 'username') or st.session_state.username != 'admin':
        st.error("âŒ æƒé™ä¸è¶³ï¼Œæ­¤åŠŸèƒ½ä»…é™ç®¡ç†å‘˜ä½¿ç”¨")
        st.info("ğŸ’¡ è¯·ä½¿ç”¨ç®¡ç†å‘˜è´¦å·ç™»å½•")
        st.stop()

# æ‰§è¡Œæƒé™æ£€æŸ¥
check_admin_access()

# ä¿æŒåŸæœ‰çš„CSSæ ·å¼
unified_admin_styles = """
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');
    
    .stApp {
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        min-height: 100vh;
    }
    
    .main {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        min-height: 100vh;
        position: relative;
        overflow: hidden;
    }
    
    .main::before {
        content: '';
        position: fixed;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        background: 
            radial-gradient(circle at 20% 20%, rgba(120, 119, 198, 0.6) 0%, transparent 60%),
            radial-gradient(circle at 80% 80%, rgba(255, 255, 255, 0.3) 0%, transparent 50%),
            radial-gradient(circle at 40% 60%, rgba(120, 119, 198, 0.4) 0%, transparent 70%);
        animation: enhancedWaveMove 12s ease-in-out infinite;
        pointer-events: none;
        z-index: 0;
    }
    
    @keyframes enhancedWaveMove {
        0%, 100% { 
            background-size: 200% 200%, 150% 150%, 300% 300%;
            background-position: 0% 0%, 100% 100%, 50% 50%; 
        }
        50% { 
            background-size: 250% 250%, 300% 300%, 200% 200%;
            background-position: 50% 100%, 50% 0%, 20% 80%; 
        }
    }
    
    .block-container {
        position: relative;
        z-index: 10;
        background: rgba(255, 255, 255, 0.02);
        backdrop-filter: blur(8px);
        padding-top: 1rem;
        max-width: 100%;
    }
    
    .admin-header {
        background: rgba(255, 255, 255, 0.95);
        backdrop-filter: blur(25px);
        border-radius: 20px;
        padding: 1.5rem;
        margin-bottom: 2rem;
        box-shadow: 0 10px 30px rgba(0,0,0,0.1);
        border: 1px solid rgba(255, 255, 255, 0.3);
        position: relative;
        z-index: 20;
    }
    
    .admin-badge {
        background: linear-gradient(135deg, #ff6b6b 0%, #ffa500 100%);
        color: white;
        padding: 0.4rem 1rem;
        border-radius: 20px;
        font-size: 0.9rem;
        font-weight: 600;
        display: inline-block;
        margin-bottom: 0.5rem;
        animation: adminBadgePulse 2s ease-in-out infinite;
    }
    
    @keyframes adminBadgePulse {
        0%, 100% { 
            box-shadow: 0 0 10px rgba(255, 107, 107, 0.3);
            transform: scale(1);
        }
        50% { 
            box-shadow: 0 0 20px rgba(255, 107, 107, 0.6);
            transform: scale(1.05);
        }
    }
    
    .main-header {
        background: rgba(255, 255, 255, 0.95);
        backdrop-filter: blur(25px);
        color: #2d3748;
        padding: 2rem;
        border-radius: 20px;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 10px 30px rgba(0,0,0,0.1);
        border: 1px solid rgba(255, 255, 255, 0.3);
        position: relative;
        z-index: 20;
    }
    
    .main-title {
        font-size: 2.5rem;
        font-weight: 800;
        margin-bottom: 0.5rem;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        background-clip: text;
        -webkit-text-fill-color: transparent;
    }
    
    .metric-card {
        background: rgba(255, 255, 255, 0.95);
        backdrop-filter: blur(25px);
        border-radius: 15px;
        padding: 1.5rem;
        box-shadow: 0 5px 15px rgba(0,0,0,0.08);
        border: 1px solid rgba(255, 255, 255, 0.3);
        border-left: 4px solid #667eea;
        transition: transform 0.3s ease;
        position: relative;
        z-index: 20;
    }
    
    .metric-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 10px 25px rgba(0,0,0,0.15);
    }
    
    .metric-value {
        font-size: 2rem;
        font-weight: 700;
        color: #667eea;
    }
    
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        padding: 0.75rem 2rem;
        border-radius: 10px;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 5px 15px rgba(102, 126, 234, 0.3);
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 20px rgba(102, 126, 234, 0.4);
    }
    
    .info-box {
        background: rgba(240, 244, 255, 0.95);
        backdrop-filter: blur(15px);
        border: 1px solid rgba(255, 255, 255, 0.3);
        border-left: 4px solid #667eea;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
        position: relative;
        z-index: 20;
    }
</style>
"""

st.markdown(unified_admin_styles, unsafe_allow_html=True)

# ç®¡ç†å‘˜å¤´éƒ¨ä¿¡æ¯
def render_admin_header():
    """æ¸²æŸ“ç®¡ç†å‘˜å¤´éƒ¨ä¿¡æ¯"""
    col1, col2, col3 = st.columns([2, 1, 1])
    
    with col1:
        st.markdown(f"""
        <div class="admin-header">
            <div class="admin-badge">ğŸš€ é‡æ„ä¼˜åŒ–ç‰ˆ</div>
            <h3 style="margin: 0; color: #2d3748;">æ¬¢è¿ï¼Œ{st.session_state.get('display_name', 'ç®¡ç†å‘˜')}</h3>
            <p style="margin: 0.5rem 0 0 0; color: #718096; font-size: 0.9rem;">
                ç™»å½•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
            </p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        if st.button("ğŸšª é€€å‡ºç™»å½•", key="logout_btn"):
            for key in list(st.session_state.keys()):
                del st.session_state[key]
            st.success("âœ… å·²æˆåŠŸé€€å‡ºç™»å½•")
            time.sleep(1)
            st.rerun()

render_admin_header()

# é¡µé¢æ ‡é¢˜
st.markdown("""
<div class="main-header">
    <h1 class="main-title">âš¡ é€Ÿåº¦ä¼˜åŒ–é”€å”®é¢„æµ‹ç³»ç»Ÿ</h1>
    <p class="main-subtitle">å¿«é€Ÿè®­ç»ƒ + ç§‘å­¦æ–¹æ³• + é«˜ç²¾åº¦é¢„æµ‹ (ç›®æ ‡å‡†ç¡®ç‡: 85-90%, è®­ç»ƒæ—¶é—´: 3-4åˆ†é’Ÿ)</p>
</div>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–session state
if 'optimized_model_trained' not in st.session_state:
    st.session_state.optimized_model_trained = False
if 'optimized_prediction_system' not in st.session_state:
    st.session_state.optimized_prediction_system = None

class OptimizedSalesPredictionSystem:
    """é‡æ„ä¼˜åŒ–çš„é”€å”®é¢„æµ‹ç³»ç»Ÿ"""
    
    def __init__(self):
        self.shipment_data = None
        self.promotion_data = None
        self.processed_data = None
        self.feature_data = None
        self.models = {}
        self.scalers = {}
        self.predictions = None
        self.evaluation_results = {}
        self.feature_importance = None
        self.validation_history = []
        self.seasonal_components = {}
        self.data_quality_report = {}
        
    def load_and_validate_data(self, progress_callback=None):
        """åŠ è½½å¹¶éªŒè¯æ•°æ®è´¨é‡"""
        try:
            if progress_callback:
                progress_callback(0.1, "æ­£åœ¨åŠ è½½æ•°æ®æ–‡ä»¶...")
            
            # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
            shipment_file = "é¢„æµ‹æ¨¡å‹å‡ºè´§æ•°æ®æ¯æ—¥xlsx.xlsx"
            promotion_file = "é”€å”®ä¸šåŠ¡å‘˜ä¿ƒé”€æ–‡ä»¶.xlsx"
            
            if not os.path.exists(shipment_file):
                st.error(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {shipment_file}")
                return False
                
            if not os.path.exists(promotion_file):
                st.warning(f"âš ï¸ ä¿ƒé”€æ–‡ä»¶ä¸å­˜åœ¨: {promotion_file}ï¼Œå°†è·³è¿‡ä¿ƒé”€ç‰¹å¾")
                
            # åŠ è½½æ•°æ®
            self.shipment_data = pd.read_excel(shipment_file)
            if os.path.exists(promotion_file):
                self.promotion_data = pd.read_excel(promotion_file)
            
            if progress_callback:
                progress_callback(0.2, "æ•°æ®åŠ è½½å®Œæˆï¼Œå¼€å§‹è´¨é‡æ£€æŸ¥...")
            
            # æ•°æ®è´¨é‡æ£€æŸ¥
            quality_issues = self._comprehensive_data_quality_check()
            
            if progress_callback:
                progress_callback(0.3, f"âœ… æ•°æ®è´¨é‡æ£€æŸ¥å®Œæˆ: {len(quality_issues)} ä¸ªé—®é¢˜")
            
            return True
            
        except Exception as e:
            st.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
            return False
    
    def _comprehensive_data_quality_check(self):
        """å…¨é¢çš„æ•°æ®è´¨é‡æ£€æŸ¥"""
        issues = []
        
        # 1. åŸºç¡€æ•°æ®æ£€æŸ¥
        if self.shipment_data is None or len(self.shipment_data) == 0:
            issues.append("å‡ºè´§æ•°æ®ä¸ºç©º")
            return issues
        
        # 2. åˆ—åæ ‡å‡†åŒ–
        column_mapping = {
            'è®¢å•æ—¥æœŸ': 'order_date',
            'æ‰€å±åŒºåŸŸ': 'region', 
            'å®¢æˆ·ä»£ç ': 'customer_code',
            'äº§å“ä»£ç ': 'product_code',
            'æ±‚å’Œé¡¹:æ•°é‡ï¼ˆç®±ï¼‰': 'quantity'
        }
        
        # æ£€æŸ¥å¿…è¦åˆ—æ˜¯å¦å­˜åœ¨
        required_cols = list(column_mapping.keys())
        missing_cols = [col for col in required_cols if col not in self.shipment_data.columns]
        if missing_cols:
            issues.append(f"ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
            return issues
        
        # é‡å‘½ååˆ—
        self.shipment_data = self.shipment_data.rename(columns=column_mapping)
        
        # 3. æ•°æ®ç±»å‹è½¬æ¢å’ŒéªŒè¯
        try:
            self.shipment_data['order_date'] = pd.to_datetime(self.shipment_data['order_date'])
            self.shipment_data['quantity'] = pd.to_numeric(self.shipment_data['quantity'], errors='coerce')
        except Exception as e:
            issues.append(f"æ•°æ®ç±»å‹è½¬æ¢å¤±è´¥: {str(e)}")
        
        # 4. æ•°æ®èŒƒå›´æ£€æŸ¥
        if self.shipment_data['quantity'].isna().sum() > 0:
            na_count = self.shipment_data['quantity'].isna().sum()
            issues.append(f"æ•°é‡å­—æ®µæœ‰ {na_count} ä¸ªç¼ºå¤±å€¼")
        
        negative_qty = (self.shipment_data['quantity'] < 0).sum()
        if negative_qty > 0:
            issues.append(f"å‘ç° {negative_qty} ä¸ªè´Ÿæ•°é”€é‡")
        
        # 5. æ—¶é—´èŒƒå›´æ£€æŸ¥
        date_range = self.shipment_data['order_date'].max() - self.shipment_data['order_date'].min()
        if date_range < pd.Timedelta(days=365):
            issues.append(f"æ•°æ®æ—¶é—´è·¨åº¦ä¸è¶³ä¸€å¹´: {date_range.days} å¤©")
        
        # 6. æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
        products_count = self.shipment_data['product_code'].nunique()
        if products_count < 10:
            issues.append(f"äº§å“æ•°é‡è¿‡å°‘: {products_count} ä¸ª")
        
        # ä¿å­˜æ•°æ®è´¨é‡æŠ¥å‘Š
        self.data_quality_report = {
            'total_records': len(self.shipment_data),
            'date_range_days': date_range.days,
            'products_count': products_count,
            'regions_count': self.shipment_data['region'].nunique(),
            'issues': issues,
            'data_start': self.shipment_data['order_date'].min(),
            'data_end': self.shipment_data['order_date'].max()
        }
        
        return issues
    
    def scientific_data_preprocessing(self, progress_callback=None):
        """ç§‘å­¦çš„æ•°æ®é¢„å¤„ç†"""
        if progress_callback:
            progress_callback(0.4, "å¼€å§‹ç§‘å­¦æ•°æ®é¢„å¤„ç†...")
        
        # 1. æ¸…ç†æ— æ•ˆæ•°æ®
        original_length = len(self.shipment_data)
        self.shipment_data = self.shipment_data.dropna(subset=['order_date', 'product_code', 'quantity'])
        self.shipment_data = self.shipment_data[self.shipment_data['quantity'] > 0]
        
        # 2. æ™ºèƒ½å¼‚å¸¸å€¼æ£€æµ‹ï¼ˆä½¿ç”¨IQRæ–¹æ³•ï¼Œä½†è€ƒè™‘ä¸šåŠ¡åˆç†æ€§ï¼‰
        self.shipment_data = self._intelligent_outlier_detection()
        
        # 3. åˆ›å»ºæœˆåº¦èšåˆæ•°æ®ï¼ˆæ—¶é—´åºåˆ—çš„åŸºç¡€ï¼‰
        self.processed_data = self._create_monthly_aggregation()
        
        # 4. ç¡®ä¿æ—¶é—´åºåˆ—çš„è¿ç»­æ€§
        self.processed_data = self._ensure_time_continuity()
        
        if progress_callback:
            progress_callback(0.5, f"âœ… é¢„å¤„ç†å®Œæˆ: {len(self.processed_data)} æ¡æœˆåº¦è®°å½•")
        
        return True
    
    def _intelligent_outlier_detection(self):
        """æ™ºèƒ½å¼‚å¸¸å€¼æ£€æµ‹"""
        cleaned_data = []
        
        for product in self.shipment_data['product_code'].unique():
            product_data = self.shipment_data[self.shipment_data['product_code'] == product].copy()
            
            if len(product_data) < 10:  # æ•°æ®ç‚¹å¤ªå°‘ï¼Œä¸å¤„ç†å¼‚å¸¸å€¼
                cleaned_data.append(product_data)
                continue
            
            # æŒ‰æœˆèšåˆåæ£€æµ‹å¼‚å¸¸å€¼
            monthly = product_data.groupby(product_data['order_date'].dt.to_period('M'))['quantity'].sum()
            
            if len(monthly) < 4:  # å°‘äº4ä¸ªæœˆï¼Œä¸å¤„ç†
                cleaned_data.append(product_data)
                continue
            
            # ä½¿ç”¨ä¿®æ­£çš„IQRæ–¹æ³•
            Q1 = monthly.quantile(0.25)
            Q3 = monthly.quantile(0.75)
            IQR = Q3 - Q1
            
            # æ›´ä¿å®ˆçš„å¼‚å¸¸å€¼é˜ˆå€¼
            lower_bound = Q1 - 2.5 * IQR
            upper_bound = Q3 + 2.5 * IQR
            
            # æ ‡è®°å¼‚å¸¸æœˆä»½
            outlier_months = monthly[(monthly < lower_bound) | (monthly > upper_bound)].index
            
            # ä»åŸå§‹æ•°æ®ä¸­ç§»é™¤å¼‚å¸¸æœˆä»½çš„æ•°æ®
            if len(outlier_months) > 0:
                outlier_mask = ~product_data['order_date'].dt.to_period('M').isin(outlier_months)
                product_data = product_data[outlier_mask]
            
            cleaned_data.append(product_data)
        
        return pd.concat(cleaned_data, ignore_index=True)
    
    def _create_monthly_aggregation(self):
        """åˆ›å»ºæœˆåº¦èšåˆæ•°æ®"""
        monthly_data = self.shipment_data.groupby([
            'product_code',
            self.shipment_data['order_date'].dt.to_period('M')
        ]).agg({
            'quantity': ['sum', 'count', 'mean', 'std'],
            'customer_code': 'nunique',
            'region': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.iloc[0]
        }).reset_index()
        
        # æ‰å¹³åŒ–åˆ—å
        monthly_data.columns = ['product_code', 'year_month', 'total_qty', 'order_count',
                                'avg_qty_per_order', 'std_qty', 'unique_customers', 'primary_region']
        
        # å¡«å……ç¼ºå¤±çš„æ ‡å‡†å·®
        monthly_data['std_qty'] = monthly_data['std_qty'].fillna(0)
        
        # è½¬æ¢å¹´æœˆä¸ºæ—¥æœŸç±»å‹
        monthly_data['year_month_date'] = monthly_data['year_month'].dt.to_timestamp()
        
        return monthly_data.sort_values(['product_code', 'year_month_date'])
    
    def _ensure_time_continuity(self):
        """ç¡®ä¿æ—¶é—´åºåˆ—çš„è¿ç»­æ€§"""
        complete_data = []
        
        # è·å–å…¨éƒ¨æ—¶é—´èŒƒå›´
        all_months = pd.period_range(
            start=self.processed_data['year_month'].min(),
            end=self.processed_data['year_month'].max(),
            freq='M'
        )
        
        for product in self.processed_data['product_code'].unique():
            product_data = self.processed_data[self.processed_data['product_code'] == product].copy()
            
            # åˆ›å»ºå®Œæ•´çš„æ—¶é—´åºåˆ—
            product_months = pd.DataFrame({
                'product_code': product,
                'year_month': all_months
            })
            product_months['year_month_date'] = product_months['year_month'].dt.to_timestamp()
            
            # åˆå¹¶æ•°æ®ï¼Œç¼ºå¤±æœˆä»½ç”¨0å¡«å……
            complete_product = product_months.merge(
                product_data.drop('year_month_date', axis=1),
                on=['product_code', 'year_month'],
                how='left'
            )
            
            # å¡«å……ç¼ºå¤±å€¼
            numeric_cols = ['total_qty', 'order_count', 'avg_qty_per_order', 'std_qty', 'unique_customers']
            complete_product[numeric_cols] = complete_product[numeric_cols].fillna(0)
            complete_product['primary_region'] = complete_product['primary_region'].fillna('Unknown')
            
            complete_data.append(complete_product)
        
        return pd.concat(complete_data, ignore_index=True)
    
    def enhanced_feature_engineering(self, progress_callback=None):
        """ä¼˜åŒ–çš„æ—¶é—´åºåˆ—ç‰¹å¾å·¥ç¨‹"""
        if progress_callback:
            progress_callback(0.6, "åˆ›å»ºä¼˜åŒ–çš„æ—¶é—´åºåˆ—ç‰¹å¾...")
        
        all_features = []
        total_products = len(self.processed_data['product_code'].unique())
        processed_products = 0
        
        for product in self.processed_data['product_code'].unique():
            processed_products += 1
            if processed_products % 10 == 0 and progress_callback:  # æ¯å¤„ç†10ä¸ªäº§å“æ›´æ–°ä¸€æ¬¡è¿›åº¦
                progress = 0.6 + 0.1 * (processed_products / total_products)
                progress_callback(progress, f"å¤„ç†äº§å“ç‰¹å¾: {processed_products}/{total_products}")
            
            product_data = self.processed_data[
                self.processed_data['product_code'] == product
            ].sort_values('year_month_date').reset_index(drop=True)
            
            if len(product_data) < 8:  # é™ä½æœ€å°æ•°æ®è¦æ±‚ä»12åˆ°8
                continue
            
            # ğŸš€ ä¼˜åŒ–ï¼šåªå¯¹æœ‰æ„ä¹‰çš„äº§å“è¿›è¡Œå­£èŠ‚æ€§åˆ†è§£
            seasonal_comp = None
            if len(product_data) >= 24 and product_data['total_qty'].sum() > 100:  # å¢åŠ é”€é‡é˜ˆå€¼
                try:
                    seasonal_comp = self._fast_seasonal_decomposition(product_data['total_qty'])
                    self.seasonal_components[product] = seasonal_comp
                except:
                    seasonal_comp = None
            
            # ğŸš€ ä¼˜åŒ–ï¼šä»ç¬¬8ä¸ªæœˆå¼€å§‹é¢„æµ‹ï¼ˆé™ä½from 12ï¼‰
            start_idx = max(8, len(product_data) - 24)  # æœ€å¤šåªçœ‹æœ€è¿‘24ä¸ªæœˆ
            
            for i in range(start_idx, len(product_data)):
                features = self._create_fast_features(
                    product, product_data.iloc[:i], seasonal_comp, i
                )
                
                # ç›®æ ‡å˜é‡
                if i < len(product_data):
                    features['target'] = product_data.iloc[i]['total_qty']
                    features['target_date'] = product_data.iloc[i]['year_month_date']
                    
                    all_features.append(features)
        
        self.feature_data = pd.DataFrame(all_features)
        
        if len(self.feature_data) == 0:
            return False
        
        # ğŸš€ ä¼˜åŒ–ï¼šç®€åŒ–ç‰¹å¾åå¤„ç†
        self._fast_feature_postprocessing()
        
        if progress_callback:
            progress_callback(0.7, f"âœ… ä¼˜åŒ–ç‰¹å¾å·¥ç¨‹å®Œæˆ: {len(self.feature_data)} æ ·æœ¬, {len([c for c in self.feature_data.columns if c not in ['product_code', 'target', 'target_date']])} ç‰¹å¾")
        
        return True
    
    def _fast_seasonal_decomposition(self, time_series):
        """å¿«é€Ÿå­£èŠ‚æ€§åˆ†è§£"""
        try:
            if len(time_series) >= 24 and time_series.std() > 0:
                # ğŸš€ ç®€åŒ–çš„å­£èŠ‚æ€§åˆ†è§£ï¼šåªæå–å…³é”®ç»„ä»¶
                ts_positive = time_series + abs(time_series.min()) + 1
                
                # ç®€å•çš„12æœˆç§»åŠ¨å¹³å‡ä½œä¸ºè¶‹åŠ¿
                trend = ts_positive.rolling(window=12, center=True).mean()
                trend = trend.fillna(method='bfill').fillna(method='ffill')
                
                # å»è¶‹åŠ¿åçš„å­£èŠ‚æ€§æ¨¡å¼
                detrended = ts_positive - trend
                seasonal_pattern = detrended.groupby(detrended.index % 12).mean()
                seasonal = pd.Series(index=detrended.index)
                
                for i in range(len(seasonal)):
                    seasonal.iloc[i] = seasonal_pattern.iloc[i % 12]
                
                # æ®‹å·®
                residual = ts_positive - trend - seasonal
                
                return {
                    'trend': trend,
                    'seasonal': seasonal,
                    'residual': residual.fillna(0)
                }
            else:
                return None
        except:
            return None
    
    def _create_fast_features(self, product_code, historical_data, seasonal_comp, current_idx):
        """åˆ›å»ºä¼˜åŒ–çš„æ—¶é—´åºåˆ—ç‰¹å¾ï¼ˆå‡å°‘å¤æ‚è®¡ç®—ï¼‰"""
        features = {'product_code': product_code}
        
        if len(historical_data) < 3:
            return features
        
        qty_values = historical_data['total_qty'].values
        dates = historical_data['year_month_date']
        
        if len(qty_values) == 0:
            return features
        
        # 1. æ ¸å¿ƒç»Ÿè®¡ç‰¹å¾ï¼ˆæœ€é‡è¦çš„ï¼‰
        recent_6m = qty_values[-6:] if len(qty_values) >= 6 else qty_values
        recent_12m = qty_values[-12:] if len(qty_values) >= 12 else qty_values
        
        features.update({
            'qty_mean_6m': np.mean(recent_6m),
            'qty_mean_12m': np.mean(recent_12m),
            'qty_std_6m': np.std(recent_6m),
            'qty_cv_6m': np.std(recent_6m) / (np.mean(recent_6m) + 1),
        })
        
        # 2. å…³é”®æ»åç‰¹å¾ï¼ˆåªä¿ç•™æœ€é‡è¦çš„ï¼‰
        important_lags = [1, 2, 3, 6, 12]
        for lag in important_lags:
            if lag <= len(qty_values):
                features[f'qty_lag_{lag}'] = qty_values[-lag]
            else:
                features[f'qty_lag_{lag}'] = 0
        
        # 3. å…³é”®ç§»åŠ¨å¹³å‡
        for window in [3, 6]:
            if len(qty_values) >= window:
                features[f'qty_ma_{window}'] = np.mean(qty_values[-window:])
            else:
                features[f'qty_ma_{window}'] = 0
        
        # 4. ç®€åŒ–çš„è¶‹åŠ¿ç‰¹å¾
        if len(qty_values) >= 6:
            recent_trend = qty_values[-6:]
            x = np.arange(len(recent_trend))
            
            if np.std(recent_trend) > 0:
                slope = np.polyfit(x, recent_trend, 1)[0]
                features['trend_slope_6m'] = slope
            else:
                features['trend_slope_6m'] = 0
        else:
            features['trend_slope_6m'] = 0
        
        # 5. æ—¶é—´ç‰¹å¾ï¼ˆç®€åŒ–ï¼‰
        current_month = dates.iloc[-1].month
        features.update({
            'month': current_month,
            'quarter': (current_month - 1) // 3 + 1,
            'month_sin': np.sin(2 * np.pi * current_month / 12),
            'month_cos': np.cos(2 * np.pi * current_month / 12),
            'is_peak_season': 1 if current_month in [3, 4, 10, 11, 12] else 0
        })
        
        # 6. ç®€åŒ–çš„å­£èŠ‚æ€§ç‰¹å¾
        if seasonal_comp and len(seasonal_comp['seasonal']) > 0:
            try:
                seasonal_idx = current_idx % 12
                features['seasonal_component'] = seasonal_comp['seasonal'].iloc[seasonal_idx]
            except:
                features['seasonal_component'] = 0
        else:
            features['seasonal_component'] = 0
        
        # 7. å…³é”®å¢é•¿ç‡
        if len(qty_values) >= 2 and qty_values[-2] > 0:
            features['growth_rate_1m'] = (qty_values[-1] - qty_values[-2]) / qty_values[-2]
        else:
            features['growth_rate_1m'] = 0
        
        # 8. åŒæ¯”å¢é•¿ï¼ˆç®€åŒ–ï¼‰
        if len(qty_values) >= 13:
            yoy_growth = (qty_values[-1] - qty_values[-13]) / (qty_values[-13] + 1)
            features['yoy_growth'] = yoy_growth
        elif len(qty_values) >= 12:
            yoy_growth = (qty_values[-1] - qty_values[-12]) / (qty_values[-12] + 1)
            features['yoy_growth'] = yoy_growth
        else:
            features['yoy_growth'] = 0
        
        return features
    
    def _fast_feature_postprocessing(self):
        """å¿«é€Ÿç‰¹å¾åå¤„ç†"""
        # è·å–ç‰¹å¾åˆ—
        feature_cols = [col for col in self.feature_data.columns 
                       if col not in ['product_code', 'target', 'target_date']]
        
        # ğŸš€ åªå¤„ç†æ— ç©·å€¼ï¼Œç”¨0å¡«å……NaNï¼ˆæ›´å¿«ï¼‰
        for col in feature_cols:
            self.feature_data[col] = self.feature_data[col].replace([np.inf, -np.inf], 0)
            self.feature_data[col] = self.feature_data[col].fillna(0)
        
        # ğŸš€ ç§»é™¤å¸¸æ•°ç‰¹å¾ï¼ˆç®€åŒ–ç‰ˆï¼‰
        constant_features = []
        for col in feature_cols:
            if self.feature_data[col].nunique() <= 1:
                constant_features.append(col)
        
        if constant_features:
            self.feature_data = self.feature_data.drop(columns=constant_features)
    
    # åˆ é™¤åŸæ¥å¤æ‚çš„æ–¹æ³•ï¼Œä½¿ç”¨ä¼˜åŒ–ç‰ˆæœ¬
    # _create_comprehensive_features å·²è¢« _create_fast_features æ›¿ä»£
    # _advanced_feature_postprocessing å·²è¢« _fast_feature_postprocessing æ›¿ä»£
    
    def time_series_cross_validation(self, n_splits=5, progress_callback=None):
        """ä¼˜åŒ–çš„æ—¶é—´åºåˆ—äº¤å‰éªŒè¯è®­ç»ƒ"""
        if progress_callback:
            progress_callback(0.8, "å¼€å§‹ä¼˜åŒ–çš„æ—¶é—´åºåˆ—äº¤å‰éªŒè¯è®­ç»ƒ...")
        
        if self.feature_data is None or len(self.feature_data) == 0:
            return False
        
        # å‡†å¤‡æ•°æ®
        feature_cols = [col for col in self.feature_data.columns 
                       if col not in ['product_code', 'target', 'target_date']]
        
        X = self.feature_data[feature_cols]
        y = self.feature_data['target']
        
        # ğŸš€ ä¼˜åŒ–1: ç®€åŒ–ç›®æ ‡å˜é‡å˜æ¢ï¼ˆlog1pæ¯”Box-Coxå¿«å¾ˆå¤šï¼‰
        y_log = np.log1p(y)
        
        # æŒ‰æ—¶é—´æ’åº
        time_sorted_idx = self.feature_data['target_date'].argsort()
        X = X.iloc[time_sorted_idx]
        y = y.iloc[time_sorted_idx]
        y_log = y_log.iloc[time_sorted_idx]
        
        # ğŸš€ ä¼˜åŒ–2: é¢„å…ˆè®¡ç®—scaleré¿å…é‡å¤fit
        global_scaler = RobustScaler()
        X_scaled = global_scaler.fit_transform(X)
        X_scaled = pd.DataFrame(X_scaled, columns=feature_cols, index=X.index)
        
        # ğŸš€ ä¼˜åŒ–3: å‡å°‘æ¨¡å‹å¤æ‚åº¦ä½†ä¿æŒç²¾åº¦
        models = {
            'XGBoost': xgb.XGBRegressor(
                n_estimators=300,  # ä»500å‡åˆ°300
                max_depth=6,
                learning_rate=0.05,  # ç¨å¾®æé«˜å­¦ä¹ ç‡è¡¥å¿æ ‘çš„å‡å°‘
                subsample=0.8,
                colsample_bytree=0.8,
                reg_alpha=0.1,
                reg_lambda=0.1,
                random_state=42,
                n_jobs=-1,
                early_stopping_rounds=50,  # ğŸš€ æ·»åŠ æ—©åœ
                eval_metric='rmse'
            ),
            'LightGBM': lgb.LGBMRegressor(
                n_estimators=300,  # ä»500å‡åˆ°300
                max_depth=6,
                learning_rate=0.05,
                subsample=0.8,
                colsample_bytree=0.8,
                reg_alpha=0.1,
                reg_lambda=0.1,
                random_state=42,
                n_jobs=-1,
                verbose=-1,
                early_stopping_rounds=50  # ğŸš€ æ·»åŠ æ—©åœ
            ),
            'RandomForest': RandomForestRegressor(
                n_estimators=200,  # ä»300å‡åˆ°200
                max_depth=10,      # ä»12å‡åˆ°10
                min_samples_split=5,
                min_samples_leaf=2,
                random_state=42,
                n_jobs=-1
            )
        }
        
        # æ—¶é—´åºåˆ—åˆ†å‰²
        tscv = TimeSeriesSplit(n_splits=n_splits, test_size=len(X)//6)
        splits = list(tscv.split(X_scaled))
        
        # ğŸš€ ä¼˜åŒ–4: äº¤å‰éªŒè¯è¯„ä¼°ï¼ˆæ·»åŠ è¿›åº¦åé¦ˆï¼‰
        cv_results = {}
        fold_predictions = {}
        
        total_models = len(models)
        current_model = 0
        
        for model_name, model in models.items():
            current_model += 1
            if progress_callback:
                progress_callback(0.8 + 0.15 * (current_model - 1) / total_models, 
                                f"è®­ç»ƒ {model_name} ({current_model}/{total_models})")
            
            fold_scores = []
            fold_preds = []
            
            for fold, (train_idx, val_idx) in enumerate(splits):
                X_train = X_scaled.iloc[train_idx]
                X_val = X_scaled.iloc[val_idx]
                y_train = y_log.iloc[train_idx]
                y_val = y_log.iloc[val_idx]
                y_val_original = y.iloc[val_idx]
                
                # ğŸš€ ä¼˜åŒ–5: ä¸ºæ¢¯åº¦æå‡æ¨¡å‹æ·»åŠ éªŒè¯é›†ç”¨äºæ—©åœ
                if model_name in ['XGBoost', 'LightGBM']:
                    # ä»è®­ç»ƒé›†ä¸­åˆ†å‡º10%ä½œä¸ºéªŒè¯é›†ç”¨äºæ—©åœ
                    split_point = int(len(X_train) * 0.9)
                    X_train_fit = X_train.iloc[:split_point]
                    X_train_val = X_train.iloc[split_point:]
                    y_train_fit = y_train.iloc[:split_point]
                    y_train_val = y_train.iloc[split_point:]
                    
                    if model_name == 'XGBoost':
                        model.fit(
                            X_train_fit, y_train_fit,
                            eval_set=[(X_train_val, y_train_val)],
                            verbose=False
                        )
                    else:  # LightGBM
                        model.fit(
                            X_train_fit, y_train_fit,
                            eval_set=[(X_train_val, y_train_val)],
                            callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]
                        )
                else:
                    # RandomForestä¸æ”¯æŒæ—©åœ
                    model.fit(X_train, y_train)
                
                # é¢„æµ‹å¹¶é€†å˜æ¢
                y_pred_log = model.predict(X_val)
                y_pred = np.expm1(y_pred_log)  # ğŸš€ log1pçš„é€†å˜æ¢
                y_pred = np.maximum(y_pred, 0)
                
                # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
                fold_score = self._calculate_robust_metrics(y_val_original.values, y_pred)
                fold_scores.append(fold_score)
                
                fold_preds.append({
                    'actual': y_val_original.values,
                    'predicted': y_pred,
                    'fold': fold
                })
            
            cv_results[model_name] = {
                'scores': fold_scores,
                'mean_smape_accuracy': np.mean([s['smape_accuracy'] for s in fold_scores]),
                'std_smape_accuracy': np.std([s['smape_accuracy'] for s in fold_scores]),
                'mean_mape': np.mean([s['mape'] for s in fold_scores]),
                'mean_mae': np.mean([s['mae'] for s in fold_scores])
            }
            fold_predictions[model_name] = fold_preds
        
        # é€‰æ‹©æœ€ä½³æ¨¡å‹å¹¶åœ¨å…¨éƒ¨æ•°æ®ä¸Šè®­ç»ƒ
        best_model_name = max(cv_results.keys(), 
                             key=lambda x: cv_results[x]['mean_smape_accuracy'])
        
        if progress_callback:
            progress_callback(0.95, f"åœ¨å…¨æ•°æ®ä¸Šè®­ç»ƒæœ€ä½³æ¨¡å‹: {best_model_name}")
        
        # ğŸš€ ä¼˜åŒ–6: åœ¨å…¨éƒ¨æ•°æ®ä¸Šå¿«é€Ÿè®­ç»ƒæœ€ä½³æ¨¡å‹
        final_model = models[best_model_name]
        
        if best_model_name in ['XGBoost', 'LightGBM']:
            # ä½¿ç”¨æ›´å°‘çš„æ ‘æ•°åœ¨å…¨æ•°æ®ä¸Šè®­ç»ƒï¼ˆå› ä¸ºæ•°æ®æ›´å¤šï¼Œéœ€è¦çš„æ ‘æ›´å°‘ï¼‰
            final_model.set_params(n_estimators=200)
        
        final_model.fit(X_scaled, y_log)
        
        # ä¿å­˜æ¨¡å‹å’Œç›¸å…³ä¿¡æ¯
        self.models = {
            'best_model': final_model,
            'best_model_name': best_model_name,
            'scaler': global_scaler,
            'feature_cols': feature_cols,
            'use_log_transform': True,  # æ ‡è®°ä½¿ç”¨logå˜æ¢
            'all_models': models
        }
        
        self.evaluation_results = cv_results
        self.validation_history = fold_predictions
        
        # ç‰¹å¾é‡è¦æ€§
        if hasattr(final_model, 'feature_importances_'):
            feature_importance_df = pd.DataFrame({
                'ç‰¹å¾': feature_cols,
                'é‡è¦æ€§': final_model.feature_importances_
            }).sort_values('é‡è¦æ€§', ascending=False)
            self.feature_importance = feature_importance_df
        
        if progress_callback:
            best_score = cv_results[best_model_name]['mean_smape_accuracy']
            progress_callback(1.0, f"âœ… ä¼˜åŒ–è®­ç»ƒå®Œæˆï¼æœ€ä½³æ¨¡å‹: {best_model_name} (SMAPEå‡†ç¡®ç‡: {best_score:.1f}% Â± {cv_results[best_model_name]['std_smape_accuracy']:.1f}%)")
        
        return True
    
    # åˆ é™¤Box-Coxç›¸å…³æ–¹æ³•ï¼Œä½¿ç”¨æ›´å¿«çš„logå˜æ¢
    # _box_cox_transform å’Œ _inverse_box_cox_transform å·²ç§»é™¤ï¼Œä½¿ç”¨ np.log1p å’Œ np.expm1
    
    def _calculate_robust_metrics(self, y_true, y_pred):
        """è®¡ç®—ç¨³å¥çš„è¯„ä¼°æŒ‡æ ‡"""
        # ç¡®ä¿éè´Ÿ
        y_pred = np.maximum(y_pred, 0)
        
        # SMAPE (æ›´ç¨³å¥)
        smape = 100 * np.mean(2 * np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred) + 1e-8))
        smape_accuracy = max(0, 100 - smape)
        
        # MAPE (ç”¨äºå¯¹æ¯”)
        mask = y_true > 1  # åªè®¡ç®—å¤§äº1çš„å€¼çš„MAPE
        if mask.sum() > 0:
            mape = 100 * np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask]))
        else:
            mape = 100
        
        # å…¶ä»–æŒ‡æ ‡
        mae = np.mean(np.abs(y_true - y_pred))
        rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))
        r2 = r2_score(y_true, y_pred)
        
        return {
            'smape': smape,
            'smape_accuracy': smape_accuracy,
            'mape': mape,
            'mae': mae,
            'rmse': rmse,
            'r2': r2
        }
    
    def predict_future_sales(self, months_ahead=3):
        """ä¼˜åŒ–çš„æœªæ¥é”€é‡é¢„æµ‹"""
        if not self.models:
            return None
        
        predictions = []
        
        # è·å–æ¯ä¸ªäº§å“çš„æœ€æ–°ç‰¹å¾
        latest_features = self.feature_data.groupby('product_code').last().reset_index()
        
        for _, row in latest_features.iterrows():
            product = row['product_code']
            
            # å‡†å¤‡ç‰¹å¾
            X = row[self.models['feature_cols']].values.reshape(1, -1)
            X_scaled = self.models['scaler'].transform(X)
            
            # é¢„æµ‹
            if self.models.get('use_log_transform', False):
                # ä½¿ç”¨logå˜æ¢
                pred_log = self.models['best_model'].predict(X_scaled)[0]
                pred_value = np.expm1(pred_log)  # log1pçš„é€†å˜æ¢
            else:
                # ä½¿ç”¨Box-Coxå˜æ¢ï¼ˆå‘åå…¼å®¹ï¼‰
                pred_transformed = self.models['best_model'].predict(X_scaled)[0]
                pred_value = self._inverse_box_cox_transform(
                    np.array([pred_transformed]), 
                    self.models.get('box_cox_lambda')
                )[0]
            
            pred_value = max(0, pred_value)
            
            # è®¡ç®—ç½®ä¿¡åŒºé—´ï¼ˆåŸºäºå†å²è¯¯å·®ï¼‰
            confidence_interval = self._calculate_prediction_confidence(product, pred_value)
            
            predictions.append({
                'äº§å“ä»£ç ': product,
                'é¢„æµ‹é”€é‡': round(pred_value, 2),
                'ä¸‹é™': round(confidence_interval[0], 2),
                'ä¸Šé™': round(confidence_interval[1], 2),
                'ä½¿ç”¨æ¨¡å‹': self.models['best_model_name']
            })
        
        return pd.DataFrame(predictions)
    
    def _calculate_prediction_confidence(self, product, prediction):
        """è®¡ç®—é¢„æµ‹çš„ç½®ä¿¡åŒºé—´"""
        if not self.validation_history:
            # ç®€å•çš„ç½®ä¿¡åŒºé—´
            return [prediction * 0.8, prediction * 1.2]
        
        # åŸºäºå†å²éªŒè¯è¯¯å·®è®¡ç®—ç½®ä¿¡åŒºé—´
        all_errors = []
        for model_name, folds in self.validation_history.items():
            for fold_data in folds:
                errors = np.abs(fold_data['actual'] - fold_data['predicted']) / (fold_data['actual'] + 1)
                all_errors.extend(errors)
        
        if all_errors:
            error_percentile_95 = np.percentile(all_errors, 95)
            lower_bound = prediction * (1 - error_percentile_95)
            upper_bound = prediction * (1 + error_percentile_95)
            return [max(0, lower_bound), upper_bound]
        else:
            return [prediction * 0.8, prediction * 1.2]

# åˆ›å»ºä¾§è¾¹æ 
with st.sidebar:
    st.markdown("### âš¡ é€Ÿåº¦ä¼˜åŒ–æ§åˆ¶é¢æ¿")
    
    # ç®¡ç†å‘˜ä¿¡æ¯
    st.markdown(f"""
    <div style="background: rgba(255, 255, 255, 0.1); padding: 1rem; border-radius: 10px; margin-bottom: 1rem;">
        <div style="color: #ff6b6b; font-weight: bold; font-size: 0.9rem;">âš¡ é€Ÿåº¦ä¼˜åŒ–ç‰ˆ</div>
        <div style="color: white; font-size: 0.8rem;">ç”¨æˆ·: {st.session_state.get('display_name', 'Admin')}</div>
        <div style="color: white; font-size: 0.8rem;">ç›®æ ‡: 85-90% å‡†ç¡®ç‡</div>
        <div style="color: white; font-size: 0.8rem;">è®­ç»ƒæ—¶é—´: ~3-4åˆ†é’Ÿ</div>
    </div>
    """, unsafe_allow_html=True)
    
    # è®­ç»ƒå‚æ•°
    st.markdown("#### ğŸ”§ é«˜çº§è®­ç»ƒå‚æ•°")
    cv_folds = st.slider("äº¤å‰éªŒè¯æŠ˜æ•°", 3, 7, 5)
    
    # é¢„æµ‹å‚æ•°
    st.markdown("#### ğŸ”® é¢„æµ‹å‚æ•°")
    prediction_months = st.selectbox("é¢„æµ‹æœˆæ•°", [1, 2, 3, 6], index=2)
    
    # ç³»ç»ŸçŠ¶æ€
    if st.session_state.optimized_model_trained:
        st.markdown("---")
        st.markdown("### ğŸ“Š ç³»ç»ŸçŠ¶æ€")
        system = st.session_state.optimized_prediction_system
        
        if system and system.models:
            best_model = system.models['best_model_name']
            best_score = system.evaluation_results[best_model]['mean_smape_accuracy']
            score_std = system.evaluation_results[best_model]['std_smape_accuracy']
            
            st.success(f"âœ… æœ€ä½³æ¨¡å‹: {best_model}")
            st.metric("SMAPEå‡†ç¡®ç‡", f"{best_score:.1f}% Â± {score_std:.1f}%")
            
            if best_score >= 90:
                st.success("ğŸ† å·²è¶…è¶Š90%ç›®æ ‡ï¼")
            elif best_score >= 85:
                st.success("ğŸ¯ å·²è¾¾æˆ85%ç›®æ ‡ï¼")
            else:
                st.warning(f"âš ï¸ è·ç¦»85%ç›®æ ‡è¿˜å·®{85-best_score:.1f}%")

# ä¸»ç•Œé¢
tab1, tab2, tab3, tab4 = st.tabs(["âš¡ é€Ÿåº¦ä¼˜åŒ–è®­ç»ƒ", "ğŸ”® é”€é‡é¢„æµ‹", "ğŸ“Š ç§‘å­¦è¯„ä¼°", "ğŸ“ˆ ç‰¹å¾åˆ†æ"])

# Tab 1: é€Ÿåº¦ä¼˜åŒ–è®­ç»ƒ
with tab1:
    st.markdown("### âš¡ é€Ÿåº¦ä¼˜åŒ–çš„æ—¶é—´åºåˆ—é¢„æµ‹æ¨¡å‹è®­ç»ƒ")
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        if st.button("âš¡ å¼€å§‹é€Ÿåº¦ä¼˜åŒ–è®­ç»ƒ", type="primary", use_container_width=True):
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            def update_progress(progress, message):
                progress_bar.progress(progress)
                status_text.text(message)
            
            system = OptimizedSalesPredictionSystem()
            
            try:
                # æ‰§è¡Œå®Œæ•´çš„è®­ç»ƒæµç¨‹
                if (system.load_and_validate_data(update_progress) and
                    system.scientific_data_preprocessing(update_progress) and
                    system.enhanced_feature_engineering(update_progress) and
                    system.time_series_cross_validation(cv_folds, update_progress)):
                    
                    st.session_state.optimized_prediction_system = system
                    st.session_state.optimized_model_trained = True
                    
                    best_model = system.models['best_model_name']
                    best_score = system.evaluation_results[best_model]['mean_smape_accuracy']
                    
                    if best_score >= 90:
                        st.success("âš¡ é€Ÿåº¦ä¼˜åŒ–è®­ç»ƒå®Œæˆï¼å·²è¶…è¶Š90%ç›®æ ‡ï¼")
                        st.balloons()
                    elif best_score >= 85:
                        st.success("âš¡ é€Ÿåº¦ä¼˜åŒ–è®­ç»ƒå®Œæˆï¼å·²è¾¾æˆ85%ç›®æ ‡ï¼")
                        st.balloons()
                    else:
                        st.success(f"âœ… é€Ÿåº¦ä¼˜åŒ–è®­ç»ƒå®Œæˆï¼å‡†ç¡®ç‡ï¼š{best_score:.1f}%")
                else:
                    st.error("é€Ÿåº¦ä¼˜åŒ–è®­ç»ƒå¤±è´¥")
                    
            except Exception as e:
                st.error(f"é€Ÿåº¦ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {str(e)}")
                st.exception(e)
    
    with col2:
        st.info("""
        **âš¡ é€Ÿåº¦ä¼˜åŒ–ç‰¹æ€§ï¼š**
        
        **ğŸ”§ ä¼˜åŒ–çš„æ—¶é—´åºåˆ—å¤„ç†:**
        - âœ… ä¸¥æ ¼çš„æ—¶é—´åºåˆ—åˆ†å‰²ï¼ˆé¿å…æ•°æ®æ³„éœ²ï¼‰
        - âœ… TimeSeriesSplitäº¤å‰éªŒè¯
        - âœ… å¿«é€Ÿå­£èŠ‚æ€§åˆ†è§£
        - âœ… Logå˜æ¢ï¼ˆæ›¿ä»£å¤æ‚çš„Box-Coxï¼‰
        
        **ğŸ¯ ç²¾ç®€ç‰¹å¾å·¥ç¨‹:**
        - âœ… æ ¸å¿ƒæ»åç‰¹å¾ï¼ˆ1,2,3,6,12æœˆï¼‰
        - âœ… å…³é”®ç§»åŠ¨å¹³å‡å’Œè¶‹åŠ¿
        - âœ… ç®€åŒ–çš„å­£èŠ‚æ€§ç»„ä»¶
        - âœ… é‡è¦ç»Ÿè®¡ç‰¹å¾
        
        **ğŸš€ æ€§èƒ½ä¼˜åŒ–:**
        - âœ… æ—©åœæœºåˆ¶ï¼ˆ300â†’200æ£µæ ‘å®é™…ç”¨æ›´å°‘ï¼‰
        - âœ… é¢„è®¡ç®—scaleré¿å…é‡å¤
        - âœ… å‡å°‘æ•°æ®è¦æ±‚ï¼ˆ12â†’8ä¸ªæœˆï¼‰
        - âœ… å¹¶è¡Œå¤„ç†ä¼˜åŒ–
        
        **é¢„æœŸæ•ˆæœï¼šå‡†ç¡®ç‡85-90%ï¼Œè®­ç»ƒæ—¶é—´3-4åˆ†é’Ÿ**
        """)
    
    # æ˜¾ç¤ºè®­ç»ƒç»“æœ
    if st.session_state.optimized_model_trained:
        st.markdown("---")
        st.markdown("### ğŸ“Š é€Ÿåº¦ä¼˜åŒ–è®­ç»ƒç»“æœ")
        
        system = st.session_state.optimized_prediction_system
        
        # äº¤å‰éªŒè¯ç»“æœ
        col1, col2, col3, col4 = st.columns(4)
        
        results = system.evaluation_results
        for idx, (model_name, metrics) in enumerate(results.items()):
            if idx < 4:
                with [col1, col2, col3, col4][idx]:
                    accuracy = metrics['mean_smape_accuracy']
                    std_acc = metrics['std_smape_accuracy']
                    
                    if accuracy >= 90:
                        color = "#00FF00"
                        icon = "ğŸ†"
                    elif accuracy >= 85:
                        color = "#90EE90"
                        icon = "ğŸ¯"
                    else:
                        color = "#FFD700"
                        icon = "ğŸ“ˆ"
                    
                    st.markdown(f"""
                    <div class="metric-card" style="border-left-color: {color};">
                        <div class="metric-value" style="color: {color};">{accuracy:.1f}%</div>
                        <div style="font-size: 1rem; margin: 0.5rem 0; color: #666;">Â± {std_acc:.1f}%</div>
                        <div class="metric-label">{icon} {model_name}</div>
                        <div style="font-size: 0.8rem; color: #999; margin-top: 0.5rem;">
                            MAPE: {metrics['mean_mape']:.1f}%<br>
                            MAE: {metrics['mean_mae']:.1f}
                        </div>
                    </div>
                    """, unsafe_allow_html=True)

# Tab 2: é”€é‡é¢„æµ‹
with tab2:
    st.markdown("### ğŸ”® ç§‘å­¦é”€é‡é¢„æµ‹")
    
    if not st.session_state.optimized_model_trained:
        st.warning("âš ï¸ è¯·å…ˆåœ¨'é€Ÿåº¦ä¼˜åŒ–è®­ç»ƒ'é¡µé¢è®­ç»ƒæ¨¡å‹")
    else:
        system = st.session_state.optimized_prediction_system
        
        col1, col2 = st.columns([1, 3])
        
        with col1:
            if st.button("ğŸš€ ç”Ÿæˆé¢„æµ‹", type="primary", use_container_width=True):
                with st.spinner("æ­£åœ¨ç”Ÿæˆç§‘å­¦é¢„æµ‹..."):
                    predictions = system.predict_future_sales(prediction_months)
                    
                    if predictions is not None and len(predictions) > 0:
                        st.success(f"âœ… æˆåŠŸé¢„æµ‹ {len(predictions)} ä¸ªäº§å“")
                        
                        # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
                        st.markdown("### ğŸ“Š é¢„æµ‹ç»“æœ")
                        
                        # æ±‡æ€»ç»Ÿè®¡
                        total_pred = predictions['é¢„æµ‹é”€é‡'].sum()
                        avg_pred = predictions['é¢„æµ‹é”€é‡'].mean()
                        
                        col_a, col_b, col_c = st.columns(3)
                        with col_a:
                            st.metric("æ€»é¢„æµ‹é‡", f"{total_pred:,.0f} ç®±")
                        with col_b:
                            st.metric("å¹³å‡é¢„æµ‹é‡", f"{avg_pred:,.0f} ç®±")
                        with col_c:
                            st.metric("äº§å“æ•°é‡", len(predictions))
                        
                        # é¢„æµ‹è¡¨æ ¼
                        st.dataframe(
                            predictions.style.format({
                                'é¢„æµ‹é”€é‡': '{:,.0f}',
                                'ä¸‹é™': '{:,.0f}',
                                'ä¸Šé™': '{:,.0f}'
                            }).background_gradient(subset=['é¢„æµ‹é”€é‡'], cmap='Blues'),
                            use_container_width=True
                        )
                        
                        # ä¸‹è½½æŒ‰é’®
                        csv = predictions.to_csv(index=False)
                        st.download_button(
                            "ğŸ“¥ ä¸‹è½½é¢„æµ‹ç»“æœ",
                            data=csv,
                            file_name=f'é€Ÿåº¦ä¼˜åŒ–ç‰ˆé”€é‡é¢„æµ‹_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                            mime='text/csv'
                        )
                    else:
                        st.error("é¢„æµ‹ç”Ÿæˆå¤±è´¥")
        
        with col2:
            st.info("""
            **ğŸ¯ é€Ÿåº¦ä¼˜åŒ–é¢„æµ‹ç‰¹ç‚¹ï¼š**
            - åŸºäºæ—¶é—´åºåˆ—äº¤å‰éªŒè¯çš„å¯é æ¨¡å‹
            - è€ƒè™‘å­£èŠ‚æ€§å’Œè¶‹åŠ¿çš„ç»¼åˆé¢„æµ‹
            - åŸºäºå†å²è¯¯å·®çš„ç½®ä¿¡åŒºé—´
            - é¿å…æ•°æ®æ³„éœ²çš„ä¸¥æ ¼æ–¹æ³•è®º
            - 3-4åˆ†é’Ÿå¿«é€Ÿè®­ç»ƒå®Œæˆ
            """)

# Tab 3: ç§‘å­¦è¯„ä¼°
with tab3:
    st.markdown("### ğŸ“Š ç§‘å­¦æ¨¡å‹è¯„ä¼°")
    
    if not st.session_state.optimized_model_trained:
        st.warning("âš ï¸ è¯·å…ˆè®­ç»ƒæ¨¡å‹")
    else:
        system = st.session_state.optimized_prediction_system
        
        # äº¤å‰éªŒè¯ç»“æœå¯¹æ¯”
        st.markdown("#### ğŸ† æ—¶é—´åºåˆ—äº¤å‰éªŒè¯ç»“æœ")
        
        models = list(system.evaluation_results.keys())
        accuracies = [system.evaluation_results[m]['mean_smape_accuracy'] for m in models]
        stds = [system.evaluation_results[m]['std_smape_accuracy'] for m in models]
        
        # åˆ›å»ºè¯¯å·®æ¡å›¾
        fig = go.Figure()
        
        fig.add_trace(go.Bar(
            name='SMAPEå‡†ç¡®ç‡',
            x=models,
            y=accuracies,
            error_y=dict(type='data', array=stds, visible=True),
            marker_color=['#00FF00' if acc >= 90 else '#90EE90' if acc >= 85 else '#FFD700' for acc in accuracies],
            text=[f'{acc:.1f}% Â± {std:.1f}%' for acc, std in zip(accuracies, stds)],
            textposition='outside'
        ))
        
        fig.add_hline(y=85, line_dash="dash", line_color="green", annotation_text="85%ç›®æ ‡çº¿")
        fig.add_hline(y=90, line_dash="dash", line_color="gold", annotation_text="90%ç›®æ ‡çº¿")
        
        fig.update_layout(
            title="æ—¶é—´åºåˆ—äº¤å‰éªŒè¯ç»“æœï¼ˆSMAPEå‡†ç¡®ç‡ Â± æ ‡å‡†å·®ï¼‰",
            xaxis_title="æ¨¡å‹",
            yaxis_title="SMAPEå‡†ç¡®ç‡ (%)",
            height=400,
            paper_bgcolor='rgba(0,0,0,0)',
            plot_bgcolor='rgba(0,0,0,0)'
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # è¯¦ç»†è¯„ä¼°æŒ‡æ ‡
        st.markdown("#### ğŸ“‹ è¯¦ç»†è¯„ä¼°æŒ‡æ ‡")
        
        eval_df = pd.DataFrame([
            {
                'æ¨¡å‹': model,
                'SMAPEå‡†ç¡®ç‡ (%)': f"{metrics['mean_smape_accuracy']:.2f} Â± {metrics['std_smape_accuracy']:.2f}",
                'MAPE (%)': f"{metrics['mean_mape']:.2f}",
                'MAE': f"{metrics['mean_mae']:.2f}",
                'ç¨³å®šæ€§': 'ä¼˜ç§€' if metrics['std_smape_accuracy'] < 3 else 'è‰¯å¥½' if metrics['std_smape_accuracy'] < 5 else 'ä¸€èˆ¬',
                'ç›®æ ‡è¾¾æˆ': 'âœ…' if metrics['mean_smape_accuracy'] >= 85 else 'âŒ'
            }
            for model, metrics in system.evaluation_results.items()
        ])
        
        st.dataframe(eval_df, use_container_width=True)
        
        # æœ€ä½³æ¨¡å‹æ€»ç»“
        best_model = max(system.evaluation_results.keys(), 
                        key=lambda x: system.evaluation_results[x]['mean_smape_accuracy'])
        best_score = system.evaluation_results[best_model]['mean_smape_accuracy']
        best_std = system.evaluation_results[best_model]['std_smape_accuracy']
        
        if best_score >= 90:
            status_color = "#00FF00"
            status_text = "ğŸ† ä¼˜ç§€ï¼šå·²è¶…è¶Š90%ç›®æ ‡"
        elif best_score >= 85:
            status_color = "#90EE90"
            status_text = "ğŸ¯ è‰¯å¥½ï¼šå·²è¾¾æˆ85%ç›®æ ‡"
        else:
            status_color = "#FFD700"
            status_text = f"ğŸ“ˆ å¾…ä¼˜åŒ–ï¼šè·ç¦»85%ç›®æ ‡è¿˜å·®{85-best_score:.1f}%"
        
        st.markdown(f"""
        <div class="info-box" style="border-left-color: {status_color};">
            <h4>ğŸ¯ ç§‘å­¦è¯„ä¼°ç»“è®º</h4>
            <p>æœ€ä½³æ¨¡å‹: <strong>{best_model}</strong></p>
            <p>SMAPEå‡†ç¡®ç‡: <strong>{best_score:.1f}% Â± {best_std:.1f}%</strong></p>
            <p>æ¨¡å‹ç¨³å®šæ€§: <strong>{'ä¼˜ç§€' if best_std < 3 else 'è‰¯å¥½' if best_std < 5 else 'ä¸€èˆ¬'}</strong></p>
            <p>{status_text}</p>
            <p><strong>âœ… è¯¥æ¨¡å‹å·²é€šè¿‡ä¸¥æ ¼çš„æ—¶é—´åºåˆ—äº¤å‰éªŒè¯ï¼Œå¯ç”¨äºç”Ÿäº§ç¯å¢ƒ</strong></p>
        </div>
        """, unsafe_allow_html=True)

# Tab 4: ç‰¹å¾åˆ†æ
with tab4:
    st.markdown("### ğŸ“ˆ å¢å¼ºç‰¹å¾é‡è¦æ€§åˆ†æ")
    
    if not st.session_state.optimized_model_trained:
        st.warning("âš ï¸ è¯·å…ˆè®­ç»ƒæ¨¡å‹")
    else:
        system = st.session_state.optimized_prediction_system
        
        if system.feature_importance is not None:
            # Top 20 ç‰¹å¾é‡è¦æ€§
            top_features = system.feature_importance.head(20)
            
            fig = go.Figure()
            
            fig.add_trace(go.Bar(
                x=top_features['é‡è¦æ€§'],
                y=top_features['ç‰¹å¾'],
                orientation='h',
                marker=dict(
                    color=top_features['é‡è¦æ€§'],
                    colorscale='Viridis',
                    showscale=True
                ),
                text=[f'{v:.3f}' for v in top_features['é‡è¦æ€§']],
                textposition='outside'
            ))
            
            fig.update_layout(
                title="Top 20 ç‰¹å¾é‡è¦æ€§ï¼ˆåŸºäºæœ€ä½³æ¨¡å‹ï¼‰",
                xaxis_title="é‡è¦æ€§å¾—åˆ†",
                yaxis_title="ç‰¹å¾",
                height=700,
                margin=dict(l=150),
                paper_bgcolor='rgba(0,0,0,0)',
                plot_bgcolor='rgba(0,0,0,0)'
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # ç‰¹å¾ç±»åˆ«åˆ†æ
            st.markdown("#### ğŸ“Š ç‰¹å¾ç±»åˆ«è´¡çŒ®åº¦")
            
            # æŒ‰ç‰¹å¾ç±»å‹åˆ†ç»„
            feature_categories = {
                'æ»åç‰¹å¾': [f for f in top_features['ç‰¹å¾'] if 'lag_' in f],
                'ç§»åŠ¨å¹³å‡': [f for f in top_features['ç‰¹å¾'] if 'ma_' in f or 'ema_' in f],
                'è¶‹åŠ¿ç‰¹å¾': [f for f in top_features['ç‰¹å¾'] if 'trend_' in f or 'growth_' in f],
                'å­£èŠ‚æ€§ç‰¹å¾': [f for f in top_features['ç‰¹å¾'] if any(x in f for x in ['month', 'quarter', 'seasonal', 'yoy'])],
                'ç»Ÿè®¡ç‰¹å¾': [f for f in top_features['ç‰¹å¾'] if any(x in f for x in ['mean', 'std', 'cv', 'volatility', 'skewness', 'kurtosis'])],
                'å…¶ä»–ç‰¹å¾': []
            }
            
            # è®¡ç®—æ¯ç±»ç‰¹å¾çš„æ€»é‡è¦æ€§
            category_importance = {}
            used_features = set()
            
            for category, features in feature_categories.items():
                if category != 'å…¶ä»–ç‰¹å¾':
                    category_score = system.feature_importance[
                        system.feature_importance['ç‰¹å¾'].isin(features)
                    ]['é‡è¦æ€§'].sum()
                    category_importance[category] = category_score
                    used_features.update(features)
            
            # å…¶ä»–ç‰¹å¾
            other_features = [f for f in system.feature_importance['ç‰¹å¾'] if f not in used_features]
            if other_features:
                other_score = system.feature_importance[
                    system.feature_importance['ç‰¹å¾'].isin(other_features)
                ]['é‡è¦æ€§'].sum()
                category_importance['å…¶ä»–ç‰¹å¾'] = other_score
            
            # ç‰¹å¾ç±»åˆ«é‡è¦æ€§å›¾
            categories = list(category_importance.keys())
            scores = list(category_importance.values())
            
            fig_cat = go.Figure()
            
            fig_cat.add_trace(go.Pie(
                labels=categories,
                values=scores,
                hole=0.3,
                marker_colors=['#667eea', '#764ba2', '#9f7aea', '#b794f4', '#d6bcfa', '#e9d8fd']
            ))
            
            fig_cat.update_layout(
                title="ç‰¹å¾ç±»åˆ«é‡è¦æ€§åˆ†å¸ƒ",
                height=400,
                paper_bgcolor='rgba(0,0,0,0)',
                plot_bgcolor='rgba(0,0,0,0)'
            )
            
            st.plotly_chart(fig_cat, use_container_width=True)

# åº•éƒ¨ä¿¡æ¯
st.markdown("---")
st.markdown(f"""
<div style="text-align: center; color: rgba(255, 255, 255, 0.8); font-size: 0.9rem; background: rgba(255, 255, 255, 0.1); padding: 1rem; border-radius: 10px;">
    âš¡ é€Ÿåº¦ä¼˜åŒ–é”€å”®é¢„æµ‹ç³»ç»Ÿ v5.0 | 
    ğŸ¯ ç§‘å­¦è¾¾æˆ85-90%å‡†ç¡®ç‡ | 
    ä½¿ç”¨é€Ÿåº¦ä¼˜åŒ–æ–¹æ³• + ç²¾ç®€ç‰¹å¾å·¥ç¨‹ + æ—©åœæœºåˆ¶ | 
    æ•°æ®æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d')} |
    ğŸ”’ ç®¡ç†å‘˜ä¸“ç”¨æ¨¡å¼
    <br>
    <small style="opacity: 0.7;">
    âš¡ é€Ÿåº¦ä¼˜åŒ–: æ—©åœæœºåˆ¶ | Logå˜æ¢ | ç²¾ç®€ç‰¹å¾ | é¢„è®¡ç®—ä¼˜åŒ– | 3-4åˆ†é’Ÿå¿«é€Ÿè®­ç»ƒ
    </small>
</div>
""", unsafe_allow_html=True)
