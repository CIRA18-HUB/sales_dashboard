# pages/inventory_page.py - åº“å­˜åˆ†æé¡µé¢
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import os
import math
import glob
import warnings
import logging
from pathlib import Path

# é…ç½®æ—¥å¿—ç³»ç»Ÿ
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger('åº“å­˜åˆ†æ')

warnings.filterwarnings('ignore')

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="åº“å­˜åˆ†æ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼ - ä¸é¢„æµ‹ä¸è®¡åˆ’.pyä¿æŒä¸€è‡´
st.markdown("""
<style>
    .main-header {
        font-size: 2rem;
        color: #1f3867;
        text-align: center;
        margin-bottom: 1rem;
    }
    .card-header {
        font-size: 1.2rem;
        font-weight: bold;
        color: #444444;
    }
    .card-value {
        font-size: 1.8rem;
        font-weight: bold;
        color: #1f3867;
    }
    .metric-card {
        background-color: white;
        border-radius: 0.5rem;
        padding: 1rem;
        box-shadow: 0 0.15rem 1.75rem 0 rgba(58, 59, 69, 0.15);
        margin-bottom: 1rem;
        position: relative;
    }
    .view-details-btn {
        position: absolute;
        bottom: 5px;
        right: 10px;
        background-color: #1f3867;
        color: white;
        border: none;
        border-radius: 3px;
        padding: 2px 8px;
        font-size: 0.7rem;
        cursor: pointer;
    }
    .view-details-btn:hover {
        background-color: #4c78a8;
    }
    .card-text {
        font-size: 0.9rem;
        color: #6c757d;
    }
    .alert-box {
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
    }
    .alert-success {
        background-color: rgba(76, 175, 80, 0.1);
        border-left: 0.5rem solid #4CAF50;
    }
    .alert-warning {
        background-color: rgba(255, 152, 0, 0.1);
        border-left: 0.5rem solid #FF9800;
    }
    .alert-danger {
        background-color: rgba(244, 67, 54, 0.1);
        border-left: 0.5rem solid #F44336;
    }
    .sub-header {
        font-size: 1.5rem;
        font-weight: bold;
        color: #1f3867;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
    .chart-explanation {
        background-color: rgba(76, 175, 80, 0.1);
        padding: 0.9rem;
        border-radius: 0.5rem;
        margin: 0.8rem 0;
        border-left: 0.5rem solid #4CAF50;
    }
    .low-accuracy {
        border: 2px solid #F44336;
        box-shadow: 0 0 8px #F44336;
    }
    .time-dim-note {
        font-size: 0.85rem;
        color: #6c757d;
        font-style: italic;
        margin-top: 0.3rem;
        margin-bottom: 0.7rem;
    }
    .empty-chart-message {
        height: 300px;
        display: flex;
        align-items: center;
        justify-content: center;
        flex-direction: column;
        background-color: rgba(0,0,0,0.03);
        border-radius: 10px;
        margin: 1rem 0;
        padding: 20px;
    }
    .empty-chart-message h3 {
        color: #6c757d;
        margin-bottom: 10px;
    }
    .empty-chart-message p {
        color: #6c757d;
        text-align: center;
        max-width: 80%;
    }
    .data-search-info {
        font-size: 0.85rem;
        background-color: #f8f9fa;
        padding: 0.5rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
        color: #6c757d;
    }
    .file-info {
        margin-top: 0.25rem;
        font-size: 0.8rem;
    }
    .error-box {
        background-color: rgba(244, 67, 54, 0.05);
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
        border-left: 0.5rem solid #F44336;
    }
    .success-box {
        background-color: rgba(76, 175, 80, 0.05);
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
        border-left: 0.5rem solid #4CAF50;
    }
</style>
""", unsafe_allow_html=True)

# é¡µé¢æ ‡é¢˜
st.markdown('<div class="main-header">ğŸ“¦ åº“å­˜åˆ†æ</div>', unsafe_allow_html=True)

# å…¨å±€å¸¸é‡å®šä¹‰
COLORS = {
    'primary': '#1f3867',
    'secondary': '#4c78a8',
    'success': '#4CAF50',
    'warning': '#FF9800',
    'danger': '#F44336',
    'gray': '#6c757d'
}

INVENTORY_RISK_COLORS = {
    'æé«˜é£é™©': '#8B0000',  # æ·±çº¢è‰²
    'é«˜é£é™©': '#FF0000',  # çº¢è‰²
    'ä¸­é£é™©': '#FFA500',  # æ©™è‰²
    'ä½é£é™©': '#4CAF50',  # ç»¿è‰²
    'æä½é£é™©': '#2196F3'  # è“è‰²
}

# åº“å­˜é…ç½®å‚æ•°
INVENTORY_CONFIG = {
    'high_stock_days': 90,  # åº“å­˜è¶…è¿‡90å¤©è§†ä¸ºé«˜é£é™©
    'medium_stock_days': 60,  # åº“å­˜è¶…è¿‡60å¤©è§†ä¸ºä¸­é£é™©
    'low_stock_days': 30,  # åº“å­˜è¶…è¿‡30å¤©è§†ä¸ºä½é£é™©
    'min_daily_sales': 0.1,  # æœ€å°æ—¥å‡é”€é‡é˜ˆå€¼
    'annual_capital_cost': 0.12,  # å¹´åŒ–èµ„é‡‘æˆæœ¬ç‡ (12%)
    'stagnant_days_threshold': 60  # è¶…è¿‡60å¤©çš„æ‰¹æ¬¡è§†ä¸ºå‘†æ»åº“å­˜
}


# ==================== 1. æ ¼å¼åŒ–å‡½æ•° ====================
def format_currency(value):
    """æ ¼å¼åŒ–è´§å¸"""
    return f"Â¥{value:,.2f}" if pd.notna(value) else "Â¥0.00"


def format_percentage(value):
    """æ ¼å¼åŒ–ç™¾åˆ†æ¯”"""
    return f"{value:.1f}%" if pd.notna(value) else "0.0%"


def format_number(value):
    """æ ¼å¼åŒ–æ•°é‡"""
    return f"{int(value):,}" if pd.notna(value) else "0"


def format_days(value):
    """æ ¼å¼åŒ–å¤©æ•°"""
    if pd.isna(value) or value == float('inf'):
        return "âˆ"
    return f"{value:.1f}å¤©"


# ==================== 2. åº“å­˜æ•°æ®åŠ è½½ä¸å¤„ç†å‡½æ•° - å®Œå…¨é‡å†™ ====================
def find_data_files(file_patterns, search_dirs=None):
    """æŸ¥æ‰¾åŒ¹é…çš„æ•°æ®æ–‡ä»¶

    Args:
        file_patterns: æ–‡ä»¶åæ¨¡å¼åˆ—è¡¨ï¼Œå¦‚['*åº“å­˜*.xlsx', '*å‡ºè´§*.xlsx']
        search_dirs: è¦æœç´¢çš„ç›®å½•åˆ—è¡¨ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•å’Œç›¸å…³å­ç›®å½•

    Returns:
        dict: é”®ä¸ºæ¨¡å¼ï¼Œå€¼ä¸ºæ‰¾åˆ°çš„ç¬¬ä¸€ä¸ªåŒ¹é…æ–‡ä»¶è·¯å¾„
    """
    if search_dirs is None:
        # é»˜è®¤æœç´¢ç›®å½•ï¼šå½“å‰ç›®å½•ã€pagesç›®å½•ã€dataç›®å½•å’Œä¸Šçº§ç›®å½•
        base_dir = os.getcwd()
        search_dirs = [
            base_dir,
            os.path.join(base_dir, "pages"),
            os.path.join(base_dir, "data"),
            os.path.dirname(base_dir)
        ]

    found_files = {}

    # è®°å½•æœç´¢è¿‡çš„æ–‡ä»¶æ€»æ•°
    total_files_searched = 0

    for pattern in file_patterns:
        found_files[pattern] = None

        for directory in search_dirs:
            if not os.path.exists(directory):
                continue

            # åœ¨æ¯ä¸ªç›®å½•ä¸­æœç´¢
            search_path = os.path.join(directory, pattern)
            matching_files = glob.glob(search_path)
            total_files_searched += len(matching_files)

            # å¦‚æœæ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶ï¼Œé€‰æ‹©æœ€æ–°çš„ä¸€ä¸ª
            if matching_files:
                newest_file = max(matching_files, key=os.path.getmtime)
                found_files[pattern] = newest_file
                break

    # è®°å½•æ‰¾åˆ°äº†å¤šå°‘æ–‡ä»¶
    found_count = sum(1 for f in found_files.values() if f is not None)

    logger.info(f"æœç´¢äº†{len(search_dirs)}ä¸ªç›®å½•ï¼Œæ‰«æäº†{total_files_searched}ä¸ªæ–‡ä»¶ï¼Œæ‰¾åˆ°{found_count}ä¸ªåŒ¹é…æ–‡ä»¶")

    return found_files


@st.cache_data
def load_inventory_data(show_details=False):
    """åŠ è½½åº“å­˜æ•°æ® - æ›´çµæ´»çš„æ–‡ä»¶æŸ¥æ‰¾å’Œé”™è¯¯å¤„ç†"""
    try:
        # éœ€è¦æŸ¥æ‰¾çš„æ–‡ä»¶æ¨¡å¼
        file_patterns = [
            "*æ‰¹æ¬¡*åº“å­˜*.xlsx",  # åº“å­˜æ•°æ®
            "*å‡ºè´§æ•°æ®*.xlsx",  # å‡ºè´§æ•°æ®
            "*äººå·¥é¢„æµ‹*.xlsx",  # é¢„æµ‹æ•°æ®
            "*å•ä»·*.xlsx"  # å•ä»·æ•°æ®
        ]

        # æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶
        found_files = find_data_files(file_patterns)

        # æ˜¾ç¤ºæ•°æ®æ–‡ä»¶ä¿¡æ¯
        if show_details:
            file_info = "<div class='data-search-info'>æ•°æ®æ–‡ä»¶æœç´¢ç»“æœï¼š<ul>"
            for pattern, file_path in found_files.items():
                status = "âœ… å·²æ‰¾åˆ°" if file_path else "âŒ æœªæ‰¾åˆ°"
                file_info += f"<li>{pattern}: {status}"
                if file_path:
                    file_info += f" <span class='file-info'>({file_path}, ä¿®æ”¹æ—¶é—´: {datetime.fromtimestamp(os.path.getmtime(file_path)).strftime('%Y-%m-%d %H:%M')})</span>"
                file_info += "</li>"
            file_info += "</ul></div>"
            st.markdown(file_info, unsafe_allow_html=True)

        # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°äº†å¿…è¦çš„åº“å­˜æ•°æ®æ–‡ä»¶
        inventory_file = found_files.get("*æ‰¹æ¬¡*åº“å­˜*.xlsx")
        if not inventory_file:
            st.error("æ‰¾ä¸åˆ°åº“å­˜æ•°æ®æ–‡ä»¶ï¼Œè¯·ç¡®ä¿æ–‡ä»¶ååŒ…å«'æ‰¹æ¬¡'å’Œ'åº“å­˜'å­—æ ·ï¼Œæ ¼å¼ä¸ºExcel(.xlsx)")
            if show_details:
                st.info("æç¤ºï¼šè¯·æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä½äºåº”ç”¨ç›®å½•ã€pageså­ç›®å½•æˆ–dataå­ç›®å½•ä¸­")
            return None

        # è¯»å–åº“å­˜æ•°æ® - å¢å¼ºçš„é”™è¯¯å¤„ç†
        try:
            inventory_raw = pd.read_excel(inventory_file, header=0)
            logger.info(f"æˆåŠŸè¯»å–åº“å­˜æ•°æ®: {inventory_file}, è¡Œæ•°: {len(inventory_raw)}")
        except Exception as e:
            st.error(f"è¯»å–åº“å­˜æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            st.info(f"è¯·æ£€æŸ¥æ–‡ä»¶ {inventory_file} çš„æ ¼å¼æ˜¯å¦æ­£ç¡®")
            return None

        # é€šè¿‡åˆ†ææ•°æ®ç»“æ„å¤„ç†æ•°æ®
        # é¦–å…ˆæ£€æŸ¥æ•°æ®ç»“æ„
        if len(inventory_raw.columns) < 7:
            st.error(f"åº“å­˜æ•°æ®æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®: åªæœ‰{len(inventory_raw.columns)}åˆ—ï¼Œè‡³å°‘éœ€è¦7åˆ—")
            return None

        # å¤„ç†ç¬¬ä¸€å±‚æ•°æ®ï¼ˆäº§å“ä¿¡æ¯ï¼‰- ä½¿ç”¨æ›´çµæ´»çš„åˆ—æ£€æµ‹
        product_rows = inventory_raw[inventory_raw.iloc[:, 0].notna()]
        inventory_data = product_rows.iloc[:, :7].copy()

        # åŠ¨æ€è®¾ç½®åˆ—å
        expected_cols = ['äº§å“ä»£ç ', 'æè¿°', 'ç°æœ‰åº“å­˜', 'å·²åˆ†é…é‡', 'ç°æœ‰åº“å­˜å¯è®¢é‡', 'å¾…å…¥åº“é‡', 'æœ¬æœˆå‰©ä½™å¯è®¢é‡']
        if len(inventory_data.columns) >= len(expected_cols):
            inventory_data.columns = expected_cols
        else:
            st.warning(f"åº“å­˜æ•°æ®åˆ—æ•°ä¸è¶³ï¼Œé¢„æœŸ{len(expected_cols)}åˆ—ï¼Œå®é™…{len(inventory_data.columns)}åˆ—")
            # å°è¯•éƒ¨åˆ†æ˜ å°„
            available_cols = min(len(inventory_data.columns), len(expected_cols))
            inventory_data.columns = expected_cols[:available_cols] + list(inventory_data.columns[available_cols:])

        # å¤„ç†ç¬¬äºŒå±‚æ•°æ®ï¼ˆæ‰¹æ¬¡ä¿¡æ¯ï¼‰
        batch_rows = inventory_raw[inventory_raw.iloc[:, 7].notna()]
        if len(batch_rows) == 0:
            st.warning("åº“å­˜æ•°æ®ä¸­æœªæ‰¾åˆ°æ‰¹æ¬¡ä¿¡æ¯ï¼Œè¿™å°†å½±å“åˆ†æç»“æœ")
            batch_data = pd.DataFrame(columns=['äº§å“ä»£ç ', 'æè¿°', 'åº“ä½', 'ç”Ÿäº§æ—¥æœŸ', 'ç”Ÿäº§æ‰¹å·', 'æ•°é‡'])
        else:
            batch_data = batch_rows.iloc[:, 7:].copy()
            batch_cols = ['åº“ä½', 'ç”Ÿäº§æ—¥æœŸ', 'ç”Ÿäº§æ‰¹å·', 'æ•°é‡']
            batch_data.columns = batch_cols + list(batch_data.columns[len(batch_cols):])

            # ä¸ºæ‰¹æ¬¡æ•°æ®æ·»åŠ äº§å“ä»£ç 
            product_code = None
            product_description = None
            batch_with_product = []

            for i, row in inventory_raw.iterrows():
                if pd.notna(row.iloc[0]):
                    # è¿™æ˜¯äº§å“è¡Œ
                    product_code = row.iloc[0]
                    product_description = row.iloc[1] if len(row) > 1 else ""  # è·å–äº§å“æè¿°
                elif pd.notna(row.iloc[7]) and product_code is not None:
                    # è¿™æ˜¯æ‰¹æ¬¡è¡Œ
                    batch_row = row.iloc[7:].copy()
                    batch_row_with_product = pd.Series([product_code, product_description] + batch_row.tolist())
                    batch_with_product.append(batch_row_with_product)

            if batch_with_product:
                batch_data = pd.DataFrame(batch_with_product)
                batch_cols = ['äº§å“ä»£ç ', 'æè¿°', 'åº“ä½', 'ç”Ÿäº§æ—¥æœŸ', 'ç”Ÿäº§æ‰¹å·', 'æ•°é‡']
                batch_data.columns = batch_cols + list(batch_data.columns[len(batch_cols):])

                # è½¬æ¢æ—¥æœŸåˆ— - å®¹é”™å¤„ç†
                try:
                    batch_data['ç”Ÿäº§æ—¥æœŸ'] = pd.to_datetime(batch_data['ç”Ÿäº§æ—¥æœŸ'], errors='coerce')
                except Exception as e:
                    st.warning(f"è½¬æ¢ç”Ÿäº§æ—¥æœŸæ—¶å‡ºé”™: {str(e)}ï¼Œå°†ä½¿ç”¨å½“å‰æ—¥æœŸä»£æ›¿")
                    batch_data['ç”Ÿäº§æ—¥æœŸ'] = datetime.now()
            else:
                batch_data = pd.DataFrame(columns=['äº§å“ä»£ç ', 'æè¿°', 'åº“ä½', 'ç”Ÿäº§æ—¥æœŸ', 'ç”Ÿäº§æ‰¹å·', 'æ•°é‡'])
                st.warning("æ— æ³•æå–æ‰¹æ¬¡ä¿¡æ¯ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼")

        # åŠ è½½å‡ºè´§æ•°æ®
        shipping_data = None
        shipping_file = found_files.get("*å‡ºè´§æ•°æ®*.xlsx")
        if shipping_file:
            try:
                shipping_data = pd.read_excel(shipping_file)

                # å°è¯•è‡ªåŠ¨æ£€æµ‹åˆ—å
                if 'äº§å“ä»£ç ' in shipping_data.columns and 'æ•°é‡' in shipping_data.columns:
                    required_cols = ['è®¢å•æ—¥æœŸ', 'æ‰€å±åŒºåŸŸ', 'ç”³è¯·äºº', 'äº§å“ä»£ç ', 'æ•°é‡']
                    missing_cols = [col for col in required_cols if col not in shipping_data.columns]

                    if missing_cols:
                        st.warning(f"å‡ºè´§æ•°æ®ç¼ºå°‘åˆ—: {', '.join(missing_cols)}ï¼Œåˆ†æç»“æœå¯èƒ½ä¸å‡†ç¡®")
                else:
                    # å‡è®¾æ ‡å‡†æ ¼å¼
                    shipping_data.columns = ['è®¢å•æ—¥æœŸ', 'æ‰€å±åŒºåŸŸ', 'ç”³è¯·äºº', 'äº§å“ä»£ç ', 'æ•°é‡']

                shipping_data['è®¢å•æ—¥æœŸ'] = pd.to_datetime(shipping_data['è®¢å•æ—¥æœŸ'], errors='coerce')
                logger.info(f"æˆåŠŸè¯»å–å‡ºè´§æ•°æ®: {shipping_file}, è¡Œæ•°: {len(shipping_data)}")
            except Exception as e:
                st.warning(f"è¯»å–å‡ºè´§æ•°æ®æ—¶å‡ºé”™: {str(e)}ï¼Œå°†å½±å“é”€å”®åˆ†æç»“æœ")
                shipping_data = None

        # åŠ è½½é¢„æµ‹æ•°æ®
        forecast_data = None
        forecast_file = found_files.get("*äººå·¥é¢„æµ‹*.xlsx")
        if forecast_file:
            try:
                forecast_data = pd.read_excel(forecast_file)

                # å°è¯•è‡ªåŠ¨æ£€æµ‹åˆ—å
                if 'äº§å“ä»£ç ' in forecast_data.columns and 'é¢„è®¡é”€å”®é‡' in forecast_data.columns:
                    # ä½¿ç”¨ç°æœ‰åˆ—å
                    pass
                else:
                    # å‡è®¾æ ‡å‡†æ ¼å¼
                    forecast_data.columns = ['æ‰€å±å¤§åŒº', 'é”€å”®å‘˜', 'æ‰€å±å¹´æœˆ', 'äº§å“ä»£ç ', 'é¢„è®¡é”€å”®é‡']

                # å°è¯•è½¬æ¢æ—¥æœŸåˆ—
                try:
                    forecast_data['æ‰€å±å¹´æœˆ'] = pd.to_datetime(forecast_data['æ‰€å±å¹´æœˆ'], errors='coerce')
                except:
                    st.warning("è½¬æ¢é¢„æµ‹æ•°æ®æ—¥æœŸæ—¶å‡ºé”™ï¼Œå°†å½±å“é¢„æµ‹åˆ†æç»“æœ")

                logger.info(f"æˆåŠŸè¯»å–é¢„æµ‹æ•°æ®: {forecast_file}, è¡Œæ•°: {len(forecast_data)}")
            except Exception as e:
                st.warning(f"è¯»å–é¢„æµ‹æ•°æ®æ—¶å‡ºé”™: {str(e)}ï¼Œå°†å½±å“é¢„æµ‹åˆ†æç»“æœ")
                forecast_data = None

        # åŠ è½½å•ä»·æ•°æ®
        price_data = {}
        price_file = found_files.get("*å•ä»·*.xlsx")
        if price_file:
            try:
                price_df = pd.read_excel(price_file)

                # æ£€æµ‹åˆ—å
                if 'äº§å“ä»£ç ' in price_df.columns and 'å•ä»·' in price_df.columns:
                    for _, row in price_df.iterrows():
                        price_data[row['äº§å“ä»£ç ']] = row['å•ä»·']
                else:
                    # å°è¯•ä½¿ç”¨å‰ä¸¤åˆ—
                    for _, row in price_df.iterrows():
                        if len(row) >= 2:
                            price_data[str(row.iloc[0])] = float(row.iloc[1])

                logger.info(f"æˆåŠŸè¯»å–å•ä»·æ•°æ®: {price_file}, äº§å“æ•°: {len(price_data)}")
            except Exception as e:
                st.warning(f"è¯»å–å•ä»·æ•°æ®æ—¶å‡ºé”™: {str(e)}ï¼Œå°†ä½¿ç”¨é»˜è®¤å•ä»·")
                price_data = {}

        # å¦‚æœæœªæ‰¾åˆ°ä»·æ ¼æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤ä»·æ ¼
        if not price_data:
            # ä»åº“å­˜æ•°æ®ä¸­ï¼Œæå–æ‰€æœ‰äº§å“ä»£ç ï¼Œè®¾ç½®é»˜è®¤ä»·æ ¼
            for code in inventory_data['äº§å“ä»£ç ']:
                if code not in price_data:
                    price_data[code] = 150.0  # é»˜è®¤ä»·æ ¼

        return {
            'inventory_data': inventory_data,
            'batch_data': batch_data,
            'shipping_data': shipping_data,
            'forecast_data': forecast_data,
            'price_data': price_data
        }

    except Exception as e:
        logger.exception("åŠ è½½åº“å­˜æ•°æ®æ—¶å‘ç”Ÿå¼‚å¸¸")
        st.error(f"æ•°æ®åŠ è½½è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        return None


@st.cache_data
def load_and_process_inventory_data(show_details=False):
    """åŠ è½½å¹¶å¤„ç†åº“å­˜åˆ†ææ•°æ® - ä¸å†ä½¿ç”¨ç¤ºä¾‹æ•°æ®"""
    try:
        with st.spinner("æ­£åœ¨åŠ è½½åº“å­˜æ•°æ®..."):
            data = load_inventory_data(show_details)

            if not data:
                st.error("æ— æ³•åŠ è½½åº“å­˜æ•°æ®ï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶è·¯å¾„å’Œæ ¼å¼")
                return None

            if 'inventory_data' not in data or data['inventory_data'].empty:
                st.error("åº“å­˜æ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶")
                return None

            # åˆ†ææ•°æ®
            with st.spinner("æ­£åœ¨åˆ†æåº“å­˜æ•°æ®..."):
                analysis_result = analyze_inventory_data(data)
                data['analysis_result'] = analysis_result

            if not analysis_result:
                st.warning("æ•°æ®åˆ†æç»“æœä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®è´¨é‡")

            return data

    except Exception as e:
        logger.exception("å¤„ç†åº“å­˜æ•°æ®æ—¶å‘ç”Ÿå¼‚å¸¸")
        st.error(f"æ•°æ®å¤„ç†å¤±è´¥: {str(e)}")
        return None


# ==================== 3. åº“å­˜ç­›é€‰å™¨ ====================
def create_inventory_filters(data):
    """åˆ›å»ºåº“å­˜é¡µé¢ä¸“ç”¨ç­›é€‰å™¨"""
    if not data:
        return data

    # åˆå§‹åŒ–ç­›é€‰çŠ¶æ€
    if 'inv_filter_product' not in st.session_state:
        st.session_state.inv_filter_product = 'å…¨éƒ¨'
    if 'inv_filter_risk' not in st.session_state:
        st.session_state.inv_filter_risk = 'å…¨éƒ¨'
    if 'inv_filter_region' not in st.session_state:
        st.session_state.inv_filter_region = 'å…¨éƒ¨'
    if 'inv_filter_person' not in st.session_state:
        st.session_state.inv_filter_person = 'å…¨éƒ¨'

    with st.sidebar:
        st.markdown("## ğŸ” åº“å­˜ç­›é€‰")
        st.markdown("---")

        # äº§å“ä»£ç ç­›é€‰
        if 'batch_data' in data and not data['batch_data'].empty:
            all_products = ['å…¨éƒ¨'] + sorted(data['batch_data']['äº§å“ä»£ç '].unique().tolist())
            selected_product = st.selectbox(
                "é€‰æ‹©äº§å“ä»£ç ", all_products,
                index=all_products.index(
                    st.session_state.inv_filter_product) if st.session_state.inv_filter_product in all_products else 0,
                key="inv_product_filter"
            )
            st.session_state.inv_filter_product = selected_product

        # é£é™©ç­‰çº§ç­›é€‰
        risk_levels = ['å…¨éƒ¨', 'æé«˜é£é™©', 'é«˜é£é™©', 'ä¸­é£é™©', 'ä½é£é™©', 'æä½é£é™©']
        selected_risk = st.selectbox(
            "é€‰æ‹©é£é™©ç­‰çº§", risk_levels,
            index=risk_levels.index(
                st.session_state.inv_filter_risk) if st.session_state.inv_filter_risk in risk_levels else 0,
            key="inv_risk_filter"
        )
        st.session_state.inv_filter_risk = selected_risk

        # è´£ä»»åŒºåŸŸç­›é€‰
        if 'shipping_data' in data and data['shipping_data'] is not None and not data['shipping_data'].empty:
            all_regions = ['å…¨éƒ¨'] + sorted(data['shipping_data']['æ‰€å±åŒºåŸŸ'].unique().tolist())
            selected_region = st.selectbox(
                "é€‰æ‹©è´£ä»»åŒºåŸŸ", all_regions,
                index=all_regions.index(
                    st.session_state.inv_filter_region) if st.session_state.inv_filter_region in all_regions else 0,
                key="inv_region_filter"
            )
            st.session_state.inv_filter_region = selected_region

        # è´£ä»»äººç­›é€‰
        if 'shipping_data' in data and data['shipping_data'] is not None and not data['shipping_data'].empty:
            all_persons = ['å…¨éƒ¨'] + sorted(data['shipping_data']['ç”³è¯·äºº'].unique().tolist())
            selected_person = st.selectbox(
                "é€‰æ‹©è´£ä»»äºº", all_persons,
                index=all_persons.index(
                    st.session_state.inv_filter_person) if st.session_state.inv_filter_person in all_persons else 0,
                key="inv_person_filter"
            )
            st.session_state.inv_filter_person = selected_person

        # é‡ç½®æŒ‰é’®
        if st.button("é‡ç½®ç­›é€‰æ¡ä»¶", key="inv_reset_filters"):
            st.session_state.inv_filter_product = 'å…¨éƒ¨'
            st.session_state.inv_filter_risk = 'å…¨éƒ¨'
            st.session_state.inv_filter_region = 'å…¨éƒ¨'
            st.session_state.inv_filter_person = 'å…¨éƒ¨'
            st.rerun()

    return apply_inventory_filters(data)


def apply_inventory_filters(data):
    """åº”ç”¨åº“å­˜ç­›é€‰æ¡ä»¶"""
    if not data or 'analysis_result' not in data:
        return data

    filtered_data = data.copy()

    # åº”ç”¨ç­›é€‰åˆ°æ‰¹æ¬¡åˆ†æç»“æœ
    if 'batch_analysis' in data['analysis_result']:
        batch_analysis = data['analysis_result']['batch_analysis'].copy()

        # äº§å“ç­›é€‰
        if st.session_state.inv_filter_product != 'å…¨éƒ¨':
            batch_analysis = batch_analysis[batch_analysis['äº§å“ä»£ç '] == st.session_state.inv_filter_product]

        # é£é™©ç­‰çº§ç­›é€‰
        if st.session_state.inv_filter_risk != 'å…¨éƒ¨':
            batch_analysis = batch_analysis[batch_analysis['é£é™©ç¨‹åº¦'] == st.session_state.inv_filter_risk]

        # è´£ä»»åŒºåŸŸç­›é€‰
        if st.session_state.inv_filter_region != 'å…¨éƒ¨':
            batch_analysis = batch_analysis[batch_analysis['è´£ä»»åŒºåŸŸ'] == st.session_state.inv_filter_region]

        # è´£ä»»äººç­›é€‰
        if st.session_state.inv_filter_person != 'å…¨éƒ¨':
            batch_analysis = batch_analysis[batch_analysis['è´£ä»»äºº'] == st.session_state.inv_filter_person]

        # æ›´æ–°ç­›é€‰åçš„æ•°æ®
        filtered_data['analysis_result']['batch_analysis'] = batch_analysis

    return filtered_data


# ==================== 4. è¾…åŠ©å‡½æ•° ====================
def get_simplified_product_name(product_code, full_name):
    """å°†äº§å“å®Œæ•´åç§°ç®€åŒ–ä¸ºæ›´ç®€çŸ­çš„æ ¼å¼"""
    if not full_name or not isinstance(full_name, str):
        return product_code

    # å¦‚æœç¬¦åˆ"å£åŠ›X-ä¸­å›½"æ ¼å¼ï¼Œåˆ™ç®€åŒ–
    if "å£åŠ›" in full_name and "-ä¸­å›½" in full_name:
        # å»é™¤"å£åŠ›"å‰ç¼€å’Œ"-ä¸­å›½"åç¼€
        return full_name.replace("å£åŠ›", "").replace("-ä¸­å›½", "").strip()

    # å¦åˆ™è¿”å›åŸå§‹åç§°
    return full_name


def calculate_risk_percentage(days_to_clear, batch_age, target_days):
    """
    è®¡ç®—åº“å­˜é£é™©ç™¾åˆ†æ¯”

    å‚æ•°:
    days_to_clear (float): é¢„è®¡æ¸…åº“å¤©æ•°
    batch_age (int): æ‰¹æ¬¡åº“é¾„ï¼ˆå¤©æ•°ï¼‰
    target_days (int): ç›®æ ‡æ¸…åº“å¤©æ•°ï¼ˆ30/60/90å¤©ï¼‰

    è¿”å›:
    float: é£é™©ç™¾åˆ†æ¯”ï¼ŒèŒƒå›´0-100
    """
    # åº“é¾„å·²ç»è¶…è¿‡ç›®æ ‡å¤©æ•°ï¼Œé£é™©ç›´æ¥ä¸º100%
    if batch_age >= target_days:
        return 100.0

    # æ— æ³•æ¸…åº“æƒ…å†µ
    if days_to_clear == float('inf'):
        return 100.0

    # æ¸…åº“å¤©æ•°è¶…è¿‡ç›®æ ‡çš„3å€ï¼Œé£é™©ä¸º100%
    if days_to_clear >= 3 * target_days:
        return 100.0

    # è®¡ç®—åŸºäºæ¸…åº“å¤©æ•°çš„é£é™©
    clearance_ratio = days_to_clear / target_days
    clearance_risk = 100 / (1 + math.exp(-4 * (clearance_ratio - 1)))

    # è®¡ç®—åŸºäºåº“é¾„çš„é£é™©
    age_risk = 100 * batch_age / target_days

    # ç»„åˆé£é™© - åŠ æƒå¹³å‡ï¼Œæ›´å¼ºè°ƒé«˜é£é™©å› ç´ 
    combined_risk = 0.8 * max(clearance_risk, age_risk) + 0.2 * min(clearance_risk, age_risk)

    # æ¸…åº“å¤©æ•°è¶…è¿‡ç›®æ ‡ï¼Œé£é™©è‡³å°‘ä¸º80%
    if days_to_clear > target_days:
        combined_risk = max(combined_risk, 80)

    # æ¸…åº“å¤©æ•°è¶…è¿‡ç›®æ ‡çš„2å€ï¼Œé£é™©è‡³å°‘ä¸º90%
    if days_to_clear >= 2 * target_days:
        combined_risk = max(combined_risk, 90)

    # åº“é¾„è¶…è¿‡ç›®æ ‡çš„75%ï¼Œé£é™©è‡³å°‘ä¸º75%
    if batch_age >= 0.75 * target_days:
        combined_risk = max(combined_risk, 75)

    return min(100, round(combined_risk, 1))


def calculate_inventory_risk_level(batch_age, days_to_clear, sales_volatility, forecast_bias):
    """
    è®¡ç®—åº“å­˜é£é™©ç­‰çº§

    å‚æ•°:
    batch_age (int): æ‰¹æ¬¡åº“é¾„ï¼ˆå¤©æ•°ï¼‰
    days_to_clear (float): é¢„è®¡æ¸…åº“å¤©æ•°
    sales_volatility (float): é”€é‡æ³¢åŠ¨ç³»æ•°
    forecast_bias (float): é¢„æµ‹åå·®

    è¿”å›:
    str: é£é™©ç­‰çº§ï¼ˆæé«˜é£é™©/é«˜é£é™©/ä¸­é£é™©/ä½é£é™©/æä½é£é™©ï¼‰
    """
    risk_score = 0

    # åº“é¾„å› ç´  (0-40åˆ†)
    if batch_age > 90:
        risk_score += 40
    elif batch_age > 60:
        risk_score += 30
    elif batch_age > 30:
        risk_score += 20
    else:
        risk_score += 10

    # æ¸…åº“å¤©æ•°å› ç´  (0-40åˆ†)
    if days_to_clear == float('inf'):
        risk_score += 40
    elif days_to_clear > 180:  # åŠå¹´ä»¥ä¸Š
        risk_score += 35
    elif days_to_clear > 90:  # 3ä¸ªæœˆä»¥ä¸Š
        risk_score += 30
    elif days_to_clear > 60:  # 2ä¸ªæœˆä»¥ä¸Š
        risk_score += 20
    elif days_to_clear > 30:  # 1ä¸ªæœˆä»¥ä¸Š
        risk_score += 10

    # é”€é‡æ³¢åŠ¨ç³»æ•° (0-10åˆ†)
    if sales_volatility > 2.0:
        risk_score += 10
    elif sales_volatility > 1.0:
        risk_score += 5

    # é¢„æµ‹åå·® (0-10åˆ†) - ä½¿ç”¨ç»å¯¹å€¼è¯„ä¼°åå·®å¤§å°
    if abs(forecast_bias) > 0.5:  # 50%ä»¥ä¸Šåå·®
        risk_score += 10
    elif abs(forecast_bias) > 0.3:  # 30%ä»¥ä¸Šåå·®
        risk_score += 8
    elif abs(forecast_bias) > 0.15:  # 15%ä»¥ä¸Šåå·®
        risk_score += 5

    # æ ¹æ®æ€»åˆ†ç¡®å®šé£é™©ç­‰çº§
    if risk_score >= 80:
        return "æé«˜é£é™©"
    elif risk_score >= 60:
        return "é«˜é£é™©"
    elif risk_score >= 40:
        return "ä¸­é£é™©"
    elif risk_score >= 20:
        return "ä½é£é™©"
    else:
        return "æä½é£é™©"


def add_chart_explanation(explanation_text):
    """æ·»åŠ å›¾è¡¨è§£é‡Š"""
    st.markdown(f'<div class="chart-explanation">{explanation_text}</div>', unsafe_allow_html=True)


def display_empty_chart_message(title, message):
    """æ˜¾ç¤ºç©ºå›¾è¡¨æç¤ºä¿¡æ¯"""
    st.markdown(
        f'''
        <div class="empty-chart-message">
            <h3>{title}</h3>
            <p>{message}</p>
        </div>
        ''',
        unsafe_allow_html=True
    )


# ==================== 5. æ ¸å¿ƒåˆ†æå‡½æ•° ====================
def analyze_inventory_data(data):
    """åˆ†æåº“å­˜æ•°æ®ï¼Œå®ç°å®Œæ•´çš„ä¸šåŠ¡é€»è¾‘"""
    try:
        if not data or 'inventory_data' not in data or data['inventory_data'].empty:
            return {}

        # è·å–æ•°æ®
        inventory_data = data['inventory_data']
        batch_data = data.get('batch_data', pd.DataFrame())
        shipping_data = data.get('shipping_data', pd.DataFrame())
        forecast_data = data.get('forecast_data', pd.DataFrame())
        price_data = data.get('price_data', {})

        # è®¡ç®—åŸºç¡€æŒ‡æ ‡
        total_inventory = inventory_data['ç°æœ‰åº“å­˜'].sum() if 'ç°æœ‰åº“å­˜' in inventory_data.columns else 0

        # è®¡ç®—åº“å­˜æ€»ä»·å€¼
        total_inventory_value = 0
        for _, row in inventory_data.iterrows():
            code = row['äº§å“ä»£ç ']
            qty = row['ç°æœ‰åº“å­˜']
            price = price_data.get(code, 150.0)  # é»˜è®¤ä»·æ ¼
            total_inventory_value += qty * price

        # æ‰¹æ¬¡çº§åˆ«åˆ†æ
        batch_analysis = None
        if not batch_data.empty:
            batch_analysis = analyze_batch_level_data(batch_data, shipping_data, forecast_data, price_data)

        # è®¡ç®—åº“å­˜å‘¨è½¬ç‡å’Œå‘¨è½¬å¤©æ•°
        inventory_turnover, inventory_turnover_days = calculate_inventory_turnover(
            inventory_data, shipping_data, 90, price_data  # ä½¿ç”¨90å¤©çš„é”€å”®æ•°æ®
        )

        # è®¡ç®—å‘†æ»åº“å­˜æ¯”ä¾‹
        stagnant_ratio, stagnant_value = calculate_stagnant_inventory(batch_analysis, price_data, total_inventory_value)

        # è®¡ç®—åº“å­˜èµ„é‡‘å ç”¨æˆæœ¬
        annual_rate = INVENTORY_CONFIG['annual_capital_cost']  # å¹´åŒ–èµ„é‡‘æˆæœ¬ç‡
        daily_rate = annual_rate / 365
        capital_cost = total_inventory_value * annual_rate / 12  # æœˆåŒ–æˆæœ¬

        # è®¡ç®—å¥åº·åˆ†å¸ƒ
        health_distribution = {}
        risk_distribution = {}

        if batch_analysis is not None and not batch_analysis.empty:
            # æ ¹æ®é£é™©ç¨‹åº¦ç»Ÿè®¡
            risk_counts = batch_analysis['é£é™©ç¨‹åº¦'].value_counts().to_dict()
            risk_distribution = risk_counts

            # è½¬æ¢ä¸ºå¥åº·åˆ†å¸ƒ
            extreme_high = risk_counts.get('æé«˜é£é™©', 0)
            high = risk_counts.get('é«˜é£é™©', 0)
            medium = risk_counts.get('ä¸­é£é™©', 0)
            low = risk_counts.get('ä½é£é™©', 0)
            extreme_low = risk_counts.get('æä½é£é™©', 0)

            health_distribution = {
                'åº“å­˜è¿‡å‰©': extreme_high + high,
                'åº“å­˜å¥åº·': medium + low,
                'åº“å­˜ä¸è¶³': extreme_low
            }

        return {
            'total_inventory': total_inventory,
            'total_inventory_value': total_inventory_value,
            'inventory_turnover': inventory_turnover,
            'inventory_turnover_days': inventory_turnover_days,
            'stagnant_ratio': stagnant_ratio,
            'stagnant_value': stagnant_value,
            'capital_cost': capital_cost,
            'health_distribution': health_distribution,
            'risk_distribution': risk_distribution,
            'batch_analysis': batch_analysis
        }

    except Exception as e:
        logger.exception("åº“å­˜åˆ†æå‡ºé”™")
        st.error(f"åº“å­˜åˆ†æå‡ºé”™: {str(e)}")
        return {}


def calculate_inventory_turnover(inventory_data, shipping_data, days_period, price_data):
    """è®¡ç®—åº“å­˜å‘¨è½¬ç‡å’Œå‘¨è½¬å¤©æ•°"""
    try:
        # åº“å­˜å‘¨è½¬ç‡ = ä¸€æ®µæ—¶é—´å†…çš„é”€å”®æˆæœ¬ / å¹³å‡åº“å­˜ä»·å€¼
        # è¿™é‡Œç®€åŒ–ä¸ºï¼šå‘¨æœŸå†…é”€å”®é‡ / å½“å‰åº“å­˜é‡

        if inventory_data.empty or shipping_data is None or shipping_data.empty:
            return 0.0, float('inf')

        # è®¡ç®—å½“å‰åº“å­˜æ€»ä»·å€¼
        current_inventory_value = 0
        for _, row in inventory_data.iterrows():
            code = row['äº§å“ä»£ç ']
            qty = row['ç°æœ‰åº“å­˜']
            price = price_data.get(code, 150.0)  # é»˜è®¤ä»·æ ¼
            current_inventory_value += qty * price

        if current_inventory_value == 0:
            return 0.0, float('inf')

        # è®¡ç®—å‘¨æœŸå†…çš„é”€å”®æ€»ä»·å€¼
        today = datetime.now().date()
        period_start = today - timedelta(days=days_period)

        period_sales_value = 0
        period_shipping = shipping_data[shipping_data['è®¢å•æ—¥æœŸ'].dt.date >= period_start]

        for _, row in period_shipping.iterrows():
            code = row['äº§å“ä»£ç ']
            qty = row['æ•°é‡']
            price = price_data.get(code, 150.0)  # é»˜è®¤ä»·æ ¼
            period_sales_value += qty * price

        # å¹´åŒ–å‘¨è½¬ç‡ = (å‘¨æœŸé”€å”®é¢ / å‘¨æœŸå¤©æ•°) * 365 / å½“å‰åº“å­˜å€¼
        annual_turnover = (period_sales_value / days_period) * 365 / current_inventory_value

        # å‘¨è½¬å¤©æ•° = 365 / å‘¨è½¬ç‡
        turnover_days = 365 / annual_turnover if annual_turnover > 0 else float('inf')

        return annual_turnover, turnover_days

    except Exception as e:
        logger.exception("è®¡ç®—åº“å­˜å‘¨è½¬å‡ºé”™")
        print(f"è®¡ç®—åº“å­˜å‘¨è½¬å‡ºé”™: {str(e)}")
        return 0.0, float('inf')


def calculate_stagnant_inventory(batch_analysis, price_data, total_inventory_value):
    """è®¡ç®—å‘†æ»åº“å­˜æ¯”ä¾‹å’Œä»·å€¼"""
    try:
        if batch_analysis is None or batch_analysis.empty or total_inventory_value == 0:
            return 0.0, 0.0

        # å®šä¹‰å‘†æ»åº“å­˜ï¼šåº“é¾„è¶…è¿‡60å¤©çš„æ‰¹æ¬¡
        stagnant_days = INVENTORY_CONFIG['stagnant_days_threshold']
        stagnant_batches = batch_analysis[batch_analysis['åº“é¾„'] > stagnant_days]

        if stagnant_batches.empty:
            return 0.0, 0.0

        # è®¡ç®—å‘†æ»åº“å­˜ä»·å€¼
        stagnant_value = stagnant_batches['æ‰¹æ¬¡ä»·å€¼'].sum()

        # è®¡ç®—å‘†æ»æ¯”ä¾‹
        stagnant_ratio = stagnant_value / total_inventory_value if total_inventory_value > 0 else 0.0

        return stagnant_ratio, stagnant_value

    except Exception as e:
        logger.exception("è®¡ç®—å‘†æ»åº“å­˜å‡ºé”™")
        print(f"è®¡ç®—å‘†æ»åº“å­˜å‡ºé”™: {str(e)}")
        return 0.0, 0.0


def analyze_batch_level_data(batch_data, shipping_data, forecast_data, price_data):
    """æ‰¹æ¬¡çº§åˆ«è¯¦ç»†åˆ†æ"""
    try:
        if batch_data.empty:
            return pd.DataFrame()

        batch_analysis = []
        today = datetime.now().date()

        # è®¡ç®—äº§å“é”€å”®æŒ‡æ ‡
        product_sales_metrics = calculate_product_sales_metrics(shipping_data)

        # å¤„ç†æ¯ä¸ªæ‰¹æ¬¡
        for _, batch in batch_data.iterrows():
            try:
                product_code = batch['äº§å“ä»£ç ']
                description = batch['æè¿°']
                batch_date = pd.to_datetime(batch['ç”Ÿäº§æ—¥æœŸ']).date() if pd.notna(batch['ç”Ÿäº§æ—¥æœŸ']) else today
                batch_qty = float(batch['æ•°é‡']) if pd.notna(batch['æ•°é‡']) else 0

                # è®¡ç®—åº“é¾„
                batch_age = (today - batch_date).days

                # è·å–äº§å“å•ä»·
                unit_price = price_data.get(product_code, 150.0)
                batch_value = batch_qty * unit_price

                # è·å–é”€å”®æŒ‡æ ‡
                sales_metrics = product_sales_metrics.get(product_code, {
                    'daily_avg_sales': 0.1,
                    'sales_volatility': 0,
                    'total_sales': 0
                })

                # è®¡ç®—æ¸…åº“å¤©æ•°
                daily_sales = max(sales_metrics['daily_avg_sales'], INVENTORY_CONFIG['min_daily_sales'])
                days_to_clear = batch_qty / daily_sales if daily_sales > 0 else float('inf')

                # è®¡ç®—é¢„æµ‹åå·®
                forecast_bias = calculate_forecast_bias(product_code, forecast_data, shipping_data)

                # è®¡ç®—é£é™©ç§¯å‹ç™¾åˆ†æ¯”
                one_month_risk = calculate_risk_percentage(days_to_clear, batch_age, 30)
                two_month_risk = calculate_risk_percentage(days_to_clear, batch_age, 60)
                three_month_risk = calculate_risk_percentage(days_to_clear, batch_age, 90)

                # è®¡ç®—é£é™©ç­‰çº§
                risk_level = calculate_inventory_risk_level(
                    batch_age, days_to_clear,
                    sales_metrics['sales_volatility'],
                    forecast_bias
                )

                # è´£ä»»å½’å±åˆ†æ
                responsible_region, responsible_person = analyze_responsibility_simplified(
                    product_code, shipping_data, forecast_data
                )

                # ç”Ÿæˆå»ºè®®æªæ–½
                recommendation = generate_recommendation_for_inventory(risk_level, batch_age, days_to_clear)

                # ç¡®å®šç§¯å‹åŸå› 
                stocking_reasons = determine_stocking_reasons(batch_age, sales_metrics['sales_volatility'],
                                                              forecast_bias)

                # è·å–äº§å“ç®€åŒ–åç§°
                simplified_name = get_simplified_product_name(product_code, description)

                # æ·»åŠ åˆ°åˆ†æç»“æœ
                batch_analysis.append({
                    'äº§å“ä»£ç ': product_code,
                    'æè¿°': description,
                    'äº§å“ç®€åŒ–åç§°': simplified_name,
                    'æ‰¹æ¬¡æ—¥æœŸ': batch_date,
                    'æ‰¹æ¬¡åº“å­˜': batch_qty,
                    'åº“é¾„': batch_age,
                    'æ‰¹æ¬¡ä»·å€¼': batch_value,
                    'æ—¥å‡å‡ºè´§': round(sales_metrics['daily_avg_sales'], 2),
                    'å‡ºè´§æ³¢åŠ¨ç³»æ•°': round(sales_metrics['sales_volatility'], 2),
                    'é¢„è®¡æ¸…åº“å¤©æ•°': days_to_clear if days_to_clear != float('inf') else float('inf'),
                    'ä¸€ä¸ªæœˆç§¯å‹é£é™©': f"{one_month_risk:.1f}%",
                    'ä¸¤ä¸ªæœˆç§¯å‹é£é™©': f"{two_month_risk:.1f}%",
                    'ä¸‰ä¸ªæœˆç§¯å‹é£é™©': f"{three_month_risk:.1f}%",
                    'ç§¯å‹åŸå› ': stocking_reasons,
                    'è´£ä»»åŒºåŸŸ': responsible_region,
                    'è´£ä»»äºº': responsible_person,
                    'é£é™©ç¨‹åº¦': risk_level,
                    'é£é™©å¾—åˆ†': calculate_risk_score(batch_age, days_to_clear, sales_metrics['sales_volatility'],
                                                     forecast_bias),
                    'å»ºè®®æªæ–½': recommendation,
                    'é¢„æµ‹åå·®': f"{forecast_bias * 100:.1f}%" if abs(forecast_bias) < 10 else "å¼‚å¸¸"
                })

            except Exception as e:
                logger.exception(f"å¤„ç†æ‰¹æ¬¡æ•°æ®æ—¶å‡ºé”™: {str(e)}")
                continue

        # è½¬æ¢ä¸ºDataFrameå¹¶æ’åº
        if batch_analysis:
            df = pd.DataFrame(batch_analysis)
            risk_order = {"æé«˜é£é™©": 0, "é«˜é£é™©": 1, "ä¸­é£é™©": 2, "ä½é£é™©": 3, "æä½é£é™©": 4}
            df['é£é™©æ’åº'] = df['é£é™©ç¨‹åº¦'].map(risk_order)
            df = df.sort_values(['é£é™©æ’åº', 'åº“é¾„'], ascending=[True, False])
            df = df.drop(columns=['é£é™©æ’åº'])
            return df
        else:
            return pd.DataFrame()

    except Exception as e:
        logger.exception("æ‰¹æ¬¡åˆ†æå‡ºé”™")
        st.error(f"æ‰¹æ¬¡åˆ†æå‡ºé”™: {str(e)}")
        return pd.DataFrame()


def calculate_risk_score(batch_age, days_to_clear, sales_volatility, forecast_bias):
    """è®¡ç®—æ‰¹æ¬¡é£é™©å¾—åˆ†"""
    risk_score = 0

    # åº“é¾„å› ç´  (0-40åˆ†)
    if batch_age > 90:
        risk_score += 40
    elif batch_age > 60:
        risk_score += 30
    elif batch_age > 30:
        risk_score += 20
    else:
        risk_score += 10

    # æ¸…åº“å¤©æ•°å› ç´  (0-40åˆ†)
    if days_to_clear == float('inf'):
        risk_score += 40
    elif days_to_clear > 180:  # åŠå¹´ä»¥ä¸Š
        risk_score += 35
    elif days_to_clear > 90:  # 3ä¸ªæœˆä»¥ä¸Š
        risk_score += 30
    elif days_to_clear > 60:  # 2ä¸ªæœˆä»¥ä¸Š
        risk_score += 20
    elif days_to_clear > 30:  # 1ä¸ªæœˆä»¥ä¸Š
        risk_score += 10

    # é”€é‡æ³¢åŠ¨ç³»æ•° (0-10åˆ†)
    if sales_volatility > 2.0:
        risk_score += 10
    elif sales_volatility > 1.0:
        risk_score += 5

    # é¢„æµ‹åå·® (0-10åˆ†) - ä½¿ç”¨ç»å¯¹å€¼è¯„ä¼°åå·®å¤§å°
    if abs(forecast_bias) > 0.5:  # 50%ä»¥ä¸Šåå·®
        risk_score += 10
    elif abs(forecast_bias) > 0.3:  # 30%ä»¥ä¸Šåå·®
        risk_score += 8
    elif abs(forecast_bias) > 0.15:  # 15%ä»¥ä¸Šåå·®
        risk_score += 5

    return risk_score


def calculate_product_sales_metrics(shipping_data):
    """è®¡ç®—äº§å“é”€å”®æŒ‡æ ‡"""
    if shipping_data is None or shipping_data.empty:
        return {}

    metrics = {}
    today = datetime.now().date()

    for product_code in shipping_data['äº§å“ä»£ç '].unique():
        product_sales = shipping_data[shipping_data['äº§å“ä»£ç '] == product_code]

        if product_sales.empty:
            metrics[product_code] = {
                'daily_avg_sales': 0.1,
                'sales_volatility': 0,
                'total_sales': 0
            }
            continue

        # è®¡ç®—æ€»é”€é‡
        total_sales = product_sales['æ•°é‡'].sum()

        # è®¡ç®—æ—¥æœŸèŒƒå›´
        min_date = product_sales['è®¢å•æ—¥æœŸ'].min().date()
        days_range = (today - min_date).days + 1

        # æ—¥å‡é”€é‡
        daily_avg_sales = total_sales / days_range if days_range > 0 else 0.1

        # è®¡ç®—é”€é‡æ³¢åŠ¨
        daily_sales = product_sales.groupby(product_sales['è®¢å•æ—¥æœŸ'].dt.date)['æ•°é‡'].sum()
        sales_volatility = daily_sales.std() / daily_sales.mean() if len(
            daily_sales) > 1 and daily_sales.mean() > 0 else 0

        metrics[product_code] = {
            'daily_avg_sales': max(daily_avg_sales, 0.1),
            'sales_volatility': sales_volatility,
            'total_sales': total_sales
        }

    return metrics


def calculate_forecast_bias(product_code, forecast_data, shipping_data):
    """è®¡ç®—é¢„æµ‹åå·®"""
    try:
        if forecast_data is None or forecast_data.empty or shipping_data is None or shipping_data.empty:
            return 0.0

        # è·å–æœ€è¿‘ä¸€ä¸ªæœˆçš„é¢„æµ‹å’Œå®é™…é”€é‡
        recent_forecast = forecast_data[forecast_data['äº§å“ä»£ç '] == product_code]['é¢„è®¡é”€å”®é‡'].sum()

        # è·å–æœ€è¿‘30å¤©çš„å®é™…é”€é‡
        today = datetime.now().date()
        thirty_days_ago = today - timedelta(days=30)
        recent_sales_data = shipping_data[
            (shipping_data['äº§å“ä»£ç '] == product_code) &
            (shipping_data['è®¢å•æ—¥æœŸ'].dt.date >= thirty_days_ago)
            ]
        recent_sales = recent_sales_data['æ•°é‡'].sum() if not recent_sales_data.empty else 0

        if recent_forecast == 0 and recent_sales == 0:
            return 0.0
        elif recent_forecast == 0:
            return -1.0  # æ— é¢„æµ‹ä½†æœ‰é”€å”®
        elif recent_sales == 0:
            return 1.0  # æœ‰é¢„æµ‹ä½†æ— é”€å”®
        else:
            # è®¡ç®—é¢„æµ‹åå·® - å¯¹ç§°å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®(SMAPE)å˜ä½“
            bias = (recent_forecast - recent_sales) / ((recent_forecast + recent_sales) / 2)
            return max(-1.0, min(1.0, bias))  # é™åˆ¶åœ¨-1åˆ°1ä¹‹é—´

    except Exception:
        logger.exception("è®¡ç®—é¢„æµ‹åå·®å‡ºé”™")
        return 0.0


def analyze_responsibility_simplified(product_code, shipping_data, forecast_data):
    """ç®€åŒ–çš„è´£ä»»å½’å±åˆ†æ"""
    try:
        # é»˜è®¤è´£ä»»äººå’ŒåŒºåŸŸ
        default_region = "æœªçŸ¥åŒºåŸŸ"
        default_person = "ç³»ç»Ÿç®¡ç†å‘˜"

        # ä»å‡ºè´§æ•°æ®ä¸­æ‰¾æœ€ä¸»è¦çš„è´£ä»»äºº
        if shipping_data is not None and not shipping_data.empty:
            product_shipping = shipping_data[shipping_data['äº§å“ä»£ç '] == product_code]
            if not product_shipping.empty:
                # æŒ‰ç”³è¯·äººç»Ÿè®¡æ•°é‡
                person_sales = product_shipping.groupby('ç”³è¯·äºº')['æ•°é‡'].sum()
                if not person_sales.empty:
                    main_person = person_sales.idxmax()
                    # è·å–è¯¥äººå‘˜çš„åŒºåŸŸ
                    person_region_data = product_shipping[product_shipping['ç”³è¯·äºº'] == main_person]['æ‰€å±åŒºåŸŸ']
                    if not person_region_data.empty:
                        person_region = person_region_data.iloc[0]
                        return person_region, main_person

        # ä»é¢„æµ‹æ•°æ®ä¸­æ‰¾è´£ä»»äºº
        if forecast_data is not None and not forecast_data.empty:
            product_forecast = forecast_data[forecast_data['äº§å“ä»£ç '] == product_code]
            if not product_forecast.empty:
                forecast_person = product_forecast['é”€å”®å‘˜'].iloc[0]
                forecast_region = product_forecast['æ‰€å±å¤§åŒº'].iloc[0]
                return forecast_region, forecast_person

        return default_region, default_person

    except Exception:
        logger.exception("åˆ†æè´£ä»»å½’å±æ—¶å‡ºé”™")
        return "æœªçŸ¥åŒºåŸŸ", "ç³»ç»Ÿç®¡ç†å‘˜"


def generate_recommendation_for_inventory(risk_level, batch_age, days_to_clear):
    """ç”Ÿæˆåº“å­˜å»ºè®®æªæ–½"""
    if risk_level == "æé«˜é£é™©":
        return "ç´§æ€¥æ¸…ç†ï¼šè€ƒè™‘æŠ˜ä»·ä¿ƒé”€æˆ–è½¬ä»“"
    elif risk_level == "é«˜é£é™©":
        return "ä¼˜å…ˆå¤„ç†ï¼šä¿ƒé”€æˆ–åŠ å¤§è¥é”€åŠ›åº¦"
    elif risk_level == "ä¸­é£é™©":
        return "å¯†åˆ‡ç›‘æ§ï¼šè°ƒæ•´é‡‡è´­è®¡åˆ’"
    elif risk_level == "ä½é£é™©":
        return "å¸¸è§„ç®¡ç†ï¼šå®šæœŸæ£€æŸ¥åº“å­˜çŠ¶æ€"
    else:
        return "ç»´æŒç°çŠ¶ï¼šæ­£å¸¸åº“å­˜æ°´å¹³"


def determine_stocking_reasons(batch_age, volatility, forecast_bias):
    """ç¡®å®šç§¯å‹åŸå› """
    reasons = []
    if batch_age > 60:
        reasons.append("åº“é¾„è¿‡é•¿")
    if volatility > 1.0:
        reasons.append("é”€é‡æ³¢åŠ¨å¤§")
    if abs(forecast_bias) > 0.3:
        reasons.append("é¢„æµ‹åå·®å¤§")
    if not reasons:
        reasons.append("æ­£å¸¸åº“å­˜")
    return "ï¼Œ".join(reasons)


# ==================== 6. å›¾è¡¨åˆ›å»ºå‡½æ•° - ä¼˜åŒ–é‡ç»„ç‰ˆ ====================
def create_risk_overview_chart(analysis_result):
    """åˆ›å»ºé£é™©æ¦‚è§ˆå›¾è¡¨ - å°†åº“å­˜å¥åº·å’Œé£é™©åˆ†å¸ƒæ•´åˆä¸ºä¸€ä¸ªå›¾"""
    if not analysis_result:
        return None

    # é£é™©ç­‰çº§åˆ†å¸ƒ
    risk_dist = analysis_result.get('risk_distribution', {})

    if not risk_dist:
        return None

    # ç¡®ä¿æŒ‰é£é™©ç­‰çº§æ’åº
    risk_order = ['æé«˜é£é™©', 'é«˜é£é™©', 'ä¸­é£é™©', 'ä½é£é™©', 'æä½é£é™©']
    ordered_risk = {k: risk_dist.get(k, 0) for k in risk_order if k in risk_dist}

    # åˆ›å»ºé¥¼å›¾
    risk_fig = go.Figure()

    # æ·»åŠ é£é™©ç¯å½¢å›¾
    risk_fig.add_trace(go.Pie(
        labels=list(ordered_risk.keys()),
        values=list(ordered_risk.values()),
        marker_colors=[INVENTORY_RISK_COLORS.get(level, COLORS['gray']) for level in ordered_risk.keys()],
        textposition='inside',
        textinfo='percent+label',
        hole=0.6,
        hovertemplate='<b>%{label}</b><br>æ‰¹æ¬¡æ•°é‡: %{value}<br>å æ¯”: %{percent}<extra></extra>',
        domain={'x': [0, 1], 'y': [0, 1]},
        sort=False  # ä¿æŒè‡ªå®šä¹‰æ’åº
    ))

    # åœ¨ä¸­å¿ƒæ·»åŠ æ€»æ‰¹æ¬¡æ•°é‡
    total_batches = sum(ordered_risk.values())
    high_risk_count = ordered_risk.get('æé«˜é£é™©', 0) + ordered_risk.get('é«˜é£é™©', 0)
    high_risk_pct = high_risk_count / total_batches * 100 if total_batches > 0 else 0

    risk_fig.add_annotation(
        x=0.5, y=0.5,
        text=f"<b>æ€»æ‰¹æ¬¡: {total_batches}</b><br>é«˜é£é™©: {format_percentage(high_risk_pct)}",
        font=dict(size=14, color=COLORS['primary']),
        showarrow=False
    )

    risk_fig.update_layout(
        title={
            'text': "<b>åº“å­˜é£é™©åˆ†å¸ƒ</b><br><span style='font-size:12px;font-weight:normal'>æŒ‰é£é™©ç­‰çº§åˆ’åˆ†çš„æ‰¹æ¬¡æ•°é‡</span>",
            'y': 0.95,
            'x': 0.5,
            'xanchor': 'center',
            'yanchor': 'top'
        },
        height=400,
        plot_bgcolor='white',
        title_font=dict(size=16, color=COLORS['primary']),
        showlegend=True,
        legend=dict(
            orientation='h',
            yanchor='bottom',
            y=-0.1,
            xanchor='center',
            x=0.5
        )
    )

    return risk_fig


def create_combined_risk_chart(batch_analysis):
    """åˆ›å»ºç»¼åˆé£é™©åˆ†æå›¾è¡¨ - æ•´åˆåº“é¾„å’Œä»·å€¼åˆ†æ"""
    if batch_analysis is None or batch_analysis.empty:
        return None

    # é€‰å–é«˜é£é™©å’Œæé«˜é£é™©æ‰¹æ¬¡
    high_risk_batches = batch_analysis[batch_analysis['é£é™©ç¨‹åº¦'].isin(['æé«˜é£é™©', 'é«˜é£é™©'])]

    if high_risk_batches.empty:
        return None

    # æŒ‰åº“é¾„æ’åºï¼Œé€‰æ‹©å‰15ä¸ªæœ€è€æ‰¹æ¬¡
    top_batches = high_risk_batches.sort_values('åº“é¾„', ascending=False).head(15)

    # åˆ›å»ºå›¾è¡¨ - ä½¿ç”¨æ•£ç‚¹å›¾ï¼Œå¤§å°è¡¨ç¤ºæ‰¹æ¬¡ä»·å€¼ï¼Œé¢œè‰²è¡¨ç¤ºé£é™©ç­‰çº§
    risk_fig = go.Figure()

    # ä¸ºæ¯ä¸ªé£é™©ç­‰çº§åˆ†åˆ«æ·»åŠ æ•£ç‚¹
    for risk_level in ['æé«˜é£é™©', 'é«˜é£é™©']:
        risk_data = top_batches[top_batches['é£é™©ç¨‹åº¦'] == risk_level]
        if not risk_data.empty:
            # è®¡ç®—æ•£ç‚¹å¤§å° - åŸºäºæ‰¹æ¬¡ä»·å€¼çš„æ­£è§„åŒ–
            if risk_data['æ‰¹æ¬¡ä»·å€¼'].max() > 0:
                size_scale = risk_data['æ‰¹æ¬¡ä»·å€¼'] / risk_data['æ‰¹æ¬¡ä»·å€¼'].max() * 40 + 10
            else:
                size_scale = 15

            risk_fig.add_trace(go.Scatter(
                x=risk_data['åº“é¾„'],
                y=risk_data['é¢„è®¡æ¸…åº“å¤©æ•°'],
                mode='markers',
                marker=dict(
                    size=size_scale,
                    color=INVENTORY_RISK_COLORS.get(risk_level),
                    opacity=0.7,
                    line=dict(width=1, color='white')
                ),
                name=risk_level,
                text=risk_data['äº§å“ç®€åŒ–åç§°'],
                customdata=risk_data[['æ‰¹æ¬¡ä»·å€¼', 'è´£ä»»äºº', 'å»ºè®®æªæ–½']],
                hovertemplate='<b>%{text}</b><br>åº“é¾„: %{x}å¤©<br>æ¸…åº“å¤©æ•°: %{y}å¤©<br>æ‰¹æ¬¡ä»·å€¼: Â¥%{customdata[0]:.2f}<br>è´£ä»»äºº: %{customdata[1]}<br>å»ºè®®: %{customdata[2]}<extra></extra>'
            ))

    # æ·»åŠ å‚è€ƒçº¿
    risk_fig.add_shape(
        type="line", x0=90, x1=90, y0=0, y1=top_batches['é¢„è®¡æ¸…åº“å¤©æ•°'].max() * 1.1,
        line=dict(color=COLORS['danger'], dash="dash", width=2)
    )
    risk_fig.add_shape(
        type="line", x0=60, x1=60, y0=0, y1=top_batches['é¢„è®¡æ¸…åº“å¤©æ•°'].max() * 1.1,
        line=dict(color=COLORS['warning'], dash="dash", width=1.5)
    )

    # æ·»åŠ å‚è€ƒçº¿è¯´æ˜
    risk_fig.add_annotation(
        x=90, y=top_batches['é¢„è®¡æ¸…åº“å¤©æ•°'].max() * 1.05,
        text="é«˜é£é™©åº“é¾„(90å¤©)",
        showarrow=False,
        font=dict(size=10, color=COLORS['danger']),
        xanchor="center",
        yanchor="bottom"
    )

    risk_fig.add_annotation(
        x=60, y=top_batches['é¢„è®¡æ¸…åº“å¤©æ•°'].max() * 1.05,
        text="ä¸­é£é™©åº“é¾„(60å¤©)",
        showarrow=False,
        font=dict(size=10, color=COLORS['warning']),
        xanchor="center",
        yanchor="bottom"
    )

    # æ·»åŠ å›¾è¡¨è¯´æ˜
    risk_fig.update_layout(
        title={
            'text': "<b>é«˜é£é™©æ‰¹æ¬¡åˆ†æ</b><br><span style='font-size:12px;font-weight:normal'>åº“é¾„ vs æ¸…åº“å¤©æ•°ï¼Œæ°”æ³¡å¤§å°è¡¨ç¤ºæ‰¹æ¬¡ä»·å€¼</span>",
            'y': 0.95,
            'x': 0.5,
            'xanchor': 'center',
            'yanchor': 'top'
        },
        height=500,
        plot_bgcolor='white',
        title_font=dict(size=16, color=COLORS['primary']),
        xaxis_title="æ‰¹æ¬¡åº“é¾„ï¼ˆå¤©ï¼‰",
        yaxis_title="é¢„è®¡æ¸…åº“å¤©æ•°ï¼ˆå¤©ï¼‰",
        xaxis=dict(
            showgrid=True,
            gridcolor='rgba(0,0,0,0.1)',
            zeroline=False,
            title_font=dict(size=12),
            tickfont=dict(size=10)
        ),
        yaxis=dict(
            showgrid=True,
            gridcolor='rgba(0,0,0,0.1)',
            zeroline=False,
            title_font=dict(size=12),
            tickfont=dict(size=10)
        ),
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1,
            font=dict(size=10)
        ),
        margin=dict(l=20, r=20, t=100, b=80)
    )

    return risk_fig


def create_responsibility_tree_chart(batch_analysis):
    """åˆ›å»ºè´£ä»»å½’å±æ ‘çŠ¶å›¾ - æ›¿ä»£åˆ†ç¦»çš„è´£ä»»å›¾è¡¨"""
    if batch_analysis is None or batch_analysis.empty:
        return None

    # æ•´åˆæ•°æ® - æŒ‰åŒºåŸŸã€è´£ä»»äººå’Œé£é™©ç¨‹åº¦ç»Ÿè®¡æ‰¹æ¬¡ä»·å€¼
    aggregated_data = batch_analysis.groupby(['è´£ä»»åŒºåŸŸ', 'è´£ä»»äºº', 'é£é™©ç¨‹åº¦'])['æ‰¹æ¬¡ä»·å€¼'].sum().reset_index()

    # ç¡®ä¿æœ‰åŒºåŸŸä¿¡æ¯ - è¿‡æ»¤æ‰æœªçŸ¥åŒºåŸŸ
    aggregated_data = aggregated_data[
        (aggregated_data['è´£ä»»åŒºåŸŸ'].notna()) &
        (aggregated_data['è´£ä»»åŒºåŸŸ'] != 'æœªçŸ¥åŒºåŸŸ') &
        (aggregated_data['è´£ä»»äºº'].notna()) &
        (aggregated_data['è´£ä»»äºº'] != 'ç³»ç»Ÿç®¡ç†å‘˜')
        ]

    if aggregated_data.empty:
        return None

    # åˆ›å»ºæ ‘çŠ¶å›¾æ•°æ®
    risk_order = ["æé«˜é£é™©", "é«˜é£é™©", "ä¸­é£é™©", "ä½é£é™©", "æä½é£é™©"]

    # æ·»åŠ æ‰€æœ‰å±‚çº§
    labels = ['å…¨éƒ¨æ‰¹æ¬¡']
    parents = ['']
    values = [aggregated_data['æ‰¹æ¬¡ä»·å€¼'].sum()]
    colors = ['#FFFFFF']  # æ ¹èŠ‚ç‚¹é¢œè‰²

    # æ·»åŠ åŒºåŸŸå±‚çº§
    for region, group in aggregated_data.groupby('è´£ä»»åŒºåŸŸ'):
        labels.append(region)
        parents.append('å…¨éƒ¨æ‰¹æ¬¡')
        values.append(group['æ‰¹æ¬¡ä»·å€¼'].sum())
        colors.append(COLORS['primary'])

        # æ·»åŠ è´£ä»»äººå±‚çº§
        for person, person_group in group.groupby('è´£ä»»äºº'):
            person_id = f"{region} - {person}"
            labels.append(person_id)
            parents.append(region)
            values.append(person_group['æ‰¹æ¬¡ä»·å€¼'].sum())
            colors.append(COLORS['secondary'])

            # æ·»åŠ é£é™©ç­‰çº§å±‚çº§
            for risk in risk_order:
                risk_rows = person_group[person_group['é£é™©ç¨‹åº¦'] == risk]
                if not risk_rows.empty:
                    risk_id = f"{person_id} - {risk}"
                    labels.append(risk_id)
                    parents.append(person_id)
                    values.append(risk_rows['æ‰¹æ¬¡ä»·å€¼'].sum())
                    colors.append(INVENTORY_RISK_COLORS.get(risk, COLORS['gray']))

    # åˆ›å»ºæ ‘çŠ¶å›¾
    fig = go.Figure(go.Treemap(
        labels=labels,
        parents=parents,
        values=values,
        marker=dict(
            colors=colors,
            line=dict(width=1, color='white')
        ),
        textinfo="label+value+percent parent",
        hovertemplate='<b>%{label}</b><br>æ‰¹æ¬¡ä»·å€¼: Â¥%{value:,.2f}<br>å æ¯”: %{percentParent:.1%}<br>å æ€»ä½“: %{percentRoot:.1%}<extra></extra>',
        branchvalues="total"
    ))

    fig.update_layout(
        title={
            'text': "<b>è´£ä»»å½’å±åˆ†æ</b><br><span style='font-size:12px;font-weight:normal'>æŒ‰åŒºåŸŸã€è´£ä»»äººå’Œé£é™©ç­‰çº§çš„æ‰¹æ¬¡ä»·å€¼åˆ†å¸ƒ</span>",
            'y': 0.95,
            'x': 0.5,
            'xanchor': 'center',
            'yanchor': 'top'
        },
        height=600,
        plot_bgcolor='white',
        title_font=dict(size=16, color=COLORS['primary']),
        margin=dict(l=20, r=20, t=80, b=20)
    )

    return fig


def create_forecast_impact_chart(batch_analysis):
    """åˆ›å»ºé¢„æµ‹å½±å“ç»¼åˆå›¾è¡¨ - æ•´åˆæ¸…åº“é¢„æµ‹å’Œé¢„æµ‹åå·®åˆ†æ"""
    if batch_analysis is None or batch_analysis.empty:
        return None

    # å¤„ç†é¢„æµ‹åå·®æ•°æ®
    batch_analysis_copy = batch_analysis.copy()
    batch_analysis_copy['é¢„æµ‹åå·®å€¼'] = batch_analysis_copy['é¢„æµ‹åå·®'].apply(
        lambda x: float(x.rstrip('%')) / 100 if isinstance(x, str) and '%' in x and x != 'å¼‚å¸¸' else 0
    )

    # ç­›é€‰æœ‰æ•ˆæ•°æ®
    valid_forecast = batch_analysis_copy[
        (abs(batch_analysis_copy['é¢„æµ‹åå·®å€¼']) <= 1.0) &
        (batch_analysis_copy['é¢„è®¡æ¸…åº“å¤©æ•°'] != float('inf'))
        ]

    if valid_forecast.empty or len(valid_forecast) < 3:
        return None

    # é€‰æ‹©é¢„æµ‹åå·®è¾ƒå¤§çš„æ‰¹æ¬¡
    significant_bias = valid_forecast.sort_values('é¢„æµ‹åå·®å€¼', key=abs, ascending=False).head(20)

    # åˆ›å»ºå›¾è¡¨
    fig = go.Figure()

    # åˆ›å»ºæ•£ç‚¹å›¾ï¼Œä½¿ç”¨æ¡ä»¶é¢œè‰²æ˜ å°„
    fig.add_trace(go.Scatter(
        x=significant_bias['é¢„æµ‹åå·®å€¼'] * 100,  # è½¬ä¸ºç™¾åˆ†æ¯”æ˜¾ç¤º
        y=significant_bias['é¢„è®¡æ¸…åº“å¤©æ•°'],
        mode='markers',
        marker=dict(
            size=significant_bias['æ‰¹æ¬¡ä»·å€¼'] / significant_bias['æ‰¹æ¬¡ä»·å€¼'].max() * 30 + 10,
            color=significant_bias['é¢„æµ‹åå·®å€¼'] * 100,
            colorscale=[
                [0.0, '#1565C0'],  # æ·±è“è‰² - é¢„æµ‹ä¸è¶³
                [0.5, '#FFFFFF'],  # ç™½è‰² - é¢„æµ‹å‡†ç¡®
                [1.0, '#C62828']  # æ·±çº¢è‰² - é¢„æµ‹è¿‡é«˜
            ],
            colorbar=dict(
                title="é¢„æµ‹åå·® (%)",
                titleside="right",
                tickmode="array",
                tickvals=[-100, -50, 0, 50, 100],
                ticktext=["-100%", "-50%", "0%", "50%", "100%"],
                ticks="outside"
            ),
            line=dict(width=1, color='white')
        ),
        text=significant_bias['äº§å“ç®€åŒ–åç§°'],
        customdata=significant_bias[['æ‰¹æ¬¡ä»·å€¼', 'è´£ä»»äºº', 'é£é™©ç¨‹åº¦', 'åº“é¾„']],
        hovertemplate='<b>%{text}</b><br>é¢„æµ‹åå·®: %{x:.1f}%<br>æ¸…åº“å¤©æ•°: %{y:.1f}å¤©<br>æ‰¹æ¬¡ä»·å€¼: Â¥%{customdata[0]:.2f}<br>è´£ä»»äºº: %{customdata[1]}<br>é£é™©ç¨‹åº¦: %{customdata[2]}<br>åº“é¾„: %{customdata[3]}å¤©<extra></extra>'
    ))

    # æ·»åŠ å‚è€ƒçº¿
    fig.add_shape(
        type="line", x0=0, x1=0,
        y0=0, y1=significant_bias['é¢„è®¡æ¸…åº“å¤©æ•°'].max() * 1.1,
        line=dict(color=COLORS['gray'], dash="dash", width=1)
    )

    fig.add_shape(
        type="line", x0=significant_bias['é¢„æµ‹åå·®å€¼'].min() * 100 * 1.1,
        x1=significant_bias['é¢„æµ‹åå·®å€¼'].max() * 100 * 1.1,
        y0=90, y1=90,
        line=dict(color=COLORS['danger'], dash="dash", width=1)
    )

    # æ·»åŠ åŒºåŸŸæ ‡æ³¨
    fig.add_annotation(
        x=50,
        y=significant_bias['é¢„è®¡æ¸…åº“å¤©æ•°'].max() * 0.75,
        text="é¢„æµ‹è¿‡é«˜<br>åº“å­˜ç§¯å‹é£é™©",
        showarrow=False,
        font=dict(size=12, color=COLORS['danger']),
        align="center",
        bgcolor="rgba(255,255,255,0.8)",
        bordercolor=COLORS['danger'],
        borderwidth=1,
        borderpad=4
    )

    fig.add_annotation(
        x=-50,
        y=significant_bias['é¢„è®¡æ¸…åº“å¤©æ•°'].max() * 0.75,
        text="é¢„æµ‹è¿‡ä½<br>ç¼ºè´§é£é™©",
        showarrow=False,
        font=dict(size=12, color=COLORS['primary']),
        align="center",
        bgcolor="rgba(255,255,255,0.8)",
        bordercolor=COLORS['primary'],
        borderwidth=1,
        borderpad=4
    )

    # ä¼˜åŒ–å›¾è¡¨å¸ƒå±€
    fig.update_layout(
        title={
            'text': "<b>é¢„æµ‹åå·®å¯¹åº“å­˜çš„å½±å“</b><br><span style='font-size:12px;font-weight:normal'>æ°”æ³¡å¤§å°è¡¨ç¤ºæ‰¹æ¬¡ä»·å€¼ï¼Œé¢œè‰²è¡¨ç¤ºé¢„æµ‹åå·®</span>",
            'y': 0.95,
            'x': 0.5,
            'xanchor': 'center',
            'yanchor': 'top'
        },
        height=550,
        plot_bgcolor='white',
        title_font=dict(size=16, color=COLORS['primary']),
        xaxis_title="é¢„æµ‹åå·® (%)",
        yaxis_title="é¢„è®¡æ¸…åº“å¤©æ•°",
        xaxis=dict(
            showgrid=True,
            gridcolor='rgba(0,0,0,0.1)',
            zeroline=False,
            title_font=dict(size=12),
            tickfont=dict(size=10),
            range=[significant_bias['é¢„æµ‹åå·®å€¼'].min() * 100 * 1.1,
                   significant_bias['é¢„æµ‹åå·®å€¼'].max() * 100 * 1.1]
        ),
        yaxis=dict(
            showgrid=True,
            gridcolor='rgba(0,0,0,0.1)',
            zeroline=False,
            title_font=dict(size=12),
            tickfont=dict(size=10)
        ),
        margin=dict(l=20, r=20, t=100, b=50)
    )

    return fig


def create_batch_risk_heatmap(data):
    """åˆ›å»ºæ‰¹æ¬¡é£é™©çƒ­åŠ›å›¾ï¼Œç”¨äºæ›¿ä»£è¯¦ç»†æ•°æ®è¡¨ - ä¼˜åŒ–ç‰ˆ"""
    if data is None or data.empty:
        return None

    # å‡†å¤‡çƒ­åŠ›å›¾æ•°æ®
    risk_order = ["æé«˜é£é™©", "é«˜é£é™©", "ä¸­é£é™©", "ä½é£é™©", "æä½é£é™©"]

    # æŒ‰äº§å“å’Œé£é™©ç¨‹åº¦åˆ†ç»„
    grouped_data = data.groupby(['äº§å“ç®€åŒ–åç§°', 'é£é™©ç¨‹åº¦']).agg({
        'æ‰¹æ¬¡ä»·å€¼': 'sum',
        'æ‰¹æ¬¡åº“å­˜': 'sum',
        'åº“é¾„': 'mean',
        'é¢„è®¡æ¸…åº“å¤©æ•°': 'mean'
    }).reset_index()

    # åˆ›å»ºçƒ­åŠ›å›¾
    pivot_data = pd.pivot_table(
        grouped_data,
        values='æ‰¹æ¬¡ä»·å€¼',
        index='äº§å“ç®€åŒ–åç§°',
        columns='é£é™©ç¨‹åº¦',
        aggfunc='sum',
        fill_value=0
    )

    # ç¡®ä¿æ‰€æœ‰é£é™©çº§åˆ«çš„åˆ—éƒ½å­˜åœ¨
    for risk in risk_order:
        if risk not in pivot_data.columns:
            pivot_data[risk] = 0

    # æŒ‰ç…§é£é™©é¡ºåºæ’åˆ—åˆ—
    for col in risk_order:
        if col not in pivot_data.columns:
            pivot_data[col] = 0
    pivot_data = pivot_data[risk_order]

    # è®¡ç®—æ¯è¡Œ(äº§å“)çš„æ€»å’Œï¼Œå¹¶æŒ‰æ€»å’Œæ’åº
    pivot_data['æ€»ä»·å€¼'] = pivot_data.sum(axis=1)
    pivot_data = pivot_data.sort_values('æ€»ä»·å€¼', ascending=False)
    pivot_data = pivot_data.drop('æ€»ä»·å€¼', axis=1)

    # é™åˆ¶æ˜¾ç¤ºå‰15ä¸ªäº§å“
    pivot_data = pivot_data.head(15)

    # ç¡®ä¿æ•°æ®ä¸ä¸ºç©º
    if pivot_data.empty or pivot_data.sum().sum() == 0:
        return None

    # åˆ›å»ºçƒ­åŠ›å›¾
    fig = go.Figure(data=go.Heatmap(
        z=pivot_data.values,
        x=pivot_data.columns,
        y=pivot_data.index,
        colorscale=[
            [0, 'rgb(247, 251, 255)'],  # æ¥è¿‘ç™½è‰²
            [0.1, 'rgb(198, 219, 239)'],
            [0.3, 'rgb(107, 174, 214)'],
            [0.5, 'rgb(33, 113, 181)'],
            [0.8, 'rgb(8, 48, 107)'],
            [1, 'rgb(8, 29, 88)']  # æ·±è“è‰²
        ],
        showscale=True,
        colorbar=dict(title="æ‰¹æ¬¡ä»·å€¼"),
        text=[[format_currency(val) for val in row] for row in pivot_data.values],
        hovertemplate='<b>äº§å“: %{y}</b><br>é£é™©ç­‰çº§: %{x}<br>æ‰¹æ¬¡ä»·å€¼: %{text}<extra></extra>'
    ))

    fig.update_layout(
        title={
            'text': "<b>æ‰¹æ¬¡é£é™©åˆ†å¸ƒçƒ­åŠ›å›¾</b><br><span style='font-size:12px;font-weight:normal'>å„äº§å“åœ¨ä¸åŒé£é™©ç­‰çº§ä¸‹çš„æ‰¹æ¬¡ä»·å€¼åˆ†å¸ƒ</span>",
            'y': 0.95,
            'x': 0.5,
            'xanchor': 'center',
            'yanchor': 'top'
        },
        height=600,
        plot_bgcolor='white',
        title_font=dict(size=16, color=COLORS['primary']),
        xaxis_title="é£é™©ç­‰çº§",
        yaxis_title="äº§å“",
        xaxis=dict(
            tickangle=-30,
            categoryorder='array',
            categoryarray=risk_order,
            title_font=dict(size=12),
            tickfont=dict(size=10)
        ),
        yaxis=dict(
            title_font=dict(size=12),
            tickfont=dict(size=10)
        ),
        margin=dict(l=20, r=20, t=100, b=50)
    )

    return fig


def create_top_high_risk_product_chart(data):
    """åˆ›å»ºé«˜é£é™©äº§å“Topå›¾è¡¨"""
    if data is None or data.empty:
        return None

    # é€‰æ‹©é«˜é£é™©å’Œæé«˜é£é™©æ‰¹æ¬¡
    high_risk_data = data[data['é£é™©ç¨‹åº¦'].isin(['æé«˜é£é™©', 'é«˜é£é™©'])]

    if high_risk_data.empty:
        return None

    # æŒ‰äº§å“åˆ†ç»„è®¡ç®—æ€»ä»·å€¼å’Œå¹³å‡åº“é¾„
    product_summary = high_risk_data.groupby('äº§å“ç®€åŒ–åç§°').agg({
        'æ‰¹æ¬¡ä»·å€¼': 'sum',
        'åº“é¾„': 'mean',
        'æ‰¹æ¬¡åº“å­˜': 'sum',
        'é£é™©ç¨‹åº¦': lambda x: 'æé«˜é£é™©' if 'æé«˜é£é™©' in x.values else 'é«˜é£é™©'
    }).reset_index()

    # å–ä»·å€¼æœ€é«˜çš„10ä¸ªäº§å“
    top_products = product_summary.sort_values('æ‰¹æ¬¡ä»·å€¼', ascending=False).head(10)

    if top_products.empty:
        return None

    # åˆ›å»ºæ¡å½¢å›¾
    fig = go.Figure()

    # æŒ‰é£é™©ç¨‹åº¦åˆ†åˆ«æ·»åŠ æ¡å½¢
    for risk in ['æé«˜é£é™©', 'é«˜é£é™©']:
        risk_products = top_products[top_products['é£é™©ç¨‹åº¦'] == risk]
        if not risk_products.empty:
            fig.add_trace(go.Bar(
                y=risk_products['äº§å“ç®€åŒ–åç§°'],
                x=risk_products['æ‰¹æ¬¡ä»·å€¼'],
                orientation='h',
                name=risk,
                marker_color=INVENTORY_RISK_COLORS.get(risk),
                text=risk_products['æ‰¹æ¬¡ä»·å€¼'].apply(format_currency),
                textposition='outside',
                customdata=risk_products[['åº“é¾„', 'æ‰¹æ¬¡åº“å­˜']],
                hovertemplate='<b>%{y}</b><br>æ‰¹æ¬¡ä»·å€¼: %{text}<br>å¹³å‡åº“é¾„: %{customdata[0]:.1f}å¤©<br>åº“å­˜é‡: %{customdata[1]:.0f}ç®±<br>é£é™©çº§åˆ«: ' + risk + '<extra></extra>'
            ))

    # ä¼˜åŒ–å›¾è¡¨å¸ƒå±€
    fig.update_layout(
        title={
            'text': "<b>é«˜é£é™©äº§å“Top10</b><br><span style='font-size:12px;font-weight:normal'>æŒ‰æ‰¹æ¬¡ä»·å€¼æ’åºçš„é«˜é£é™©/æé«˜é£é™©äº§å“</span>",
            'y': 0.95,
            'x': 0.5,
            'xanchor': 'center',
            'yanchor': 'top'
        },
        height=500,
        plot_bgcolor='white',
        title_font=dict(size=16, color=COLORS['primary']),
        xaxis_title="æ‰¹æ¬¡ä»·å€¼ï¼ˆå…ƒï¼‰",
        yaxis_title="äº§å“",
        xaxis=dict(
            showgrid=True,
            gridcolor='rgba(0,0,0,0.1)',
            zeroline=False,
            title_font=dict(size=12),
            tickfont=dict(size=10)
        ),
        yaxis=dict(
            autorange="reversed",  # ä»å¤§åˆ°å°æ˜¾ç¤º
            title_font=dict(size=12),
            tickfont=dict(size=10),
            categoryorder='total ascending'
        ),
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1,
            font=dict(size=10)
        ),
        margin=dict(l=20, r=20, t=100, b=50)
    )

    return fig


# ==================== 7. è¿½åŠ è·³è½¬åˆ°æ ‡ç­¾é¡µçš„è¾…åŠ©å‡½æ•° - ä¼˜åŒ–ç‰ˆ ====================
def navigate_to_tab(tab_index):
    """è·³è½¬åˆ°æŒ‡å®šçš„æ ‡ç­¾é¡µ"""
    if 'active_tab' not in st.session_state:
        st.session_state.active_tab = 0
    st.session_state.active_tab = tab_index


# ==================== 8. ä¸»é¡µé¢é€»è¾‘ - ä¼˜åŒ–é‡ç»„ç‰ˆ ====================
def main():
    """ä¸»é¡µé¢å‡½æ•°"""
    # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²ç™»å½•
    if 'authenticated' not in st.session_state or not st.session_state.authenticated:
        st.warning("è¯·å…ˆç™»å½•ç³»ç»Ÿ")
        st.stop()

    # æ•°æ®æ–‡ä»¶æœç´¢å¼€å…³
    if 'show_data_search' not in st.session_state:
        st.session_state.show_data_search = False

    # æ˜¾ç¤ºæ•°æ®æ–‡ä»¶æœç´¢è¯¦æƒ…
    show_data_search = st.sidebar.checkbox("æ˜¾ç¤ºæ•°æ®æ–‡ä»¶æœç´¢è¯¦æƒ…", value=st.session_state.show_data_search)
    if show_data_search != st.session_state.show_data_search:
        st.session_state.show_data_search = show_data_search
        st.rerun()

    # åŠ è½½åº“å­˜æ•°æ®
    data = load_and_process_inventory_data(show_details=st.session_state.show_data_search)

    if data is None:
        st.error("æ— æ³•åŠ è½½åº“å­˜æ•°æ®ï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶")
        st.markdown("""
        <div class="error-box">
            <h3>æ•°æ®åŠ è½½å¤±è´¥</h3>
            <p>è¯·ç¡®ä¿ä»¥ä¸‹æ•°æ®æ–‡ä»¶å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®ï¼š</p>
            <ul>
                <li>å«æ‰¹æ¬¡åº“å­˜æ–‡ä»¶ (Excelæ ¼å¼)</li>
                <li>å‡ºè´§æ•°æ®æ–‡ä»¶ (Excelæ ¼å¼)</li>
                <li>é¢„æµ‹æ•°æ®æ–‡ä»¶ (Excelæ ¼å¼)</li>
                <li>å•ä»·æ•°æ®æ–‡ä»¶ (Excelæ ¼å¼)</li>
            </ul>
            <p>æ–‡ä»¶åº”ä½äºåº”ç”¨ç›®å½•ã€pageså­ç›®å½•æˆ–dataå­ç›®å½•ä¸­ã€‚</p>
        </div>
        """, unsafe_allow_html=True)
        return

    # åº”ç”¨ç­›é€‰
    filtered_data = create_inventory_filters(data)

    if 'analysis_result' not in filtered_data:
        st.error("æ•°æ®åˆ†æå¤±è´¥")
        return

    analysis_result = filtered_data['analysis_result']
    batch_analysis = analysis_result.get('batch_analysis')

    # åˆå§‹åŒ–æ´»åŠ¨æ ‡ç­¾é¡µ
    if 'active_tab' not in st.session_state:
        st.session_state.active_tab = 0

    # åˆ›å»ºæ ‡ç­¾é¡µ - ä¼˜åŒ–ç‰ˆï¼ˆå‡å°‘ä¸º4ä¸ªæ ‡ç­¾é¡µï¼‰
    tab_titles = [
        "ğŸ“Š åº“å­˜æ€»è§ˆä¸é£é™©",
        "âš ï¸ é«˜é£é™©æ‰¹æ¬¡åˆ†æ",
        "ğŸ‘¥ è´£ä»»å½’å±åˆ†æ",
        "ğŸ“ˆ é¢„æµ‹ä¸æ¸…åº“åˆ†æ"
    ]

    tabs = st.tabs(tab_titles)

    # æ·»åŠ æ—¶é—´ç»´åº¦è¯´æ˜
    time_dimensions = {
        "åº“é¾„": "åŸºäºæ‰¹æ¬¡ç”Ÿäº§æ—¥æœŸåˆ°å½“å‰æ—¥æœŸè®¡ç®—",
        "åº“å­˜å‘¨è½¬ç‡": "åŸºäºè¿‡å»90å¤©çš„é”€å”®æ•°æ®è®¡ç®—",
        "é¢„æµ‹åå·®": "åŸºäºæœ€è¿‘30å¤©çš„é”€å”®æ•°æ®ä¸é¢„æµ‹æ¯”è¾ƒ",
        "å‘†æ»åº“å­˜": f"åº“é¾„è¶…è¿‡{INVENTORY_CONFIG['stagnant_days_threshold']}å¤©çš„æ‰¹æ¬¡",
    }

    # æ˜¾ç¤ºæ´»åŠ¨æ ‡ç­¾é¡µ
    active_tab_index = min(st.session_state.active_tab, len(tabs) - 1)

    with tabs[0]:  # æ€»è§ˆä¸å…³é”®æŒ‡æ ‡
        if active_tab_index == 0:
            st.markdown('<div class="sub-header">ğŸ“Š åº“å­˜å…³é”®æŒ‡æ ‡</div>', unsafe_allow_html=True)

            # æ·»åŠ æ—¶é—´ç»´åº¦è¯´æ˜
            st.markdown(f'''
            <div class="time-dim-note">
            ğŸ“… <b>æ—¶é—´ç»´åº¦è¯´æ˜</b>: {time_dimensions["åº“é¾„"]}ï¼›{time_dimensions["åº“å­˜å‘¨è½¬ç‡"]}ï¼›
            {time_dimensions["é¢„æµ‹åå·®"]}ï¼›{time_dimensions["å‘†æ»åº“å­˜"]}
            </div>
            ''', unsafe_allow_html=True)

            # å…³é”®æŒ‡æ ‡è¡Œ - æ–°å¢åº“å­˜å‘¨è½¬å¤©æ•°å’Œå‘†æ»åº“å­˜æ¯”ä¾‹
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                # åº“å­˜å‘¨è½¬å¤©æ•° - æ ¸å¿ƒæŒ‡æ ‡
                turnover_days = analysis_result.get('inventory_turnover_days', float('inf'))
                turnover_days_display = format_days(turnover_days)
                turnover_color = COLORS['success'] if turnover_days < 60 else (
                    COLORS['warning'] if turnover_days < 90 else COLORS['danger'])

                # æ·»åŠ è·³è½¬åˆ°æ¸…åº“é¢„æµ‹åˆ†æçš„æŒ‰é’® - ä½¿ç”¨æ”¹è¿›çš„æ–¹å¼
                st.markdown(f"""
                <div class="metric-card">
                    <p class="card-header">åº“å­˜å‘¨è½¬å¤©æ•°</p>
                    <p class="card-value" style="color:{turnover_color};">{turnover_days_display}</p>
                    <p class="card-text">åº“å­˜æµè½¬é€Ÿåº¦æ ¸å¿ƒæŒ‡æ ‡</p>
                </div>
                """, unsafe_allow_html=True)

                if st.button("æŸ¥çœ‹æ¸…åº“åˆ†æ", key="view_turnover_details"):
                    st.session_state.active_tab = 3  # é¢„æµ‹ä¸æ¸…åº“åˆ†ææ ‡ç­¾é¡µ
                    st.rerun()

            with col2:
                # å‘†æ»åº“å­˜æ¯”ä¾‹ - æ–°å¢æ ¸å¿ƒæŒ‡æ ‡
                stagnant_ratio = analysis_result.get('stagnant_ratio', 0.0)
                stagnant_ratio_display = format_percentage(stagnant_ratio * 100)
                stagnant_color = COLORS['success'] if stagnant_ratio < 0.1 else (
                    COLORS['warning'] if stagnant_ratio < 0.3 else COLORS['danger'])

                # æ·»åŠ è·³è½¬åˆ°é£é™©æ‰¹æ¬¡åˆ†æçš„æŒ‰é’®
                st.markdown(f"""
                <div class="metric-card">
                    <p class="card-header">å‘†æ»åº“å­˜æ¯”ä¾‹</p>
                    <p class="card-value" style="color:{stagnant_color};">{stagnant_ratio_display}</p>
                    <p class="card-text">è¶…è¿‡60å¤©çš„åº“å­˜å æ¯”</p>
                </div>
                """, unsafe_allow_html=True)

                if st.button("æŸ¥çœ‹é£é™©åˆ†æ", key="view_stagnant_details"):
                    st.session_state.active_tab = 1  # é£é™©æ‰¹æ¬¡åˆ†ææ ‡ç­¾é¡µ
                    st.rerun()

            with col3:
                # é«˜é£é™©æ‰¹æ¬¡æ•°é‡
                risk_dist = analysis_result.get('risk_distribution', {})
                high_risk_count = risk_dist.get('æé«˜é£é™©', 0) + risk_dist.get('é«˜é£é™©', 0)
                total_batches = sum(risk_dist.values()) if risk_dist else 0
                high_risk_pct = (high_risk_count / total_batches * 100) if total_batches > 0 else 0

                st.markdown(f"""
                <div class="metric-card">
                    <p class="card-header">é«˜é£é™©æ‰¹æ¬¡æ•°é‡</p>
                    <p class="card-value" style="color:{COLORS['danger']};">{high_risk_count}</p>
                    <p class="card-text">å æ€»æ‰¹æ¬¡{format_percentage(high_risk_pct)}</p>
                </div>
                """, unsafe_allow_html=True)

                if st.button("æŸ¥çœ‹é«˜é£é™©æ‰¹æ¬¡", key="view_high_risk_details"):
                    st.session_state.active_tab = 1  # é£é™©æ‰¹æ¬¡åˆ†ææ ‡ç­¾é¡µ
                    st.rerun()

            with col4:
                # åº“å­˜èµ„é‡‘å ç”¨æˆæœ¬ - æ ¸å¿ƒæŒ‡æ ‡
                capital_cost = analysis_result.get('capital_cost', 0.0)
                total_value = analysis_result.get('total_inventory_value', 0.0)
                capital_cost_display = format_currency(capital_cost)

                st.markdown(f"""
                <div class="metric-card">
                    <p class="card-header">æœˆå‡èµ„é‡‘å ç”¨æˆæœ¬</p>
                    <p class="card-value">{capital_cost_display}</p>
                    <p class="card-text">æ€»ä»·å€¼: {format_currency(total_value)}</p>
                </div>
                """, unsafe_allow_html=True)

                if st.button("æŸ¥çœ‹è´£ä»»åˆ†æ", key="view_capital_cost_details"):
                    st.session_state.active_tab = 2  # è´£ä»»å½’å±åˆ†ææ ‡ç­¾é¡µ
                    st.rerun()

            # é£é™©æ¦‚è§ˆå›¾è¡¨
            st.markdown('<div class="sub-header">åº“å­˜é£é™©æ¦‚è§ˆ</div>', unsafe_allow_html=True)

            # åˆ›å»ºæ•´åˆåçš„é£é™©æ¦‚è§ˆå›¾
            risk_overview_fig = create_risk_overview_chart(analysis_result)

            if risk_overview_fig:
                st.plotly_chart(risk_overview_fig, use_container_width=True)
            else:
                display_empty_chart_message(
                    "æš‚æ— é£é™©åˆ†å¸ƒæ•°æ®",
                    "å½“å‰ç­›é€‰æ¡ä»¶ä¸‹æ— æ³•ç”Ÿæˆé£é™©åˆ†å¸ƒå›¾è¡¨ã€‚è¯·å°è¯•è°ƒæ•´ç­›é€‰æ¡ä»¶æˆ–æ£€æŸ¥æ•°æ®æºã€‚"
                )

            # é«˜é£é™©äº§å“Topå›¾è¡¨
            if batch_analysis is not None and not batch_analysis.empty:
                high_risk_products_fig = create_top_high_risk_product_chart(batch_analysis)

                if high_risk_products_fig:
                    st.plotly_chart(high_risk_products_fig, use_container_width=True)

                    # æ·»åŠ æ•°æ®æ´å¯Ÿ
                    high_risk_batches = batch_analysis[batch_analysis['é£é™©ç¨‹åº¦'].isin(['æé«˜é£é™©', 'é«˜é£é™©'])]
                    if not high_risk_batches.empty:
                        # è·å–ä¸»è¦ç§¯å‹åŸå› 
                        stocking_reasons = []
                        for reason in high_risk_batches['ç§¯å‹åŸå› ']:
                            if pd.notna(reason):
                                for r in reason.split('ï¼Œ'):
                                    stocking_reasons.append(r)

                        from collections import Counter
                        reason_counts = Counter(stocking_reasons)
                        top_reasons = reason_counts.most_common(2)
                        reasons_text = f"{top_reasons[0][0]} ({top_reasons[0][1]}æ¬¡)"
                        if len(top_reasons) > 1:
                            reasons_text += f" å’Œ {top_reasons[1][0]} ({top_reasons[1][1]}æ¬¡)"

                        # è·å–è´£ä»»äººå’ŒåŒºåŸŸä¿¡æ¯
                        top_region = high_risk_batches['è´£ä»»åŒºåŸŸ'].value_counts().index[0] if len(
                            high_risk_batches['è´£ä»»åŒºåŸŸ'].value_counts()) > 0 else "æœªçŸ¥"
                        top_person = high_risk_batches['è´£ä»»äºº'].value_counts().index[0] if len(
                            high_risk_batches['è´£ä»»äºº'].value_counts()) > 0 else "æœªçŸ¥"

                        # æ„å»ºæ´å¯Ÿæ–‡æœ¬
                        insight_text = f"<b>é£é™©æ´å¯Ÿï¼š</b> ä¸»è¦ç§¯å‹åŸå› ä¸º{reasons_text}ã€‚"
                        insight_text += f" {top_region}åŒºåŸŸå’Œ{top_person}æ˜¯é«˜é£é™©æ‰¹æ¬¡çš„ä¸»è¦è´£ä»»äººã€‚"
                        insight_text += f" å½“å‰å…±æœ‰{len(high_risk_batches)}ä¸ªé«˜é£é™©æ‰¹æ¬¡ï¼Œä»·å€¼{format_currency(high_risk_batches['æ‰¹æ¬¡ä»·å€¼'].sum())}ã€‚"
                        insight_text += "<br><b>å»ºè®®æªæ–½ï¼š</b> é’ˆå¯¹é«˜é£é™©æ‰¹æ¬¡å®æ–½æ¸…åº“è®¡åˆ’ï¼Œé‡ç‚¹å…³æ³¨åº“é¾„è¶…è¿‡90å¤©çš„æ‰¹æ¬¡ï¼›æ”¹è¿›éœ€æ±‚é¢„æµ‹å‡†ç¡®æ€§ï¼Œå‡å°‘åº“å­˜ç§¯å‹ã€‚"

                        add_chart_explanation(insight_text)

            else:
                display_empty_chart_message(
                    "æš‚æ— é«˜é£é™©äº§å“æ•°æ®",
                    "å½“å‰ç­›é€‰æ¡ä»¶ä¸‹æ— æ³•ç”Ÿæˆé«˜é£é™©äº§å“å›¾è¡¨ã€‚è¯·å°è¯•è°ƒæ•´ç­›é€‰æ¡ä»¶æˆ–æ£€æŸ¥æ•°æ®æºã€‚"
                )

    with tabs[1]:  # é«˜é£é™©æ‰¹æ¬¡åˆ†æ
        if active_tab_index == 1:
            st.markdown('<div class="sub-header">âš ï¸ é«˜é£é™©æ‰¹æ¬¡åˆ†æ</div>', unsafe_allow_html=True)

            # æ·»åŠ æ—¶é—´ç»´åº¦è¯´æ˜
            st.markdown(f'''
            <div class="time-dim-note">
            ğŸ“… <b>æ—¶é—´ç»´åº¦è¯´æ˜</b>: {time_dimensions["åº“é¾„"]}ï¼›é£é™©è¯„ä¼°åŸºäºå½“å‰åº“é¾„ã€é”€å”®è¶‹åŠ¿å’Œé¢„æµ‹åå·®ç»¼åˆè®¡ç®—
            </div>
            ''', unsafe_allow_html=True)

            if batch_analysis is not None and not batch_analysis.empty:
                # é£é™©ç»Ÿè®¡ - ä½¿ç”¨å¡ç‰‡æ ·å¼
                col1, col2, col3 = st.columns(3)

                with col1:
                    extreme_high = len(batch_analysis[batch_analysis['é£é™©ç¨‹åº¦'] == 'æé«˜é£é™©'])
                    extreme_high_value = batch_analysis[batch_analysis['é£é™©ç¨‹åº¦'] == 'æé«˜é£é™©']['æ‰¹æ¬¡ä»·å€¼'].sum()

                    st.markdown(f"""
                    <div class="metric-card">
                        <p class="card-header">æé«˜é£é™©æ‰¹æ¬¡</p>
                        <p class="card-value" style="color: {INVENTORY_RISK_COLORS['æé«˜é£é™©']};">{extreme_high}</p>
                        <p class="card-text">ä»·å€¼: {format_currency(extreme_high_value)}</p>
                    </div>
                    """, unsafe_allow_html=True)

                with col2:
                    high_risk = len(batch_analysis[batch_analysis['é£é™©ç¨‹åº¦'] == 'é«˜é£é™©'])
                    high_risk_value = batch_analysis[batch_analysis['é£é™©ç¨‹åº¦'] == 'é«˜é£é™©']['æ‰¹æ¬¡ä»·å€¼'].sum()

                    st.markdown(f"""
                    <div class="metric-card">
                        <p class="card-header">é«˜é£é™©æ‰¹æ¬¡</p>
                        <p class="card-value" style="color: {INVENTORY_RISK_COLORS['é«˜é£é™©']};">{high_risk}</p>
                        <p class="card-text">ä»·å€¼: {format_currency(high_risk_value)}</p>
                    </div>
                    """, unsafe_allow_html=True)

                with col3:
                    avg_age = batch_analysis['åº“é¾„'].mean()
                    max_age = batch_analysis['åº“é¾„'].max()

                    st.markdown(f"""
                    <div class="metric-card">
                        <p class="card-header">åº“é¾„ç»Ÿè®¡</p>
                        <p class="card-value">{format_days(avg_age)}</p>
                        <p class="card-text">æœ€é•¿åº“é¾„: {format_days(max_age)}</p>
                    </div>
                    """, unsafe_allow_html=True)

                # æ•´åˆåçš„é£é™©æ‰¹æ¬¡å›¾
                risk_fig = create_combined_risk_chart(batch_analysis)

                if risk_fig:
                    st.plotly_chart(risk_fig, use_container_width=True)
                else:
                    display_empty_chart_message(
                        "æš‚æ— é«˜é£é™©æ‰¹æ¬¡æ•°æ®",
                        "å½“å‰ç­›é€‰æ¡ä»¶ä¸‹æœªæ‰¾åˆ°é«˜é£é™©æ‰¹æ¬¡ï¼Œè¯·å°è¯•è°ƒæ•´é£é™©ç­‰çº§ç­›é€‰æ¡ä»¶æŸ¥çœ‹æ›´å¤šæ‰¹æ¬¡ä¿¡æ¯ã€‚"
                    )

                # æ‰¹æ¬¡é£é™©çƒ­åŠ›å›¾
                heatmap_fig = create_batch_risk_heatmap(batch_analysis)

                if heatmap_fig:
                    st.plotly_chart(heatmap_fig, use_container_width=True)
                else:
                    display_empty_chart_message(
                        "æš‚æ— æ‰¹æ¬¡é£é™©çƒ­åŠ›å›¾æ•°æ®",
                        "å½“å‰ç­›é€‰æ¡ä»¶ä¸‹æ— æ³•ç”Ÿæˆæ‰¹æ¬¡é£é™©çƒ­åŠ›å›¾ã€‚è¯·å°è¯•å‡å°‘ç­›é€‰æ¡ä»¶ã€‚"
                    )

                # æ·»åŠ å›¾è¡¨è§£é‡Š
                if risk_fig or heatmap_fig:
                    # æå–å…³é”®æ´å¯Ÿ
                    high_risk_batches = batch_analysis[batch_analysis['é£é™©ç¨‹åº¦'].isin(['æé«˜é£é™©', 'é«˜é£é™©'])]
                    oldest_batch = None
                    high_value_old_batch = None

                    # å®‰å…¨åœ°æ‰¾å‡ºæœ€è€æ‰¹æ¬¡
                    if not batch_analysis.empty and 'åº“é¾„' in batch_analysis.columns and batch_analysis[
                        'åº“é¾„'].notna().any():
                        oldest_batch = batch_analysis.loc[batch_analysis['åº“é¾„'].idxmax()]

                    # å®‰å…¨åœ°æ‰¾å‡ºä»·å€¼æœ€é«˜çš„é«˜é£é™©æ‰¹æ¬¡
                    if not high_risk_batches.empty and 'æ‰¹æ¬¡ä»·å€¼' in high_risk_batches.columns and high_risk_batches[
                        'æ‰¹æ¬¡ä»·å€¼'].notna().any():
                        high_value_old_batch = high_risk_batches.loc[high_risk_batches['æ‰¹æ¬¡ä»·å€¼'].idxmax()]

                    insight_text = "<b>é£é™©åˆ†ææ´å¯Ÿï¼š</b> ä¸Šå›¾å±•ç¤ºäº†é«˜é£é™©æ‰¹æ¬¡çš„åº“é¾„ä¸æ¸…åº“æ—¶é—´å…³ç³»ï¼Œæ°”æ³¡å¤§å°è¡¨ç¤ºæ‰¹æ¬¡ä»·å€¼ã€‚"
                    if oldest_batch is not None:
                        insight_text += f" æœ€è€æ‰¹æ¬¡ä¸º{oldest_batch['äº§å“ç®€åŒ–åç§°']}ï¼Œåº“é¾„{oldest_batch['åº“é¾„']}å¤©ã€‚"

                    insight_text += " çƒ­åŠ›å›¾æ˜¾ç¤ºäº†å„äº§å“åœ¨ä¸åŒé£é™©ç­‰çº§ä¸‹çš„æ‰¹æ¬¡ä»·å€¼åˆ†å¸ƒï¼Œæ·±è‰²åŒºåŸŸè¡¨ç¤ºé«˜ä»·å€¼æ‰¹æ¬¡ã€‚"
                    if high_value_old_batch is not None:
                        insight_text += f" ä»·å€¼æœ€é«˜çš„é«˜é£é™©æ‰¹æ¬¡ä¸º{high_value_old_batch['äº§å“ç®€åŒ–åç§°']}ï¼Œä»·å€¼{format_currency(high_value_old_batch['æ‰¹æ¬¡ä»·å€¼'])}ã€‚"

                    insight_text += "<br><b>è¡ŒåŠ¨å»ºè®®ï¼š</b> ä¼˜å…ˆå¤„ç†åº“é¾„è¶…è¿‡90å¤©ä¸”ä»·å€¼é«˜çš„æ‰¹æ¬¡ï¼Œåˆ¶å®šåˆ†çº§æ¸…åº“ç­–ç•¥ï¼šå¯¹æé«˜é£é™©æ‰¹æ¬¡è€ƒè™‘æŠ˜ä»·ä¿ƒé”€ï¼Œ"
                    insight_text += "å¯¹é«˜é£é™©æ‰¹æ¬¡åŠ å¼ºè¥é”€æ¨å¹¿åŠ›åº¦ã€‚å»ºç«‹å®šæœŸæ‰¹æ¬¡å®¡æŸ¥æœºåˆ¶ï¼Œå¯¹æ¥è¿‘60å¤©çš„æ‰¹æ¬¡æå‰å¹²é¢„ï¼Œé˜²æ­¢å½¢æˆå‘†æ»åº“å­˜ã€‚"

                    add_chart_explanation(insight_text)
            else:
                display_empty_chart_message(
                    "å½“å‰ç­›é€‰æ¡ä»¶ä¸‹æš‚æ— æ‰¹æ¬¡æ•°æ®",
                    "è¯·å°è¯•è°ƒæ•´ç­›é€‰æ¡ä»¶ï¼Œå‡å°‘é™åˆ¶æ¡ä»¶ä»¥æŸ¥çœ‹æ›´å¤šæ•°æ®ã€‚ç¡®ä¿æ•°æ®æºåŒ…å«æœ‰æ•ˆçš„æ‰¹æ¬¡ä¿¡æ¯ã€‚"
                )

    with tabs[2]:  # è´£ä»»å½’å±åˆ†æ
        if active_tab_index == 2:
            st.markdown('<div class="sub-header">ğŸ‘¥ è´£ä»»å½’å±åˆ†æ</div>', unsafe_allow_html=True)

            # æ·»åŠ æ—¶é—´ç»´åº¦è¯´æ˜
            st.markdown(f'''
            <div class="time-dim-note">
            ğŸ“… <b>æ—¶é—´ç»´åº¦è¯´æ˜</b>: è´£ä»»å½’å±åŸºäºå†å²é”€å”®è®°å½•å’Œé¢„æµ‹æ•°æ®åˆ†æï¼Œæ˜¾ç¤ºå½“å‰æ‰¹æ¬¡çš„ä¸»è¦è´£ä»»äººå’ŒåŒºåŸŸ
            </div>
            ''', unsafe_allow_html=True)

            if batch_analysis is not None and not batch_analysis.empty:
                # è´£ä»»ç»Ÿè®¡
                region_stats = batch_analysis.groupby('è´£ä»»åŒºåŸŸ')['æ‰¹æ¬¡ä»·å€¼'].sum().sort_values(ascending=False)
                person_stats = batch_analysis.groupby('è´£ä»»äºº')['æ‰¹æ¬¡ä»·å€¼'].sum().sort_values(ascending=False)

                # è¿‡æ»¤æ‰ç©ºæˆ–å¼‚å¸¸çš„è´£ä»»åŒºåŸŸ
                region_stats = region_stats[
                    region_stats.index.notna() & (region_stats.index != '') & (region_stats.index != 'æœªçŸ¥åŒºåŸŸ')]
                person_stats = person_stats[
                    person_stats.index.notna() & (person_stats.index != '') & (person_stats.index != 'ç³»ç»Ÿç®¡ç†å‘˜')]

                col1, col2 = st.columns(2)

                with col1:
                    top_region = region_stats.index[0] if len(region_stats) > 0 else "æ— "
                    top_region_value = region_stats.iloc[0] if len(region_stats) > 0 else 0

                    # è·å–è¿™ä¸ªåŒºåŸŸçš„é«˜é£é™©æ‰¹æ¬¡æ¯”ä¾‹
                    if top_region != "æ— ":
                        region_batches = batch_analysis[batch_analysis['è´£ä»»åŒºåŸŸ'] == top_region]
                        region_high_risk = len(region_batches[region_batches['é£é™©ç¨‹åº¦'].isin(['æé«˜é£é™©', 'é«˜é£é™©'])])
                        region_risk_pct = region_high_risk / len(region_batches) * 100 if len(region_batches) > 0 else 0
                        region_detail = f"é«˜é£é™©æ¯”ä¾‹: {format_percentage(region_risk_pct)}"
                    else:
                        region_detail = "æ— è¯¦ç»†æ•°æ®"

                    st.markdown(f"""
                    <div class="metric-card">
                        <p class="card-header">æœ€å¤§è´£ä»»åŒºåŸŸ</p>
                        <p class="card-value">{top_region}</p>
                        <p class="card-text">è´£ä»»ä»·å€¼: {format_currency(top_region_value)}<br>{region_detail}</p>
                    </div>
                    """, unsafe_allow_html=True)

                with col2:
                    top_person = person_stats.index[0] if len(person_stats) > 0 else "æ— "
                    top_person_value = person_stats.iloc[0] if len(person_stats) > 0 else 0

                    # è·å–è¿™ä¸ªè´£ä»»äººçš„é«˜é£é™©æ‰¹æ¬¡æ¯”ä¾‹
                    if top_person != "æ— ":
                        person_batches = batch_analysis[batch_analysis['è´£ä»»äºº'] == top_person]
                        person_high_risk = len(person_batches[person_batches['é£é™©ç¨‹åº¦'].isin(['æé«˜é£é™©', 'é«˜é£é™©'])])
                        person_risk_pct = person_high_risk / len(person_batches) * 100 if len(person_batches) > 0 else 0
                        person_detail = f"é«˜é£é™©æ¯”ä¾‹: {format_percentage(person_risk_pct)}"
                    else:
                        person_detail = "æ— è¯¦ç»†æ•°æ®"

                    st.markdown(f"""
                    <div class="metric-card">
                        <p class="card-header">æœ€å¤§è´£ä»»äºº</p>
                        <p class="card-value">{top_person}</p>
                        <p class="card-text">è´£ä»»ä»·å€¼: {format_currency(top_person_value)}<br>{person_detail}</p>
                    </div>
                    """, unsafe_allow_html=True)

                # è´£ä»»æ ‘çŠ¶å›¾ - æ›¿ä»£åŸæ¥çš„ä¸¤ä¸ªå›¾è¡¨
                responsibility_tree = create_responsibility_tree_chart(batch_analysis)

                if responsibility_tree:
                    st.plotly_chart(responsibility_tree, use_container_width=True)

                    # æ·»åŠ å›¾è¡¨è§£é‡Š
                    insight_text = "<b>è´£ä»»å½’å±æ´å¯Ÿï¼š</b> æ ‘çŠ¶å›¾å±•ç¤ºäº†æ‰¹æ¬¡ä»·å€¼æŒ‰åŒºåŸŸã€è´£ä»»äººå’Œé£é™©ç­‰çº§çš„åˆ†å±‚åˆ†å¸ƒã€‚"

                    if top_region != "æ— ":
                        insight_text += f" {top_region}åŒºåŸŸæ˜¯ä¸»è¦è´£ä»»åŒºåŸŸï¼Œå æ€»æ‰¹æ¬¡ä»·å€¼çš„{region_stats.iloc[0] / region_stats.sum() * 100:.1f}%ã€‚"

                    if top_person != "æ— ":
                        insight_text += f" {top_person}æ˜¯ä¸»è¦è´£ä»»äººï¼Œç®¡ç†çš„æ‰¹æ¬¡ä»·å€¼å {person_stats.iloc[0] / person_stats.sum() * 100:.1f}%ã€‚"

                    # æŸ¥æ‰¾é£é™©æœ€é«˜çš„åŒºåŸŸ
                    region_risk_counts = batch_analysis.groupby('è´£ä»»åŒºåŸŸ')['é£é™©ç¨‹åº¦'].apply(
                        lambda x: sum(x.isin(['æé«˜é£é™©', 'é«˜é£é™©'])) / len(x) if len(x) > 0 else 0
                    ).sort_values(ascending=False)

                    highest_risk_region = region_risk_counts.index[0] if len(region_risk_counts) > 0 else "æ— "
                    highest_risk_pct = region_risk_counts.iloc[0] * 100 if len(region_risk_counts) > 0 else 0

                    if highest_risk_region != "æ— " and highest_risk_region != top_region:
                        insight_text += f" å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œ{highest_risk_region}åŒºåŸŸçš„é«˜é£é™©æ‰¹æ¬¡æ¯”ä¾‹æœ€é«˜ï¼Œè¾¾åˆ°{format_percentage(highest_risk_pct)}ã€‚"

                    insight_text += "<br><b>è¡ŒåŠ¨å»ºè®®ï¼š</b> "

                    if highest_risk_region != "æ— " and highest_risk_pct > 30:
                        insight_text += f"å¯¹{highest_risk_region}åŒºåŸŸï¼ˆé«˜é£é™©æ‰¹æ¬¡å æ¯”{format_percentage(highest_risk_pct)}ï¼‰è¿›è¡Œé‡ç‚¹åº“å­˜ç®¡ç†åŸ¹è®­ï¼Œ"
                    else:
                        insight_text += "å¯¹åº“å­˜ä»·å€¼é«˜çš„åŒºåŸŸåŠ å¼ºåº“å­˜ç®¡ç†åŸ¹è®­ï¼Œ"

                    insight_text += "å»ºç«‹æ¸…æ™°çš„è´£ä»»åˆ¶è€ƒæ ¸ä½“ç³»ï¼›ä¼˜åŒ–é¢„æµ‹å‡†ç¡®æ€§ï¼Œæé«˜é”€å”®ä¸é‡‡è´­çš„åè°ƒæ•ˆç‡ï¼›"
                    insight_text += "å»ºç«‹è·¨åŒºåŸŸåº“å­˜è°ƒæ‹¨æœºåˆ¶ï¼Œå¹³è¡¡åŒºåŸŸé—´åº“å­˜åˆ†å¸ƒå·®å¼‚ã€‚"

                    add_chart_explanation(insight_text)

                else:
                    display_empty_chart_message(
                        "æš‚æ— è´£ä»»å½’å±æ•°æ®",
                        "å½“å‰ç­›é€‰æ¡ä»¶ä¸‹æ— æ³•ç”Ÿæˆè´£ä»»å½’å±åˆ†æå›¾è¡¨ã€‚è¯·å°è¯•è°ƒæ•´ç­›é€‰æ¡ä»¶æˆ–æ£€æŸ¥æ•°æ®æºã€‚"
                    )
            else:
                display_empty_chart_message(
                    "å½“å‰ç­›é€‰æ¡ä»¶ä¸‹æš‚æ— è´£ä»»å½’å±æ•°æ®",
                    "è¯·å°è¯•è°ƒæ•´ç­›é€‰æ¡ä»¶ï¼Œå‡å°‘é™åˆ¶æ¡ä»¶ä»¥æŸ¥çœ‹æ›´å¤šæ•°æ®ã€‚ç¡®ä¿æ•°æ®æºåŒ…å«æœ‰æ•ˆçš„è´£ä»»äººå’ŒåŒºåŸŸä¿¡æ¯ã€‚"
                )

    with tabs[3]:  # é¢„æµ‹ä¸æ¸…åº“åˆ†æ
        if active_tab_index == 3:
            st.markdown('<div class="sub-header">ğŸ“ˆ é¢„æµ‹ä¸æ¸…åº“åˆ†æ</div>', unsafe_allow_html=True)

            # æ·»åŠ æ—¶é—´ç»´åº¦è¯´æ˜
            st.markdown(f'''
            <div class="time-dim-note">
            ğŸ“… <b>æ—¶é—´ç»´åº¦è¯´æ˜</b>: æ¸…åº“é¢„æµ‹åŸºäºè¿‡å»é”€å”®æ•°æ®è®¡ç®—æ—¥å‡é”€é‡ï¼Œå¹¶æ ¹æ®å½“å‰åº“å­˜é¢„ä¼°æ¸…åº“æ‰€éœ€å¤©æ•°ï¼›é¢„æµ‹åå·®åˆ†æåŸºäºæœ€è¿‘30å¤©æ•°æ®
            </div>
            ''', unsafe_allow_html=True)

            if batch_analysis is not None and not batch_analysis.empty:
                # æ¸…åº“ç»Ÿè®¡
                infinite_batches = len(batch_analysis[batch_analysis['é¢„è®¡æ¸…åº“å¤©æ•°'] == float('inf')])
                infinite_value = batch_analysis[batch_analysis['é¢„è®¡æ¸…åº“å¤©æ•°'] == float('inf')]['æ‰¹æ¬¡ä»·å€¼'].sum()

                long_clearance = len(batch_analysis[
                                         (batch_analysis['é¢„è®¡æ¸…åº“å¤©æ•°'] != float('inf')) &
                                         (batch_analysis['é¢„è®¡æ¸…åº“å¤©æ•°'] > 180)
                                         ])
                long_clearance_value = batch_analysis[
                    (batch_analysis['é¢„è®¡æ¸…åº“å¤©æ•°'] != float('inf')) &
                    (batch_analysis['é¢„è®¡æ¸…åº“å¤©æ•°'] > 180)
                    ]['æ‰¹æ¬¡ä»·å€¼'].sum()

                avg_clearance = batch_analysis[batch_analysis['é¢„è®¡æ¸…åº“å¤©æ•°'] != float('inf')]['é¢„è®¡æ¸…åº“å¤©æ•°'].mean()

                col1, col2, col3 = st.columns(3)

                with col1:
                    st.markdown(f"""
                                <div class="metric-card">
                                    <p class="card-header">æ— æ³•æ¸…åº“æ‰¹æ¬¡</p>
                                    <p class="card-value" style="color: {COLORS['danger']};">{infinite_batches}</p>
                                    <p class="card-text">ä»·å€¼: {format_currency(infinite_value)}</p>
                                </div>
                                """, unsafe_allow_html=True)

                with col2:
                    st.markdown(f"""
                                <div class="metric-card">
                                    <p class="card-header">é•¿æœŸç§¯å‹æ‰¹æ¬¡</p>
                                    <p class="card-value" style="color: {COLORS['warning']};">{long_clearance}</p>
                                    <p class="card-text">ä»·å€¼: {format_currency(long_clearance_value)}</p>
                                </div>
                                """, unsafe_allow_html=True)

                with col3:
                    st.markdown(f"""
                                <div class="metric-card">
                                    <p class="card-header">å¹³å‡æ¸…åº“å‘¨æœŸ</p>
                                    <p class="card-value">{format_days(avg_clearance)}</p>
                                    <p class="card-text">å¯æ¸…åº“æ‰¹æ¬¡å¹³å‡å€¼</p>
                                </div>
                                """, unsafe_allow_html=True)

                # é¢„æµ‹åå·®åˆ†æå›¾è¡¨ - æ•´åˆå›¾
                forecast_impact_fig = create_forecast_impact_chart(batch_analysis)

                if forecast_impact_fig:
                    st.plotly_chart(forecast_impact_fig, use_container_width=True)
                else:
                    display_empty_chart_message(
                        "æš‚æ— é¢„æµ‹åå·®åˆ†ææ•°æ®",
                        "å½“å‰ç­›é€‰æ¡ä»¶ä¸‹æ— æ³•ç”Ÿæˆé¢„æµ‹åå·®åˆ†æå›¾è¡¨ã€‚å¯èƒ½æ˜¯å› ä¸ºç­›é€‰åçš„æ•°æ®é‡ä¸è¶³æˆ–é¢„æµ‹æ•°æ®ç¼ºå¤±ã€‚"
                    )

                # æ·»åŠ å›¾è¡¨è§£é‡Š
                if forecast_impact_fig:
                    # æå–å…³é”®æ´å¯Ÿ
                    no_sales_products = batch_analysis[batch_analysis['é¢„è®¡æ¸…åº“å¤©æ•°'] == float('inf')][
                        'äº§å“ç®€åŒ–åç§°'].tolist()

                    # å®‰å…¨å¤„ç†é¢„æµ‹åå·®åˆ†æ
                    batch_analysis_copy = batch_analysis.copy()
                    batch_analysis_copy['é¢„æµ‹åå·®å€¼'] = batch_analysis_copy['é¢„æµ‹åå·®'].apply(
                        lambda x: float(x.rstrip('%')) / 100 if isinstance(x, str) and '%' in x and x != 'å¼‚å¸¸' else 0
                    )

                    most_overestimated = pd.DataFrame()
                    most_underestimated = pd.DataFrame()

                    # å®‰å…¨åœ°æ‰¾å‡ºé¢„æµ‹åå·®æœ€å¤§çš„äº§å“
                    valid_forecast = batch_analysis_copy[
                        (abs(batch_analysis_copy['é¢„æµ‹åå·®å€¼']) <= 1.0) &
                        (batch_analysis_copy['é¢„è®¡æ¸…åº“å¤©æ•°'] != float('inf'))
                        ]

                    if not valid_forecast.empty:
                        sorted_bias = valid_forecast.sort_values('é¢„æµ‹åå·®å€¼', ascending=False)
                        if not sorted_bias.empty:
                            most_overestimated = sorted_bias.iloc[0:1]

                        sorted_bias_under = valid_forecast.sort_values('é¢„æµ‹åå·®å€¼', ascending=True)
                        if not sorted_bias_under.empty:
                            most_underestimated = sorted_bias_under.iloc[0:1]

                    insight_text = "<b>é¢„æµ‹ä¸æ¸…åº“æ´å¯Ÿï¼š</b> å›¾è¡¨å±•ç¤ºäº†é¢„æµ‹åå·®ä¸æ¸…åº“å¤©æ•°ä¹‹é—´çš„å…³ç³»ï¼Œæ°”æ³¡å¤§å°è¡¨ç¤ºæ‰¹æ¬¡ä»·å€¼ï¼Œé¢œè‰²ä»£è¡¨é¢„æµ‹åå·®ã€‚"

                    if not no_sales_products:
                        insight_text += " æ‰€æœ‰æ‰¹æ¬¡éƒ½æœ‰é”€å”®è®°å½•ï¼Œä½†éƒ¨åˆ†æ‰¹æ¬¡æ¸…åº“å‘¨æœŸè¿‡é•¿ã€‚"
                    elif len(no_sales_products) <= 3:
                        insight_text += f" äº§å“{', '.join(no_sales_products[:3])}å› æ— é”€é‡å¯¼è‡´æ¸…åº“å¤©æ•°ä¸ºæ— ç©·å¤§ï¼Œéœ€è¦ç‰¹åˆ«å…³æ³¨ã€‚"
                    else:
                        insight_text += f" æœ‰{infinite_batches}ä¸ªæ‰¹æ¬¡å› æ— é”€é‡å¯¼è‡´æ¸…åº“å¤©æ•°ä¸ºæ— ç©·å¤§ï¼Œéœ€è¦ç‰¹åˆ«å¹²é¢„æªæ–½ã€‚"

                    if not most_overestimated.empty:
                        product = most_overestimated['äº§å“ç®€åŒ–åç§°'].iloc[0]
                        bias = float(most_overestimated['é¢„æµ‹åå·®'].iloc[0].rstrip('%')) if isinstance(
                            most_overestimated['é¢„æµ‹åå·®'].iloc[0], str) else 0
                        insight_text += f" é¢„æµ‹åå·®æœ€å¤§çš„äº§å“æ˜¯{product}ï¼Œé¢„æµ‹è¿‡é«˜{abs(bias):.1f}%ã€‚"

                    if not most_underestimated.empty:
                        product = most_underestimated['äº§å“ç®€åŒ–åç§°'].iloc[0]
                        bias = float(most_underestimated['é¢„æµ‹åå·®'].iloc[0].rstrip('%')) if isinstance(
                            most_underestimated['é¢„æµ‹åå·®'].iloc[0], str) else 0
                        insight_text += f" é¢„æµ‹ä¸è¶³æœ€ä¸¥é‡çš„äº§å“æ˜¯{product}ï¼Œé¢„æµ‹ä½äºå®é™…é”€é‡{abs(bias):.1f}%ã€‚"

                    insight_text += "<br><b>è¡ŒåŠ¨å»ºè®®ï¼š</b> å¯¹é•¿æœŸç§¯å‹æ‰¹æ¬¡åˆ¶å®šä¸“é¡¹æ¸…åº“è¡ŒåŠ¨è®¡åˆ’ï¼Œè€ƒè™‘æ†ç»‘é”€å”®æˆ–é™æ—¶ä¿ƒé”€ï¼›"
                    insight_text += "æ”¹å–„é¢„æµ‹æ¨¡å‹å‡†ç¡®æ€§ï¼Œå‡å°‘åå·®å¯¼è‡´çš„åº“å­˜ç§¯å‹ï¼›å»ºç«‹åŠ¨æ€å®šä»·æœºåˆ¶ï¼Œæ ¹æ®åº“é¾„è°ƒæ•´ä»·æ ¼ç­–ç•¥ï¼›"
                    insight_text += "å¯¹æ— é”€é‡çš„äº§å“è€ƒè™‘æ›¿ä»£æ€§è¥é”€ç­–ç•¥æˆ–è½¬ç§»åˆ°å…¶ä»–é”€å”®æ¸ é“ã€‚"

                    add_chart_explanation(insight_text)
            else:
                display_empty_chart_message(
                    "å½“å‰ç­›é€‰æ¡ä»¶ä¸‹æš‚æ— æ¸…åº“é¢„æµ‹æ•°æ®",
                    "è¯·å°è¯•è°ƒæ•´ç­›é€‰æ¡ä»¶ï¼Œå‡å°‘é™åˆ¶æ¡ä»¶ä»¥æŸ¥çœ‹æ›´å¤šæ•°æ®ã€‚ç¡®ä¿æ•°æ®æºåŒ…å«æœ‰æ•ˆçš„é”€å”®å’Œåº“å­˜ä¿¡æ¯ã€‚"
                )


# æ‰§è¡Œä¸»å‡½æ•°
if __name__ == "__main__":
    main()